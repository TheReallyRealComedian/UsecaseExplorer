{
  "metadata": {
    "export_date": "2025-06-07T13:04:00.375500",
    "version": "1.0"
  },
  "data": {
    "users": [
      {
        "id": 1,
        "username": "Oliver",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 2,
        "username": "Comedian",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 3,
        "username": "Haifischli",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      }
    ],
    "areas": [
      {
        "id": 1,
        "name": "Supply Chain Management",
        "description": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 2,
        "name": "Strategic Partner Management",
        "description": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 3,
        "name": "Bio Excellence",
        "description": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 4,
        "name": "Maintenance",
        "description": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 5,
        "name": "Logistics",
        "description": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 6,
        "name": "Quality Control",
        "description": "# Value-Creating Tasks in Pharmaceutical Quality Control: A Step-by-Step Analysis\r\n\r\n## 1. Lab Planning and Scheduling\r\n\r\n### Strategic Resource Allocation and Dynamic Adjustment\r\n\r\nQuality Control laboratories transform raw data into actionable insights through structured planning. Value creation begins with **automated scheduling systems** that integrate production forecasts, stability testing requirements, and equipment availability[^2][^14]. For example, digital tools like SAP PM or specialized software (e.g., Binocs) enable real-time adjustments to analyst assignments, prioritizing rush samples while maintaining FIFO principles for routine testing[^9][^15]. These systems reduce idle time by 20\u201330% and prevent bottlenecks by aligning HPLC/GC instrument usage with batch release deadlines[^18].\r\n\r\nCritical tasks include:\r\n\r\n- **Demand forecasting** using historical data to predict testing volumes for new drug launches or seasonal production spikes[^7].\r\n- **Cross-functional collaboration** with supply chain teams to align QC timelines with manufacturing schedules, ensuring raw material releases occur within 48 hours of arrival[^1][^12].\r\n- **Capacity modeling** to identify underutilized shifts or equipment, enabling reallocation of analysts to high-priority stability studies[^21].\r\n\r\n\r\n## 2. Specification Creation and Handling\r\n\r\n### Standardization and Regulatory Agility\r\n\r\nQC specifications define the boundaries of product acceptability, making their management pivotal for compliance. Value is created through **global harmonization of test methods**, reducing redundant \"n-methods\" for the same product across sites[^1][^8]. For instance, AI-powered translation tools ensure inspection instructions (e.g., \"Pr\u00fcfvorschrift\") are consistent in all regions, minimizing interpretation errors during FDA audits[^1].\r\n\r\nKey activities:\r\n\r\n- **Centralized specification databases** that auto-update limits when pharmacopeial standards change (e.g., USP <905> uniformity revisions)[^8].\r\n- **Automated method transfer** to LIMS, reducing manual entry errors by 95% and enabling instant deployment of new protocols to robotic systems[^5][^19].\r\n- **Risk-based change control** where AI flags specifications impacted by regulatory updates, triggering targeted revalidations instead of full-method reviews[^12].\r\n\r\n\r\n## 3. Sampling and Sample Storage\r\n\r\n### Traceability and Condition Integrity\r\n\r\nSampling errors account for 34% of OOS results in pharmaceuticals[^26]. Modern QC labs mitigate this through **RFID-enabled sample tracking**, which logs chain-of-custody data (e.g., freezer temperatures, handler IDs) in real time[^3][^9]. For biologics, barcoded cryovials integrate with electronic batch records, ensuring -80\u00b0C storage deviations are flagged before compromising stability[^12][^26].\r\n\r\nValue-adding processes:\r\n\r\n- **Dynamic sample prioritization**: Stability samples nearing expiry dates are automatically escalated in testing queues[^14].\r\n- **Paperless sampling protocols**: Tablets with integrated cameras document particulate inspections during vial sampling, attaching visual evidence directly to LIMS records[^3][^26].\r\n- **Automated storage retrieval**: Robotic arms in -20\u00b0C archives retrieve specific samples for retesting within 2 minutes, vs. 45+ minutes manually[^9].\r\n\r\n\r\n## 4. Testing Preparation and Execution\r\n\r\n### Error-Proofing Through Automation\r\n\r\nA QC lab testing oral solid doses performs ~200 dissolutions daily. Robotic systems like Lab4U reduce hands-on time by 70% by automating media preparation, sinker placement, and sample loading[^11][^19]. Integrated balances auto-validate weights against theoretical yields, rejecting out-of-trend samples before analysis[^4][^12].\r\n\r\nCore tasks:\r\n\r\n- **Method-driven workflows**: LES systems guide analysts through compendial tests step-by-step, pausing if a pH meter hasn\u2019t been calibrated[^1][^19].\r\n- **In-line PAT**: Near-infrared (NIR) probes on blending equipment feed real-time content uniformity data to QC, allowing batch adjustments before official testing[^11][^21].\r\n- **Cross-contamination prevention**: Automated cleaning validation between penicillin and non-penicillin tests using swab sampling robots[^26].\r\n\r\n\r\n## 5. Result Generation, Evaluation \\& Release\r\n\r\n### Defect Prevention Through AI\r\n\r\nAI algorithms compare chromatograms against a library of 10,000+ known impurity profiles, flagging novel peaks for toxicology review[^20][^25]. For accelerated release, \"review-by-exception\" systems auto-approve batches where all results are within 80\u2013120% of target and no deviations occurred[^20][^25].\r\n\r\nCritical innovations:\r\n\r\n- **Predictive OOS avoidance**: Machine learning models analyze historical deviations to predict and prevent recurring errors (e.g., column degradation in HPLC)[^13][^25].\r\n- **Blockchain-enabled CoAs**: Immutable certificates of analysis are generated and shared with regulators within 15 minutes of batch approval[^12][^19].\r\n- **Trend-to-spec alignment**: Statistical process control (SPC) updates release limits quarterly based on cumulative manufacturing data, tightening ranges as processes mature[^8][^25].\r\n\r\n\r\n## 6. QC Data Analysis and Trending\r\n\r\n### Transforming Data into Process Insights\r\n\r\nA QC lab managing 50+ products uses multivariate analysis to correlate dissolution failures with humidity spikes during granulation[^13][^25]. By adjusting drying parameters, failures dropped from 12% to 1.2% within six months.\r\n\r\nValue drivers:\r\n\r\n- **Root cause prediction**: AI clusters OOS events by shift, equipment, or analyst, identifying that 40% of particulate matter cases occur on Line 2\u2019s night shift[^25][^13].\r\n- **Stability forecast modeling**: Accelerated aging data trains algorithms to predict shelf-life extensions, saving \\$2M/year in unnecessary retests[^21].\r\n- **Supplier risk scoring**: Trend analysis of raw material impurities auto-flags high-risk vendors, triggering audits before batches are delayed[^12][^25].\r\n\r\n\r\n## 7. QC Equipment Readiness\r\n\r\n### Uptime Maximization Through IoT\r\n\r\nA centralized equipment database tracks 500+ instruments, scheduling calibrations during planned downtime[^7][^18]. Vibration sensors on GC ovens predict column failures 48 hours in advance, reducing unplanned outages by 90%[^9][^18].\r\n\r\nKey initiatives:\r\n\r\n- **Prescriptive maintenance**: Augmented reality guides technicians through complex repairs using 3D equipment overlays[^18][^21].\r\n- **Usage-based recalibration**: HPLC pumps used <10 hours/week are calibrated quarterly, while high-use systems undergo monthly checks[^7][^12].\r\n- **Fleet standardization**: Replacing 15 legacy HPLC models with a single platform cut training time by 60% and spare part inventories by \\$350K/year[^18][^21].\r\n\r\n\r\n## Conclusion\r\n\r\nQuality Control in pharmaceuticals has evolved from defect detection to proactive value generation. By embedding automation, AI, and cross-functional connectivity into each step, modern QC labs reduce release times by 40%, cut compliance risks by 55%, and contribute directly to portfolio acceleration. For new professionals, mastering these interconnected systems is key to driving both patient safety and operational excellence.\r\n\r\n<div style=\"text-align: center\">\u2042</div>\r\n\r\n[^1]: paste.txt\r\n\r\n[^2]: https://www.ipsdb.com/files/docs/Resource_Scheduling_in_QC_Labs.pdf\r\n\r\n[^3]: https://the-randd-community.co.uk/resources/article/how-to-create-your-own-quality-control-process/\r\n\r\n[^4]: https://www.labmanager.com/improving-lab-scheduling-to-drive-productivity-and-flexibility-33383\r\n\r\n[^5]: https://www.designingbuildings.co.uk/wiki/Quality control for construction works\r\n\r\n[^6]: https://www.effivity.com/blog/quality-control-plans\r\n\r\n[^7]: https://www.paperlesslabacademy.com/wp-content/uploads/2022/01/BINOCS_-_Digitalizing_your_laboratory_planning_and.pdf\r\n\r\n[^8]: https://www.westgard.com/lessons/quality-management/lesson3.html\r\n\r\n[^9]: https://amplelogic.com/how-qc-planning-and-scheduling-systems-improve-lab-efficiency/\r\n\r\n[^10]: https://www.linkedin.com/pulse/6-steps-optimize-resource-planning-your-qc-lab-geert-vanhove\r\n\r\n[^11]: https://www.pharmamanufacturing.com/facilities/op-ex-lean-six-sigma/article/11323382/leaning-the-quality-control-laboratory\r\n\r\n[^12]: https://www.niras.com/insights/quality-and-compliance-in-pharma-manufacturing/\r\n\r\n[^13]: https://www.diva-portal.org/smash/get/diva2:205691/fulltext01.pdf\r\n\r\n[^14]: https://www.ipsdb.com/files/docs/Resource_Scheduling_in_QC_Laboratories.pdf\r\n\r\n[^15]: https://www.bluecrux.com/whitepapers/the-ultimate-guide-for-lab-planning-and-scheduling-digitalization/\r\n\r\n[^16]: https://amplelogic.com/best-practices-for-implementing-qc-planning-scheduling-in-pharma/\r\n\r\n[^17]: https://bsmlean.com/sites/default/files/docs/2021-07/Efeso-BSM-CapacityPlanningTool-120721.pdf\r\n\r\n[^18]: https://www.orsoft.net/en/industries/life-sciences-pharma/laboratory-planning-quality-control-in-the-pharmaceutical-industry/\r\n\r\n[^19]: https://www.bluecrux.com/blog/six-steps-to-optimize-the-resource-planning-in-your-qc-lab/\r\n\r\n[^20]: https://amplelogic.com/qc-planning-and-scheduling-software/\r\n\r\n[^21]: https://www.machinemetrics.com/blog/manufacturing-capacity-planning\r\n\r\n[^22]: https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1004\\&context=birsafricatr\r\n\r\n[^23]: https://www.projektron.de/en/blog/details/resource-planning-3784/\r\n\r\n[^24]: https://www.planta.de/en/blog/resource-planning-in-project-management-a-guideline/\r\n\r\n[^25]: https://kta.com/quality-assurance-quality-control-roles/\r\n\r\n[^26]: https://www.pharmasop.in/sop-for-quality-control-sample-management/\r\n\r\n[^27]: https://cumulusquality.com/7-steps-for-developing-effective-quality-control-procedures/\r\n\r\n[^28]: https://www.ipcc-nggip.iges.or.jp/public/gp/english/8_QA-QC.pdf\r\n\r\n[^29]: https://birdviewpsa.com/blog/smart-resource-allocation-and-task-scheduling-how-do-you-do-this/\r\n\r\n[^30]: https://www.ibm.com/docs/en/cognos-analytics/12.0.0?topic=83-schedule-priority\r\n\r\n[^31]: https://www.mechanicalpower.net/blog/optimizing-efficiency-the-role-of-consolidation-in-supply-chain-management/\r\n\r\n[^32]: https://www.shotuk.org/wp-content/uploads/2024/10/Capacity-Planning-Guidance-May-2021.pdf\r\n\r\n[^33]: https://amplelogic.com/de/qc-planning-and-scheduling-software/\r\n\r\n[^34]: https://appliedsmartfactory.com/wp-content/uploads/2022/02/Harnessing-the-Real-Capacity-of-Pharma-Manufacturing-Smart-Scheduling.pdf\r\n\r\n[^35]: https://www.planettogether.com/blog/optimizing-pharmaceutical-manufacturing-a-guide-to-dynamic-production-capacity-planning\r\n\r\n[^36]: https://appliedsmartfactory.com/pharmaceutical-blog/pharma-4-0/quality-control-lab-scheduling/\r\n\r\n[^37]: https://www.labdesignnews.com/content/optimizing-pharma-qc-lab-design\r\n\r\n[^38]: https://pharmastate.academy/sop-of-control-sample-management/\r\n\r\n[^39]: https://www.cliniversity.com/preparation-for-quality-control-qc/\r\n\r\n[^40]: https://www.scilife.io/blog/quality-control-procedures-pharmaceutical-industry\r\n\r\n[^41]: https://us.caddi.com/resources/insights/supplier-consolidation\r\n\r\n[^42]: https://smart-qc.com\r\n\r\n[^43]: https://www.ema.europa.eu/en/documents/scientific-guideline/international-conference-harmonisation-technical-requirements-registration-pharmaceuticals-human-guideline-q10-pharmaceutical-quality-system-step-5_en.pdf\r\n\r\n[^44]: https://simplerqms.com/pharmaceutical-quality-management-system/\r\n\r\n[^45]: https://my.3dexperience.3ds.com/welcome/compass-world/3dexperience-life-sciences-and-healthcare/manufacturing-excellence-for-biopharma/quality-control-lab-scheduling\r\n\r\n[^46]: https://labforward.io/blog/qc-laboratories-digital-transformation/\r\n\r\n[^47]: https://www.efeso.com/knowledge/insight/bringing-lean-to-qc-pharma\r\n\r\n[^48]: https://www.linkedin.com/pulse/workforce-capacity-planning-brings-quick-wins-quality-geert-vanhove\r\n\r\n[^49]: https://www.bluecrux.com/binocs/qa-qc-lab-planning-and-scheduling-software/\r\n\r\n[^50]: https://www.cresultsconsulting.com/wp-content/uploads/2016/04/ResourcePlanninginQCLabs.pdf\r\n\r\n[^51]: https://www.westgard.com/lessons/basic-qc-practices-l/lesson14.html\r\n\r\n[^52]: https://www.sciencedirect.com/science/article/pii/S2405896319313795\r\n\r\n[^53]: https://appliedsmartfactory.com/zh-hans/pharmaceutical-blog/pharma-zh-hans/quality-control-lab-scheduling/\r\n\r\n[^54]: https://www.orsoft.net/en/solutions-concepts/lab-scheduling/",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 7,
        "name": "Manufacturing",
        "description": "# Typical Practices in Pharmaceutical Manufacturing Operations: A Comprehensive Industry Analysis\r\n\r\nThe pharmaceutical manufacturing industry operates within a highly regulated environment where adherence to Good Manufacturing Practices (GMP) is paramount to ensuring product quality, safety, and efficacy. This comprehensive analysis examines typical industry-wide practices across six critical process areas in pharmaceutical manufacturing operations, providing insights into standard operating procedures, value creation mechanisms, and common challenges faced by manufacturers. The analysis reveals that modern pharmaceutical manufacturing is increasingly characterized by digital transformation initiatives, continuous process verification approaches, and integrated data management systems that support both operational efficiency and regulatory compliance requirements[^1][^3][^6].\r\n\r\n## Production Planning and Scheduling Operations\r\n\r\nProduction planning and scheduling represents the foundational process that orchestrates all downstream manufacturing activities in pharmaceutical operations. This critical function ensures efficient resource allocation, optimal capacity utilization, and reliable supply chain performance while maintaining compliance with regulatory requirements. The complexity of pharmaceutical production planning stems from the need to coordinate multiple interdependent processes, manage diverse product portfolios, and respond to dynamic market demands within a heavily regulated environment.\r\n\r\n### Strategic Operations Planning Framework\r\n\r\nModern pharmaceutical manufacturers typically employ comprehensive operations planning methodologies that integrate multiple planning horizons and decision-making levels. Long-term strategic planning involves capacity assessment across manufacturing networks, technology roadmap development, and facility investment decisions[^5][^10]. Medium-term planning focuses on demand forecasting, master production scheduling, and resource allocation across product lines. Short-term operational planning addresses daily scheduling, batch sequencing, and real-time resource optimization. This hierarchical planning approach enables manufacturers to balance strategic objectives with operational constraints while maintaining flexibility to respond to market changes and supply disruptions.\r\n\r\nThe integration of demand forecasting with production planning represents a critical capability, as pharmaceutical companies frequently face significant forecasting challenges. Industry surveys indicate that most pharmaceutical companies experience demand prediction errors of up to 25% for new drug products, necessitating robust scenario planning and risk mitigation strategies[^10]. Advanced planning systems typically incorporate multiple forecasting models, market intelligence, and historical consumption patterns to develop more accurate demand projections.\r\n\r\n### Capacity Planning and Resource Optimization\r\n\r\nCapacity planning in pharmaceutical manufacturing requires sophisticated analysis of equipment availability, facility constraints, personnel requirements, and regulatory compliance factors. Manufacturers must consider the unique characteristics of pharmaceutical production, including extended validation requirements, cleaning and changeover times, and quality control testing cycles[^5][^16]. Effective capacity planning integrates preventive maintenance schedules, calibration activities, and equipment qualification requirements to maximize productive capacity while ensuring continuous compliance with GMP standards.\r\n\r\nMulti-site capacity planning has become increasingly important as pharmaceutical companies operate global manufacturing networks. Companies typically develop integrated planning models that optimize production allocation across sites while considering factors such as regulatory approvals, technology capabilities, cost structures, and supply chain proximity[^5][^19]. Advanced capacity planning systems enable manufacturers to evaluate trade-offs between in-house production and contract manufacturing arrangements, supporting strategic decisions about outsourcing and facility utilization.\r\n\r\n### Advanced Scheduling Methodologies\r\n\r\nDay-to-day scheduling in pharmaceutical manufacturing involves complex optimization challenges that must balance multiple competing objectives. Manufacturers typically employ campaign-based scheduling approaches that group similar products to minimize changeover activities and cleaning requirements[^1][^16]. Advanced scheduling systems incorporate constraint-based optimization algorithms that consider equipment capabilities, material availability, personnel qualifications, and regulatory requirements to develop feasible production schedules.\r\n\r\nSetup optimization represents a critical component of pharmaceutical scheduling, as changeover activities can consume significant production time. Leading manufacturers implement sequence-dependent setup optimization that considers product compatibility, cleaning requirements, and validation constraints to minimize total changeover time[^1][^2]. This approach often involves sophisticated mathematical models that evaluate thousands of potential scheduling combinations to identify optimal production sequences.\r\n\r\n## Core Manufacturing Process Operations\r\n\r\nThe execution of manufacturing processes represents the heart of pharmaceutical operations, where raw materials are transformed into finished drug products through carefully controlled and validated procedures. Modern pharmaceutical manufacturing emphasizes process automation, real-time monitoring, and continuous improvement to ensure consistent product quality while optimizing operational efficiency. The integration of advanced process analytical technologies and digital manufacturing systems has revolutionized how companies approach process execution and control.\r\n\r\n### Master Batch Record Management and Execution\r\n\r\nMaster Batch Records (MBRs) serve as the foundational documents that define all activities required for pharmaceutical production. Industry best practices emphasize standardization of MBR formats across manufacturing sites to facilitate technology transfer and ensure consistent execution[^1][^3]. Leading manufacturers have implemented automated MBR generation systems that utilize standardized templates and product-specific parameters to create consistent documentation while reducing manual effort and potential errors.\r\n\r\nThe execution of MBRs in modern pharmaceutical facilities increasingly relies on electronic batch recording systems that integrate with manufacturing equipment and process control systems. These systems provide real-time guidance to operators, automatically capture critical process data, and enforce procedural compliance through electronic workflows[^1][^6]. Advanced implementations include exception-based review processes where human intervention is only required when parameters deviate from established acceptable ranges, significantly improving review efficiency while maintaining quality oversight.\r\n\r\n### Real-Time Process Monitoring and Control Systems\r\n\r\nContemporary pharmaceutical manufacturing operations employ sophisticated process monitoring systems that provide continuous visibility into critical process parameters. These systems typically integrate multiple data sources, including process equipment sensors, environmental monitoring systems, and in-process control measurements, to create comprehensive process understanding[^6][^17]. Real-time dashboards enable operators and supervisors to monitor process performance, identify trending issues, and implement corrective actions before quality impacts occur.\r\n\r\nAdvanced process control systems utilize statistical process control methodologies and machine learning algorithms to detect anomalies and predict potential process deviations[^17][^18]. These capabilities enable proactive process management that can prevent quality issues and reduce the frequency of process investigations. The implementation of Process Analytical Technology (PAT) has further enhanced real-time monitoring capabilities by providing continuous measurement of critical quality attributes during production[^1][^4].\r\n\r\n### Continuous Process Verification Implementation\r\n\r\nContinuous Process Verification (CPV) has emerged as a fundamental practice in modern pharmaceutical manufacturing, replacing traditional process validation approaches with ongoing monitoring and verification activities[^4][^6]. CPV programs typically integrate real-time process data, quality control results, and statistical analysis to continuously assess process performance and product quality. This approach enables manufacturers to detect process drift, validate process improvements, and maintain enhanced process understanding throughout the product lifecycle.\r\n\r\nThe implementation of effective CPV programs requires robust data management infrastructure and advanced analytics capabilities. Leading manufacturers employ automated data collection systems that capture process parameters from multiple sources and apply statistical models to assess process performance against established criteria[^6][^18]. These systems generate regular CPV reports that demonstrate ongoing process control and support regulatory compliance requirements.\r\n\r\n## Changeover Operations and Optimization\r\n\r\nChangeover operations represent critical transition periods in pharmaceutical manufacturing where production lines are prepared for different products or batches. Effective changeover management directly impacts equipment utilization, production throughput, and overall manufacturing efficiency. The pharmaceutical industry's emphasis on product quality and cross-contamination prevention adds complexity to changeover operations, requiring extensive cleaning validation and documentation procedures.\r\n\r\n### Physical Changeover Process Management\r\n\r\nThe physical execution of changeovers involves systematic procedures for equipment reconfiguration, cleaning operations, and system conditioning. Industry best practices emphasize standardized changeover procedures that specify required activities, sequence dependencies, and completion criteria[^1][^2]. Leading manufacturers implement visual management systems that provide clear guidance to operators and enable real-time tracking of changeover progress.\r\n\r\nCleaning validation represents a critical component of pharmaceutical changeovers, particularly when switching between different drug products. Modern cleaning processes increasingly utilize automated cleaning systems with validated procedures and real-time monitoring capabilities[^1]. Advanced implementations employ in-line analytical techniques such as Total Organic Carbon (TOC) analysis to verify cleaning effectiveness without requiring manual sampling and laboratory analysis, significantly reducing changeover time and improving process reliability.\r\n\r\n### Changeover Optimization Strategies\r\n\r\nPharmaceutical manufacturers employ various optimization strategies to minimize changeover time and maximize equipment utilization. Product sequencing optimization considers factors such as cleaning requirements, product potency, and allergen considerations to minimize the complexity and duration of changeover activities[^1][^12]. Advanced scheduling systems utilize mathematical optimization models to determine optimal production sequences that balance changeover efficiency with other production constraints.\r\n\r\nDigital twin technology has emerged as a powerful tool for changeover optimization, enabling manufacturers to simulate different changeover scenarios and identify improvement opportunities[^1][^17]. These virtual models incorporate equipment characteristics, cleaning procedures, and historical performance data to predict changeover durations and evaluate optimization strategies before implementation.\r\n\r\n## Equipment and Automation Lifecycle Management\r\n\r\nThe management of equipment and automation systems throughout their operational lifecycle represents a fundamental capability for pharmaceutical manufacturers. Effective lifecycle management ensures equipment reliability, regulatory compliance, and optimal return on capital investments while supporting continuous improvement initiatives. The increasing complexity of pharmaceutical manufacturing equipment and automation systems requires sophisticated management approaches that integrate technical, regulatory, and commercial considerations.\r\n\r\n### Equipment Specification and Planning Processes\r\n\r\nThe specification and planning of pharmaceutical manufacturing equipment involves comprehensive analysis of user requirements, technical specifications, and regulatory constraints. Leading manufacturers employ systematic approaches that begin with User Requirement Specifications (URS) that define functional and performance requirements based on production needs and regulatory expectations[^1][^11]. Technical specifications translate these requirements into detailed equipment designs that consider current and future production requirements, technology capabilities, and facility constraints.\r\n\r\nFactory planning activities integrate equipment specifications with facility design, utility requirements, and workflow optimization considerations. Modern planning approaches utilize digital factory modeling tools that enable manufacturers to simulate production flows, evaluate layout alternatives, and optimize facility utilization before construction[^1][^16]. These tools support decision-making about equipment placement, material flow systems, and automation integration while considering regulatory requirements and operational efficiency objectives.\r\n\r\n### Global Equipment Database and Standardization\r\n\r\nPharmaceutical manufacturers typically maintain comprehensive equipment databases that provide centralized access to equipment information across global manufacturing networks. These databases include equipment specifications, performance data, qualification documentation, and maintenance histories[^1]. Advanced implementations integrate with other enterprise systems to provide real-time equipment status information and support cross-functional decision-making processes.\r\n\r\nEquipment standardization initiatives aim to reduce complexity and improve operational efficiency across multiple manufacturing sites. Leading companies implement preferred equipment vendor programs and standardized equipment specifications that facilitate technology transfer, reduce validation requirements, and optimize maintenance operations[^1][^19]. Standardization efforts often extend to automation platforms, human-machine interfaces, and data management systems to create consistent operational environments across global manufacturing networks.\r\n\r\n### Equipment Tracking and Status Management\r\n\r\nModern pharmaceutical facilities employ sophisticated tracking systems that provide real-time visibility into equipment location and operational status. These systems typically utilize technologies such as RFID tags, NFC devices, or GPS tracking to automatically monitor movable equipment and format parts[^1]. Automated tracking systems reduce manual effort required for equipment management while ensuring accurate information for production planning and regulatory compliance purposes.\r\n\r\nEquipment status management systems integrate tracking data with other operational information to provide comprehensive equipment visibility. These systems typically include capabilities for managing equipment calibration schedules, maintenance requirements, and qualification status[^1][^11]. Advanced implementations provide predictive maintenance capabilities that utilize equipment performance data and machine learning algorithms to optimize maintenance scheduling and prevent unplanned downtime.\r\n\r\n## Data Management and Analytics Operations\r\n\r\nThe effective utilization of process and product data has become a critical differentiator in modern pharmaceutical manufacturing operations. Companies that successfully leverage data analytics capabilities achieve improved process understanding, enhanced quality control, and accelerated decision-making processes. The proliferation of connected manufacturing equipment and digital systems has created unprecedented opportunities for data-driven optimization while introducing new challenges related to data quality, integration, and governance.\r\n\r\n### Data Integration and Accessibility Infrastructure\r\n\r\nModern pharmaceutical manufacturers implement comprehensive data infrastructure that enables seamless integration of information from multiple sources throughout the manufacturing process. These systems typically incorporate data from manufacturing equipment, laboratory information management systems (LIMS), manufacturing execution systems (MES), and quality management systems into centralized data platforms[^1][^6]. Advanced data architectures utilize data lake technologies that can accommodate structured and unstructured data while providing flexible access for various analytical applications.\r\n\r\nSelf-service analytics platforms have become increasingly important for enabling business users to access and analyze manufacturing data without requiring extensive IT support. These platforms provide user-friendly interfaces that allow quality engineers, process engineers, and production managers to perform routine analyses and generate insights independently[^1]. The democratization of data access enables faster decision-making and more effective utilization of manufacturing intelligence throughout the organization.\r\n\r\n### Advanced Analytics and Continuous Process Verification\r\n\r\nThe implementation of advanced analytics capabilities enables pharmaceutical manufacturers to extract actionable insights from large volumes of manufacturing data. Machine learning algorithms and statistical modeling techniques are increasingly utilized to identify process patterns, predict quality outcomes, and optimize process parameters[^6][^17]. These capabilities support enhanced process understanding that extends beyond traditional statistical process control approaches.\r\n\r\nContinuous Process Verification programs leverage advanced analytics to provide ongoing assessment of process performance and product quality. Modern CPV implementations utilize automated data collection and analysis systems that continuously monitor process performance against established criteria and generate alerts when intervention is required[^1][^4]. Multi-site CPV programs enable manufacturers to compare process performance across facilities and identify optimization opportunities through benchmarking and best practice sharing.\r\n\r\n### Automated Documentation and Regulatory Reporting\r\n\r\nPharmaceutical manufacturers increasingly utilize automated systems to generate regulatory documentation and compliance reports from manufacturing data. These systems leverage integrated data platforms to automatically compile batch records, quality summaries, and regulatory submissions[^1]. Automated documentation generation significantly reduces manual effort while improving data consistency and reducing the risk of transcription errors.\r\n\r\nReal-time deviation and CAPA management systems utilize manufacturing data and analytics to accelerate investigation processes and improve resolution times. Advanced implementations employ machine learning algorithms to identify potential root causes and recommend corrective actions based on historical patterns and process knowledge[^1]. These capabilities enable faster resolution of quality issues while improving the effectiveness of continuous improvement efforts.\r\n\r\n## Workplace and Operator Support Systems\r\n\r\nThe empowerment of manufacturing operators through effective knowledge management and digital support systems represents a critical success factor for modern pharmaceutical operations. As manufacturing processes become increasingly complex and regulatory requirements continue to evolve, organizations must provide comprehensive support systems that enable operators to perform their roles effectively while maintaining compliance with quality standards. The integration of digital technologies and artificial intelligence capabilities has created new opportunities to enhance operator capabilities and improve operational outcomes.\r\n\r\n### Knowledge Management and Training Infrastructure\r\n\r\nComprehensive knowledge management systems serve as the foundation for effective operator support in pharmaceutical manufacturing environments. These systems typically integrate Standard Operating Procedures (SOPs), Master Batch Records (MBRs), technical documentation, and training materials into centralized platforms that provide easy access to current information[^1][^3]. Advanced knowledge management implementations utilize intelligent search capabilities and recommendation engines to help operators quickly locate relevant information based on their specific roles and current activities.\r\n\r\nDigital training programs have become increasingly sophisticated, incorporating multimedia content, interactive simulations, and virtual reality experiences to enhance learning effectiveness. Leading manufacturers implement competency-based training systems that track individual operator qualifications and automatically assign required training modules based on role requirements and career development objectives[^1]. These systems integrate with shift planning tools to ensure adequate coverage of qualified personnel while supporting continuous skill development initiatives.\r\n\r\n### AI-Powered Operational Assistance\r\n\r\nArtificial intelligence technologies are increasingly deployed to provide real-time support to manufacturing operators. AI-powered assistant systems can answer questions about procedures, provide troubleshooting guidance, and offer contextual recommendations based on current process conditions[^1]. These systems leverage natural language processing capabilities to understand operator queries and provide relevant responses based on extensive knowledge bases that include SOPs, equipment manuals, and historical incident data.\r\n\r\nProcess CoPilot systems represent an emerging category of AI assistance that provides proactive guidance and recommendations to operators during manufacturing activities. These systems monitor process conditions in real-time and alert operators to potential issues or optimization opportunities[^1]. Advanced implementations can predict likely outcomes of different operational decisions and recommend optimal actions based on current process state and historical performance data.\r\n\r\n### Digital Onboarding and Global Support Systems\r\n\r\nDigital onboarding programs provide structured pathways for new employees to acquire necessary knowledge and qualifications efficiently. These programs typically include role-based learning paths that automatically assign relevant training modules, SOPs, and assessment requirements[^1]. Digital signature capabilities ensure compliance with regulatory requirements while providing audit trails for training completion and competency verification.\r\n\r\nGlobal pharmaceutical manufacturers face unique challenges related to language barriers and cultural differences across international operations. Real-time translation systems integrated with manufacturing information systems enable operators to access procedures and guidance in their preferred languages[^1]. These systems support consistent operational practices across global manufacturing networks while accommodating local language preferences and regulatory requirements.\r\n\r\n## Conclusion\r\n\r\nThe examination of typical practices across pharmaceutical manufacturing operations reveals an industry in transition toward increasingly digital, data-driven, and integrated operational models. The six core process areas analyzed demonstrate consistent themes around automation, real-time monitoring, standardization, and continuous improvement that reflect the industry's commitment to quality, efficiency, and regulatory compliance. Modern pharmaceutical manufacturers are successfully leveraging advanced technologies including artificial intelligence, machine learning, and digital twin capabilities to enhance traditional manufacturing practices while maintaining the rigorous quality standards required for pharmaceutical production.\r\n\r\nThe evolution toward Pharma 4.0 manufacturing paradigms is evident across all process areas, with particular emphasis on data integration, automated decision-making, and predictive analytics capabilities[^6][^15]. However, the analysis also reveals that successful digital transformation requires careful attention to change management, operator training, and system integration challenges. Organizations that effectively balance technological advancement with human-centered design principles are achieving superior operational outcomes while maintaining compliance with evolving regulatory expectations.\r\n\r\nLooking forward, the continued advancement of pharmaceutical manufacturing practices will likely be characterized by further integration of digital technologies, enhanced real-time decision-making capabilities, and more sophisticated approaches to quality assurance and regulatory compliance. The industry's investment in continuous process verification, automated documentation, and AI-powered operational support systems positions pharmaceutical manufacturers to achieve higher levels of operational excellence while better serving patient needs through reliable, high-quality drug product supply.\r\n\r\n<div style=\"text-align: center\">\u2042</div>\r\n\r\n[^1]: paste.txt\r\n\r\n[^2]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11360752/\r\n\r\n[^3]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3122044/\r\n\r\n[^4]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4759219/\r\n\r\n[^5]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4415584/\r\n\r\n[^6]: https://ispe.org/pharmaceutical-engineering/march-april-2021/data-science-pharma-40tm-drug-development-production\r\n\r\n[^7]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9425710/\r\n\r\n[^8]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3980979/\r\n\r\n[^9]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11864096/\r\n\r\n[^10]: https://cyberplan.it/en/production-planning-in-the-pharmaceutical-industry/\r\n\r\n[^11]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4399016/\r\n\r\n[^12]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8802271/\r\n\r\n[^13]: https://pharmabossbd.com/role-of-ppic-in-pharmaceuticals/\r\n\r\n[^14]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8926382/\r\n\r\n[^15]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8466472/\r\n\r\n[^16]: https://discover.3ds.com/optimize-production-flows-and-batch-release-pharmaceutical-manufacturing\r\n\r\n[^17]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11350267/\r\n\r\n[^18]: https://pmc.ncbi.nlm.nih.gov/articles/PMC5746753/\r\n\r\n[^19]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8453788/\r\n\r\n[^20]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6713335/\r\n\r\n[^21]: https://www.semanticscholar.org/paper/5a52c2fe5890fcad648727763d529f2e51807081\r\n\r\n[^22]: https://www.semanticscholar.org/paper/e653b5aff612aa7ee454eac4e80c39e0661b37b0\r\n\r\n[^23]: https://www.semanticscholar.org/paper/debebabed32d85133307bb7c099364f6995fdf22\r\n\r\n[^24]: https://www.semanticscholar.org/paper/c5880fa86b7c30a2fb67d629e6dba6ffc9f13282\r\n\r\n[^25]: https://www.semanticscholar.org/paper/e76cf4802e58fba17da90ea81959060814ba3a99\r\n\r\n[^26]: https://www.semanticscholar.org/paper/2049cee1a867a87bd06fbac7c980214265c888c4\r\n\r\n[^27]: https://www.semanticscholar.org/paper/d2eb1780185bd2e3ca41b9b86ad116afdbbffd7e\r\n\r\n[^28]: https://www.semanticscholar.org/paper/b76196e6e86dbb0b2d28922bb42544708f78fe6a\r\n\r\n[^29]: https://www.semanticscholar.org/paper/49ac02aa0a3aa8d2a11624c96bedc99fd83f0446\r\n\r\n[^30]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6736431/\r\n\r\n[^31]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4037495/\r\n\r\n[^32]: https://www.linkedin.com/pulse/production-planning-control-pharmaceutical-industry-kaustubh-bhagat\r\n\r\n[^33]: https://www.sciencedirect.com/science/article/pii/S0098135423000327\r\n\r\n[^34]: https://pharmuni.com/2024/10/30/strategic-planning-in-pharmaceutical-production/\r\n\r\n[^35]: https://www.aimms.com/story/long-range-capacity-planning-with-network-design-technology/\r\n\r\n[^36]: https://scw.ai/news/product/scheduling-optimization/\r\n\r\n[^37]: https://www.planettogether.com/blog/strategic-considerations-for-long-term-production-planning-in-pharmaceutical-manufacturing\r\n\r\n[^38]: https://www.semanticscholar.org/paper/7b8c1721587f365c154ba5cab84f0921de68ca00\r\n\r\n[^39]: https://www.semanticscholar.org/paper/7a97413bc149c9051e1be6de42703c9334f94eb2\r\n\r\n[^40]: https://www.semanticscholar.org/paper/8fe1d48e7282241849cc5e44e6049b8264ad222e\r\n\r\n[^41]: https://www.semanticscholar.org/paper/bafeec65cc85b998031a39547f3db12183735fa1\r\n\r\n[^42]: https://www.semanticscholar.org/paper/2414abca3ec3ce69e458e59569007e3c70793f13\r\n\r\n[^43]: https://www.semanticscholar.org/paper/fb9e2ff1630971bba2efe931988e15f2099e310f\r\n\r\n[^44]: https://www.semanticscholar.org/paper/20cb460d6c99b138c331776b5fc39a9ae519d617\r\n\r\n[^45]: https://www.semanticscholar.org/paper/f7abee9590bc7955b3e45bce97ad42cfd20cb8c4\r\n\r\n[^46]: https://www.semanticscholar.org/paper/d50587cadb27a37073708b31b0da832fa0993fb9\r\n\r\n[^47]: https://www.semanticscholar.org/paper/1d07b633bae5c1b57ca21c00fdc166d3da3e1956\r\n\r\n[^48]: https://www.cin7.com/blog/production-planning-key-concepts-and-best-practices/\r\n\r\n[^49]: https://www.epicflow.com/blog/a-guide-to-production-planning-and-scheduling-for-manufacturing/\r\n\r\n[^50]: https://amplelogic.com/best-practices-for-implementing-qc-planning-scheduling-in-pharma/\r\n\r\n[^51]: https://kanboapp.com/en/work-coordination/mastering-pharmaceutical-production-planning-navigating-challenges-with-strategic-expertise/\r\n\r\n[^52]: https://www.semanticscholar.org/paper/046de0df4562625a14998f96601a28475a05e4bb\r\n\r\n[^53]: https://arxiv.org/abs/2411.15871\r\n\r\n[^54]: https://www.semanticscholar.org/paper/0e3c656d038d138e8c304b6317e2d16cb5462c9c\r\n\r\n[^55]: https://arxiv.org/abs/2501.12407\r\n\r\n[^56]: https://www.semanticscholar.org/paper/04ac9897181092e04360e8966d032d7bd40f1371\r\n\r\n[^57]: https://arxiv.org/abs/2111.08759\r\n\r\n[^58]: https://www.semanticscholar.org/paper/6f9f53f9f200ed9a8dcde7da4b0356c7977860c4\r\n\r\n[^59]: https://www.semanticscholar.org/paper/6b953efdfa924a2bd29faa592a90c0dab920587e\r\n\r\n[^60]: https://arxiv.org/abs/2301.05768\r\n\r\n[^61]: https://www.semanticscholar.org/paper/3ac49a664d425400bed151644f36689a6b10f77f\r\n\r\n[^62]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6706913/\r\n\r\n[^63]: https://plm.sw.siemens.com/de-DE/opcenter/execution/pharma/\r\n\r\n[^64]: https://www.process.vogel.de/batchprozesse-in-pharma-food-und-feinchemie-a-ed97b6544a00ae7d0d0254d749cfd8ff/\r\n\r\n[^65]: https://www.batchmaster.co.in/blog/improve-batch-processing-with-pharma-erp-software\r\n\r\n[^66]: https://www.koerber-pharma.com/en/glossary/batch-record\r\n\r\n[^67]: https://www.leucine.io/mes-blogs/batch-production-in-pharma\r\n\r\n[^68]: https://www.sw.siemens.com/en-US/technology/master-batch-record/\r\n\r\n[^69]: https://www.mt.com/us/en/home/applications/L1_AutoChem_Applications/L2_PAT.html\r\n\r\n[^70]: https://zamann-pharma.com/glossary/pharmaceutical-batch-release/\r\n\r\n[^71]: https://accevosystems.com/glossary/mbr-master-batch-record/\r\n\r\n[^72]: https://www.bruker.com/de/products-and-solutions/process-analytical-technology.html\r\n\r\n[^73]: https://www.semanticscholar.org/paper/23476c34f50a34531f138f2f53e732ecc69941a4\r\n\r\n[^74]: https://www.semanticscholar.org/paper/6086d765ccaa19da33cca5bebdbdad203516dc1d\r\n\r\n[^75]: https://www.semanticscholar.org/paper/5c9f86fec311672b17351f04a118aa8424769e7f\r\n\r\n[^76]: https://www.semanticscholar.org/paper/618a7db27bbbacd49a4a82e30a6740cf56d7fd9f\r\n\r\n[^77]: https://www.semanticscholar.org/paper/c49768720e9685517f0de801d0ef85a543d1bbbe\r\n\r\n[^78]: https://www.semanticscholar.org/paper/bfd80f1e15330e9ff29a9012015a89a20146bd7a\r\n\r\n[^79]: https://www.semanticscholar.org/paper/c05441615cf7ab2e98a6436c87a6daa1ee3e45fa\r\n\r\n[^80]: https://www.semanticscholar.org/paper/267c9df3baf0c15a3194598233b9876d675a503f\r\n\r\n[^81]: https://www.semanticscholar.org/paper/35187a7e40f1979af2636e64d9fb8fdf2a074ccc\r\n\r\n[^82]: https://www.semanticscholar.org/paper/1a3dfb87a6efc31a92bede40352849c7cd377b2b\r\n\r\n[^83]: https://www.porsche-consulting.com/de/de/publikation/automation-production-planning-enhanced-ai\r\n\r\n[^84]: https://www.agendrix.com/blog/pharmacy-work-schedule-examples\r\n\r\n[^85]: https://www.orsoft.net/en/industries/life-sciences-pharma/strategical-planning-in-the-pharmaceutical-industry/\r\n\r\n[^86]: https://www.planettogether.com/blog/implementation-of-advanced-scheduling-algorithms-for-dynamic-production-planning-in-pharmaceutical-manufacturing\r\n\r\n[^87]: https://www.planettogether.com/blog/real-time-scheduling-optimization-enhancing-efficiency-in-pharmaceutical-manufacturing\r\n\r\n[^88]: https://www.semanticscholar.org/paper/3f74694d2789e5bf4d38dc927dfad4225c8099ad\r\n\r\n[^89]: https://www.semanticscholar.org/paper/a42db6d6ea5d54e53fb1f4e87f0c528c0a193b75\r\n\r\n[^90]: https://www.semanticscholar.org/paper/3f95a5e3b11974299d5ac8927d7bb045588f1ba9\r\n\r\n[^91]: https://www.semanticscholar.org/paper/80b7754fd8febc836219770dcdb1358c54a7d27d\r\n\r\n[^92]: https://www.semanticscholar.org/paper/f0d62aaa35aea8e77cee9c78f39ffc6285aa38fd\r\n\r\n[^93]: https://www.semanticscholar.org/paper/d6172ac45a8313a1a5cffc7a2ba4f10cf3dd4067\r\n\r\n[^94]: https://www.semanticscholar.org/paper/9618bdc6525b7a7b42ab721b2ca98bd38dbc0b59\r\n\r\n[^95]: https://www.semanticscholar.org/paper/cfa3cdcdbbdddd8cee78655f9f31f43ec119edd9\r\n\r\n[^96]: https://arxiv.org/abs/1903.08609\r\n\r\n[^97]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4348129/\r\n\r\n[^98]: https://arxiv.org/pdf/2501.10895.pdf\r\n\r\n[^99]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8130218/\r\n\r\n[^100]: http://arxiv.org/pdf/2502.09527.pdf\r\n\r\n[^101]: https://arxiv.org/pdf/2310.08721.pdf\r\n\r\n[^102]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8376725/\r\n\r\n[^103]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11471903/\r\n\r\n[^104]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9443430/\r\n\r\n[^105]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6733292/\r\n\r\n[^106]: https://pmc.ncbi.nlm.nih.gov/articles/PMC10339337/\r\n\r\n[^107]: https://pmc.ncbi.nlm.nih.gov/articles/PMC5575510/\r\n\r\n[^108]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3977072/\r\n\r\n[^109]: https://www.aspentech.com/en/resources/on-demand-webinars/riding-the-rollercoaster-of-pharma-production-scheduling\r\n\r\n[^110]: https://www.spinnakerls.com/post/navigating-uncertainty-how-scenario-planning-empowers-fp-a-in-pharma-and-biotech\r\n\r\n[^111]: https://www.dataparc.com/manufacturing-data-integration/",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 8,
        "name": "Performance Management",
        "description": "# Performance Management Framework for Pharmaceutical Manufacturing: A Comprehensive Analysis of Industry Research Requirements\r\n\r\nThis analysis examines a detailed research briefing that outlines the scope and methodology for investigating performance management practices within pharmaceutical manufacturing. The document presents a structured framework comprising seven distinct process steps, each designed to capture the essential elements of how pharmaceutical companies typically create value through systematic performance management approaches.\r\n\r\n## Core Research Framework and Methodology\r\n\r\nThe research briefing establishes a clear mandate to focus on \"what is typically done\" in the pharmaceutical industry for each performance management process step, emphasizing fundamental process mechanics and principles rather than specific technological implementations. This approach recognizes that while modern digital tools often support these processes, the underlying organizational structures, methodologies, roles, and standard operating procedures represent the true value-generating activities that transcend specific technological solutions.\r\n\r\nThe framework explicitly acknowledges that digital enablers can be mentioned as supportive elements, but the primary emphasis remains on understanding common methodologies, organizational structures, roles, standard operating procedures, and the underlying tasks and activities that generate value. This balanced approach ensures that the research captures both traditional practices and modern enhancements without being overly focused on technology-specific solutions that may not be universally applicable across the industry.\r\n\r\n## Strategic Goal Translation and Target Setting Processes\r\n\r\nThe first core process step addresses how pharmaceutical manufacturers typically translate high-level strategic company goals into actionable, unit-specific targets. This foundational element of performance management faces several significant challenges, including securing commitment from all involved parties, the absence of standardized approaches for goal breakdown, lack of focus due to too many competing priorities, and the complex co-dependencies that exist between various organizational goals.\r\n\r\nThe research framework identifies the need to understand common methodologies and structured approaches employed for goal breakdown and target setting, specifically mentioning frameworks such as Balanced Scorecard, Objectives and Key Results (OKRs), and Hoshin Kanri/Policy Deployment. These established methodologies provide pharmaceutical companies with systematic approaches to ensure that strategic objectives are effectively cascaded throughout the organization while maintaining alignment and avoiding conflicts between different departmental or functional goals.\r\n\r\nCross-functional commitment and buy-in represent critical success factors in this process, requiring pharmaceutical companies to develop sophisticated approaches for securing engagement across different departments and business units. The research emphasizes understanding how organizations typically identify, prioritize, and manage the interdependencies between various goals to ensure alignment and avoid conflicts that could undermine overall performance.\r\n\r\n## Key Performance Indicator Development and Cascading Systems\r\n\r\nThe second process step focuses on the definition and cascading of Key Performance Indicators (KPIs) based on realistic baselines and strategic relevance. This process aims to establish a harmonized framework that ensures transparency, avoids metric overload, and supports all critical organizational goals with measurable indicators. The challenges identified in this area include the risk of setting non-achievable targets, the potential for too many KPIs that create confusion rather than clarity, and standardization issues across different departments or operational sites.\r\n\r\nPharmaceutical companies must navigate the complex task of ensuring that KPIs are realistic, measurable, and strategically relevant while avoiding both an overload of metrics and the omission of critical performance areas. The research framework emphasizes understanding how organizations typically manage potential conflicts or redundancies between KPIs and the methods used to ensure harmonization and comparability across different departments or manufacturing sites.\r\n\r\nThe cascading process represents a particularly critical aspect of KPI management, requiring clear methodologies for ensuring transparency and alignment from strategic to operational levels. This process must address the unique challenges of pharmaceutical manufacturing, including launch readiness initiatives and other strategic projects that require specialized performance indicators.\r\n\r\n## Performance Monitoring and Dialogue Structures\r\n\r\nThe third core process step examines how pharmaceutical manufacturers typically monitor performance and track KPIs through structured dialogue processes. This element of the framework recognizes that effective performance management requires more than just data collection; it demands systematic approaches to ensure data quality, consistency, and accessibility across the organization.\r\n\r\nThe research framework identifies the need to understand common structures and frequencies of performance dialogues at different organizational levels, including daily stand-ups, weekly reviews, and monthly business reviews. These dialogues serve as critical touchpoints for discussing performance deviations, identifying root causes, and initiating corrective actions based on real-time or near-real-time data analysis.\r\n\r\nEffective monitoring systems in pharmaceutical manufacturing must address significant challenges including inconsistent performance dialogues, varying data resolution across business units, manual KPI deviation detection processes, and difficulties in retrieving data from complex enterprise systems. The desired state envisions standardized KPI definitions, reliable real-time data for dialogues, automated deviation detection, and institutionalized performance dialogue processes that enable rapid, data-driven gap closure.\r\n\r\n## Continuous Improvement and Gap Closure Methodologies\r\n\r\nThe fourth process step addresses how pharmaceutical companies typically analyze identified performance gaps, determine root causes, and implement corrective or improvement actions. This aspect of performance management represents the critical link between monitoring activities and actual performance improvement, requiring sophisticated approaches to transform data insights into actionable improvements.\r\n\r\nThe research framework emphasizes understanding common methodologies for developing, selecting, and implementing corrective actions, specifically mentioning established frameworks such as Plan-Do-Check-Act (PDCA) and A3 problem-solving approaches. These structured methodologies provide pharmaceutical companies with systematic approaches to ensure that improvement efforts are both effective and sustainable over time.\r\n\r\nForward-looking or predictive KPIs represent an advanced aspect of this process, enabling organizations to anticipate and prevent future performance issues rather than simply reacting to problems after they occur. The research seeks to understand how pharmaceutical companies typically leverage performance data to identify opportunities for continuous improvement and innovation beyond just addressing immediate performance deficits.\r\n\r\n## Enabling Processes: Data, Culture, and Training\r\n\r\nThe framework identifies three critical enabling processes that support the core performance management activities. The first enabling process addresses data collection and analysis, recognizing that effective performance management requires unified, real-time data foundations that enable automated, AI-supported analysis. This process must overcome significant challenges including the absence of single sources of truth, lack of harmonized data foundations, and the prevalence of manual data entry processes that limit scalability and reliability.\r\n\r\nCultural change management represents the second enabling process, acknowledging that performance management success depends heavily on fostering a data-driven, performance-oriented mindset across all organizational levels. This process addresses fundamental challenges including resistance to change, lack of data literacy among employees, and inconsistent management support for performance-oriented behaviors.\r\n\r\nThe third enabling process focuses on employee qualification and development, recognizing that effective performance management requires tailored training approaches that build both technical capabilities and cultural alignment. This process must address challenges including generic training approaches that fail to meet specific role requirements and the absence of comprehensive performance management resources that support practical application.\r\n\r\n## Research Methodology and Expected Outcomes\r\n\r\nThe research briefing establishes clear expectations for a comprehensive, structured report that details the typical steps, tasks, and processes observed in pharmaceutical manufacturing for each identified performance management process step. The methodology emphasizes addressing specific research focus questions while providing clear understanding of how value is typically created in each process area.\r\n\r\nThe approach balances comprehensiveness with practicality, avoiding excessive detail on niche digital tools unless they are intrinsically linked to widely adopted fundamental processes. This balanced approach ensures that the research output will be both academically rigorous and practically applicable for pharmaceutical companies seeking to improve their performance management capabilities.\r\n\r\n## Conclusion\r\n\r\nThis research framework represents a comprehensive approach to understanding performance management practices in pharmaceutical manufacturing, addressing both core operational processes and critical enabling capabilities. The structured methodology ensures systematic investigation of industry practices while maintaining focus on value-generating activities that transcend specific technological implementations. The framework's emphasis on common practices, methodologies, and organizational approaches provides a solid foundation for developing industry-wide insights that can guide performance management improvements across the pharmaceutical manufacturing sector. The integration of core processes with enabling capabilities recognizes the complex, interconnected nature of effective performance management systems and provides a holistic view of the organizational capabilities required for sustained performance excellence.",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 9,
        "name": "Quality Assurance",
        "description": "# Quality Assurance Processes in Pharmaceutical Manufacturing: A Comprehensive Analysis of Critical Systems and Practices\r\n\r\nThis report examines the fundamental quality assurance processes that underpin pharmaceutical manufacturing operations, analyzing eight critical process areas that ensure product safety, efficacy, and regulatory compliance. The analysis reveals that modern pharmaceutical quality assurance operates through interconnected systems encompassing documentation management, risk assessment, contamination control, validation activities, and product release mechanisms. These processes collectively create a robust framework that transforms raw materials into safe, effective medicines while maintaining stringent regulatory standards throughout the product lifecycle[^1].\r\n\r\n## Quality Assurance Enabling Processes\r\n\r\nQuality assurance enabling processes form the foundational infrastructure that supports all pharmaceutical manufacturing activities through systematic documentation, training, and data integrity controls[^1]. These processes establish the basic operational framework required for Good Manufacturing Practice (GxP) compliance and ensure that all personnel possess the necessary competencies to perform their roles effectively. The scope of these activities extends beyond simple documentation to encompass comprehensive learning management systems, external partner integration, and continuous performance monitoring.\r\n\r\n### Standard Operating Procedures and Documentation Management\r\n\r\nStandard Operating Procedures (SOPs) represent the cornerstone of pharmaceutical quality systems, providing detailed, step-by-step instructions that govern every critical operation in pharmaceutical manufacturing[^1][^5]. These documents undergo continuous lifecycle management involving writing, reviewing, updating, approving, and distributing procedures to ensure consistency and compliance across all operations. SOP management refers to the systematic process of creating, implementing, and maintaining these procedures, with proper management helping ensure all procedures are adequately documented, regularly reviewed, and effectively communicated to relevant personnel[^5].\r\n\r\nThe pharmaceutical industry relies heavily on validated and documented methods that serve as the base of process activities, offering personnel clear step-by-step guidance for executing specific tasks to ensure compliance of company processes to internal policies and external regulations[^5]. Having well-defined and well-maintained SOPs helps pharmaceutical companies consistently carry out routine operations, improve process efficiency, achieve uniform performance, and onboard new employees effectively[^5]. Every department within pharmaceutical organizations maintains its own set of SOPs, creating a comprehensive network of procedural documentation that spans all operational areas.\r\n\r\n### Employee Training and Competency Management\r\n\r\nGood Manufacturing Practice (GMP) training represents a structured program designed to educate employees in the pharmaceutical, biotechnology, and life sciences industries on the regulatory and quality requirements necessary for producing safe and effective products[^6]. GMP training ensures compliance with industry standards and regulatory guidelines set by organizations such as the FDA, EMA, and WHO, establishing programs to train all personnel on relevant SOPs, Good Manufacturing Practices, and other quality requirements[^1][^6].\r\n\r\nThe training process involves assigning training based on job roles, tracking completion, and assessing understanding to ensure that every individual possesses the competencies required for their specific responsibilities[^1]. GMP training is essential for ensuring product quality, patient safety, and regulatory compliance, as employees may inadvertently violate GMP regulations without proper training, leading to product recalls, regulatory fines, or legal consequences[^6]. Key benefits include ensuring consistency in product quality and safety, reducing risks of contamination and errors, meeting regulatory requirements to avoid penalties, enhancing employee competency and confidence, and improving overall operational efficiency[^6].\r\n\r\n### Data Integrity and ALCOA Principles\r\n\r\nData integrity implementation ensures that all generated and recorded data from manufacturing, quality control, and other operations adheres to ALCOA principles, guaranteeing that information is accurate, complete, consistent, enduring, and available[^1][^4]. The ALCOA acronym, used since the 1990s as part of Good Documentation Practices, outlines essential data integrity requirements that data must possess: Attributable to the person generating the data, Legible and permanent, Contemporaneous, Original record (or certified true copy), and Accurate[^4].\r\n\r\nData integrity has become a fundamental topic in GxP environments, with regulatory authorities particularly concerned about its application to medicinal products and GxP-related activities[^4]. The concept guarantees the traceability and security of data throughout all pharmaceutical processes and systems, ensuring the reliability of information, identification and traceability of all changes, and helping avoid losses while protecting historical records and inventories[^4]. As part of GxP requirements, the FDA has defined essential principles to be implemented and followed to assure the integrity of both paper-based and electronic data[^4].\r\n\r\n## Product-Related Quality Assurance Enabling Processes\r\n\r\nProduct-related quality assurance enabling processes focus specifically on managing changes and risks associated with pharmaceutical products throughout their lifecycle, ensuring that any modifications are carefully assessed and that potential quality risks are identified and controlled proactively[^1]. These processes operate as essential components of pharmaceutical quality management systems, providing systematic approaches to change control, annual quality reviews, and risk management activities that maintain product integrity over time.\r\n\r\n### Change Control and Risk Management\r\n\r\nChange control represents a formal system for proposing, evaluating, approving, implementing, and reviewing any planned modifications to premises, equipment, utilities, processes, materials, analytical methods, or product formulations that could impact product quality[^1]. This systematic approach ensures that changes are controlled and assessed for impact, preventing unintended consequences that might compromise product safety or efficacy. The change control process requires comprehensive documentation and cross-functional review to evaluate potential risks and benefits associated with proposed modifications.\r\n\r\nQuality risk management implements a systematic process to identify, assess, control, communicate, and review risks to the quality of pharmaceutical products across their lifecycle[^1]. This proactive approach helps prevent potential issues before they manifest as quality problems, aligning with broader industry trends toward preventive rather than reactive quality management. Risk assessment tools and methodologies enable pharmaceutical companies to overcome various quality challenges covering development, production, distribution, inspection, and reporting of review procedures for drug substances, drug products, and biological products at every stage of their lifecycle[^18].\r\n\r\n### Annual Product Quality Reviews\r\n\r\nAnnual Product Quality Reviews (APQRs) represent a regulatory requirement under which pharmaceutical companies conduct yearly comprehensive evaluations of product quality data to confirm consistency, identify trends, and spot areas for continuous improvement[^1][^7]. According to 21 CFR 211.180 (e), drug product manufacturing companies must evaluate written records for quality standards of each drug product at least once annually, with records evaluated to determine the need for changes in drug product specification, manufacturing, or control procedures[^7].\r\n\r\nThe APQR process involves regularly compiling and reviewing comprehensive sets of product quality data including batch records, complaint data, stability data, deviations, and out-of-specification results[^1]. For products manufactured by external partners such as Contract Manufacturing Organizations (CMOs), their Product Quality Reviews (PQRs) are internalized and reviewed as part of the overall quality assessment[^1]. The review must cover a one-year rolling period that may differ from the calendar year, with manufacturers receiving an extendable timeline of three months beyond the product anniversary[^7].\r\n\r\nMulti-site data analysis represents an advanced component of product quality review activities, involving comparison of quality data across different manufacturing sites for the same product to identify global trends, differentiate site-specific issues from product-specific issues, and share best practices[^1]. This comprehensive approach ensures that quality insights gained at one location can be leveraged to improve operations globally, maximizing the value derived from quality data analysis activities.\r\n\r\n## Audit and Intelligence Systems\r\n\r\nAudit and intelligence systems provide continuous compliance oversight and quality assurance through systematic evaluation of internal operations and external partners, while maintaining current awareness of evolving regulatory and scientific requirements[^1]. These systems operate as critical oversight mechanisms that ensure ongoing compliance with Good Practice standards and enable proactive adaptation to changing regulatory landscapes that could impact pharmaceutical operations.\r\n\r\n### Quality Auditing and Compliance Assessment\r\n\r\nQuality auditing involves performing planned, systematic evaluations of internal departments such as manufacturing sites and quality control laboratories, as well as external suppliers and partners including raw material suppliers and Contract Manufacturing Organizations[^1]. These assessments evaluate compliance with GxP regulations, internal procedures, and contractual agreements, providing objective verification that operations meet established quality standards. The auditing process requires trained auditors who possess deep understanding of regulatory requirements and industry best practices.\r\n\r\nThe audit process extends beyond simple compliance checking to encompass comprehensive assessment of quality management systems, operational procedures, and documentation practices[^1]. Auditors evaluate not only whether procedures are being followed, but also whether those procedures are appropriate, effective, and aligned with current regulatory expectations. This comprehensive approach ensures that auditing activities provide meaningful insights that support continuous improvement rather than merely confirming basic compliance.\r\n\r\n### Regulatory and Pharmacopoeial Intelligence\r\n\r\nRegulatory and Pharmacopoeial Intelligence (RIN/PIN) involves continuously monitoring, analyzing, and disseminating information about new or updated pharmaceutical regulations and pharmacopoeial requirements from global health authorities and standard-setting bodies[^1]. This intelligence function assesses the impact of regulatory changes on internal operations and products, initiating necessary modifications to maintain compliance with evolving requirements. The intelligence process requires dedicated resources with expertise in regulatory affairs and change management.\r\n\r\nThe intelligence function extends beyond passive monitoring to include active analysis and impact assessment of regulatory developments[^1]. Intelligence specialists evaluate how new regulations or guideline changes might affect existing products, manufacturing processes, quality systems, or documentation requirements. This proactive approach enables pharmaceutical companies to adapt their operations before regulatory changes become mandatory, minimizing disruption and ensuring continued compliance.\r\n\r\n### Learning Integration and Continuous Improvement\r\n\r\nSystematic documentation, analysis, and communication of findings from internal audits and external regulatory inspections enables organizations to identify root causes of observations, ensure follow-up actions through Corrective and Preventive Action (CAPA) systems, and share lessons learned across the organization[^1]. This learning integration process transforms audit findings into actionable insights that drive systematic improvement rather than merely addressing isolated incidents.\r\n\r\nAutomated observation follow-up systems track and manage the resolution of findings identified during audits and inspections, including assigning corrective actions and verifying their timely completion[^1]. These systems ensure that audit findings receive appropriate attention and that corrective actions are implemented effectively, preventing recurrence of similar issues. The automation of follow-up processes improves efficiency and reduces the risk that important findings might be overlooked or inadequately addressed.\r\n\r\n## Non-conformance and Event Management\r\n\r\nNon-conformance and event management systems provide comprehensive mechanisms for identifying, investigating, and resolving quality issues that arise during pharmaceutical manufacturing and distribution operations[^1]. These systems ensure that deviations, out-of-specification results, complaints, and other quality events receive appropriate investigation and resolution, maintaining product quality and patient safety while driving continuous improvement through systematic root cause analysis and corrective action implementation.\r\n\r\n### Deviation and Out-of-Specification Management\r\n\r\nDeviation management encompasses formal processes for documenting, evaluating, investigating, and resolving any unplanned departure from approved procedures, specifications, or expected results, including equipment malfunctions and human errors[^1]. This systematic approach ensures that product quality is assessed and maintained even when unexpected events occur during manufacturing operations. The deviation management process requires thorough documentation and investigation to determine whether deviations impact product quality and what actions are necessary to prevent recurrence.\r\n\r\nOut-of-Specification (OOS) management specifically addresses analytical test results that do not meet pre-established acceptance criteria, involving laboratory investigations to determine causes and impacts, often leading to batch disposition decisions[^1]. OOS investigations require specialized expertise in analytical chemistry and statistics to determine whether results reflect true product quality issues or analytical errors. The investigation process must be thorough and scientifically sound to ensure that batch disposition decisions are based on accurate assessment of product quality.\r\n\r\n### Complaint and Market Action Management\r\n\r\nTechnical product complaint management involves receiving, documenting, investigating, and responding to complaints from the market related to the quality, safety, or efficacy of distributed products, including packaging defects and unexpected adverse effects[^1]. The complaint management process requires rapid response capabilities to assess whether complaints indicate broader quality issues that might affect other products or batches. Effective complaint management helps maintain customer confidence while providing early warning of potential quality problems.\r\n\r\nQuality issues and market action management addresses more severe or widespread quality problems that may necessitate corrective actions such as product recalls, withdrawals, or field alerts to protect public health[^1]. These activities require coordination between quality assurance, regulatory affairs, and supply chain management to ensure that appropriate actions are taken promptly when serious quality issues are identified. Market actions represent significant events that require careful management to protect patient safety while minimizing business disruption.\r\n\r\n### Investigation and CAPA Systems\r\n\r\nInvestigation management involves conducting thorough investigations into root causes of deviations, out-of-specification results, and complaints, gathering data, interviewing personnel, and applying investigation methodologies to identify fundamental reasons for issues[^1]. Effective investigations require skilled investigators who can analyze complex situations objectively and identify underlying causes rather than merely addressing symptoms. The investigation process must be systematic and thorough to ensure that corrective actions address actual root causes.\r\n\r\nCorrective and Preventive Action (CAPA) management represents a crucial component of quality assurance within the pharmaceutical industry, essential for maintaining product quality, safety, and regulatory compliance[^9]. CAPA systems function as dual-loop mechanisms that provide both reactive and proactive approaches aligned with continuous improvement principles[^9]. The CAPA process develops, implements, and tracks actions designed to correct identified problems (Corrective Action) and prevent their recurrence or prevent potential problems from occurring (Preventive Action), stemming from investigations, audits, or other quality events[^1].\r\n\r\n## Production and Process Control\r\n\r\nProduction and process control systems ensure that critical manufacturing environments and processes maintain tight control to prevent contamination and preserve product quality, particularly for sterile products that require the highest levels of environmental control[^1]. These systems implement comprehensive contamination control strategies, environmental monitoring programs, and incident management protocols that collectively ensure manufacturing operations consistently produce products meeting predetermined quality specifications.\r\n\r\n### Aseptic Manufacturing and Contamination Control\r\n\r\nAseptic manufacturing processes require quality oversight for manufacturing operations designed to prevent microbial contamination of sterile products such as injectables[^1]. These processes implement rigorous controls over personnel, environment, and equipment to maintain sterility throughout the manufacturing process. Aseptic manufacturing represents one of the most challenging aspects of pharmaceutical production, requiring specialized facilities, equipment, and personnel training to achieve and maintain the required sterility levels.\r\n\r\nContamination Control Strategy (CCS) development and management involves creating comprehensive plans outlining measures taken to prevent, detect, and control contamination including microbiological, particulate, and cross-contamination throughout the manufacturing process, particularly in sterile or highly controlled environments[^1]. The contamination control strategy integrates multiple elements including facility design, equipment selection, personnel training, environmental monitoring, and cleaning procedures to create a holistic approach to contamination prevention.\r\n\r\n### Environmental Monitoring and Control\r\n\r\nEnvironmental Monitoring (EM) programs routinely monitor microbial and particulate levels in controlled manufacturing environments such as cleanrooms through air sampling, surface sampling, and personnel monitoring to ensure they remain within specified limits[^1]. These monitoring programs provide real-time and trending data about environmental conditions that could impact product quality. Environmental monitoring data helps identify potential contamination sources and verify the effectiveness of contamination control measures.\r\n\r\nControl Strategy (CSS) definition and maintenance establishes and manages broader sets of controls for various manufacturing processes to ensure product quality attributes are consistently met, often involving definition of critical process parameters and critical quality attributes[^1]. The control strategy approach aligns with Quality by Design principles that emphasize understanding and controlling sources of variability that could impact product quality. Control strategies provide systematic frameworks for managing process variability and ensuring consistent product quality.\r\n\r\n### Incident Response and Management\r\n\r\nIncident monitoring related to contamination involves promptly detecting, investigating, and managing incidents such as microbial excursions in cleanrooms that could impact product quality, including identifying affected batches[^1]. Rapid incident response capabilities are essential for minimizing the impact of contamination events and preventing distribution of potentially compromised products. Incident management procedures must be well-defined and regularly practiced to ensure effective response when contamination events occur.\r\n\r\nThe incident management process requires coordination between multiple departments including manufacturing, quality assurance, quality control, and regulatory affairs to ensure that contamination events receive appropriate investigation and response[^1]. Effective incident management helps maintain product quality while minimizing production disruptions that could impact product availability. The process must balance the need for thorough investigation with the importance of maintaining production schedules and product supply.\r\n\r\n## Validation and Qualification\r\n\r\nValidation and qualification activities provide documented evidence that equipment, systems, and processes consistently produce results meeting predetermined specifications and quality attributes, ensuring fitness for purpose throughout the pharmaceutical manufacturing operation[^1]. These activities represent fundamental requirements for pharmaceutical manufacturing, providing the scientific and documented basis for confidence that manufacturing operations will consistently produce products of acceptable quality.\r\n\r\n### Equipment and Process Validation\r\n\r\nEquipment qualification involves documented verification that equipment is suitable for its intended purpose through Installation Qualification (IQ), Operational Qualification (OQ), and Performance Qualification (PQ) activities[^1]. Installation Qualification verifies that equipment is installed correctly according to manufacturer specifications and design requirements. Operational Qualification demonstrates that equipment operates according to its intended operational ranges and functions. Performance Qualification provides documented evidence that equipment consistently performs according to specifications under actual operating conditions.\r\n\r\nProcess validation provides documented evidence that manufacturing processes, operated within established parameters, consistently produce products meeting predetermined specifications and quality attributes[^1]. This involves initial validation activities that demonstrate process capability and ongoing verification through Continued Process Verification (CPV) that monitors process performance over time. Process validation integrates with Quality by Design approaches that emphasize process understanding and control based on scientific principles[^10].\r\n\r\n### Specialized Validation Activities\r\n\r\nCleaning validation provides documented evidence that approved cleaning procedures consistently remove residues from manufacturing equipment to below predetermined acceptance limits, preventing cross-contamination between products[^1]. Cleaning validation is particularly critical in multi-product manufacturing facilities where different products are manufactured using the same equipment. The validation process must demonstrate that cleaning procedures are effective under worst-case conditions and that residue levels are consistently below established limits.\r\n\r\nComputer System Validation (CSV) involves documented verification that computer systems used in GxP-regulated activities function as intended, maintain data integrity, and comply with regulatory requirements as part of System Life Cycle (SLC) management[^1]. Computer systems have become integral to pharmaceutical manufacturing operations, controlling everything from equipment operation to data management. CSV ensures that these systems operate reliably and maintain the integrity of data used for regulatory compliance and quality decisions.\r\n\r\nTransport qualification and validation ensures that product transportation conditions such as temperature and humidity are controlled and maintained within defined limits, especially for temperature-sensitive products, to preserve product quality during transit[^1]. This becomes increasingly important as pharmaceutical supply chains become more global and complex, with products often traveling long distances between manufacturing sites and final distribution points.\r\n\r\n### Documentation and Lifecycle Management\r\n\r\nDocumenting and tracing validation activities involves creating, reviewing, approving, and maintaining all validation and qualification documents throughout their lifecycle, ensuring traceability of requirements, testing, and results[^1]. The documentation process must be comprehensive and systematic to provide clear evidence that validation activities have been performed adequately and that results support the intended conclusions. Validation documentation serves as critical evidence during regulatory inspections and audits.\r\n\r\nValidation activities interface extensively with multiple departments including manufacturing (processes and equipment needing validation), quality control (analytical methods and laboratory equipment), engineering and maintenance (facility, utility, and equipment qualification), and information technology (computer systems validation)[^1]. This cross-functional nature of validation requires careful coordination and communication to ensure that all aspects of validation are properly planned, executed, and documented. The integration of validation activities across departments helps ensure that the overall manufacturing system operates as an integrated whole rather than as isolated components.\r\n\r\n## Facility and Equipment Lifecycle\r\n\r\nFacility and equipment lifecycle management ensures that pharmaceutical facilities and equipment maintain states of control, remain suitable for their intended purposes, and adhere to GxP requirements throughout their operational lifecycles[^1]. These activities encompass the complete span of facility and equipment existence from initial design and installation through ongoing operation, maintenance, and eventual retirement or replacement.\r\n\r\n### Facility and Utility Management\r\n\r\nQuality assurance oversight of utilities involves providing quality oversight for critical utilities such as purified water systems, HVAC systems, and compressed air that directly impact product quality, ensuring their proper design, qualification, monitoring, and maintenance[^1]. Utilities represent the infrastructure that supports pharmaceutical manufacturing operations, and their failure or malfunction can have significant impacts on product quality. Utility systems must be designed, installed, and maintained to provide consistent, reliable service that meets the requirements of the manufacturing processes they support.\r\n\r\nQuality assurance oversight of facilities ensures that manufacturing and storage facilities meet GxP requirements for design, layout, construction, cleaning, and maintenance, including appropriate zoning such as cleanroom classifications[^1]. Facility design has fundamental impacts on the ability to maintain product quality, with factors such as air flow patterns, surface materials, and layout affecting contamination risks and cleaning effectiveness. Facilities must be designed and maintained to support the specific manufacturing operations they house while meeting all applicable regulatory requirements.\r\n\r\nZoning management involves defining and overseeing different classification zones within manufacturing facilities based on their cleanliness requirements and intended use, ensuring adherence to these classifications[^1]. Different manufacturing activities require different levels of environmental control, with sterile product manufacturing requiring the highest levels of cleanliness and control. Zoning systems provide frameworks for managing these different requirements within single facilities while preventing cross-contamination between areas with different classification levels.\r\n\r\n### Maintenance and Calibration Programs\r\n\r\nQuality assurance oversight of maintenance and calibration programs involves collaborating with maintenance and calibration departments to ensure that critical equipment is regularly maintained and calibrated according to defined schedules, preventing malfunctions and ensuring accurate measurements[^1]. Preventive maintenance programs help ensure that equipment operates consistently and reliably, while calibration programs ensure that measurements used for process control and product testing remain accurate over time. These programs require careful scheduling and documentation to ensure that maintenance activities do not interfere with production schedules while maintaining equipment reliability.\r\n\r\nThe oversight process includes reviewing calibration intervals and performance to ensure that calibration frequencies are appropriate for the equipment and its intended use[^1]. Calibration intervals must balance the need for measurement accuracy with the costs and production disruptions associated with calibration activities. Performance monitoring helps identify equipment that may require more frequent calibration or maintenance due to operating conditions or age.\r\n\r\n### Digital Integration and Asset Management\r\n\r\nDigital cleaning documentation implements systems to document and track the cleaning of manufacturing rooms and equipment digitally, providing real-time status and ensuring compliance with cleaning schedules and procedures[^1]. Digital systems improve the efficiency and reliability of cleaning documentation while providing real-time visibility into facility and equipment status. These systems help ensure that cleaning activities are performed according to schedule and that documentation is complete and accurate.\r\n\r\nGlobal equipment transparency maintains central, accessible records of all critical manufacturing and analytical equipment across different sites, including their status, qualification, and maintenance history, to support efficient asset management and potential transfers[^1]. As pharmaceutical companies operate increasingly global manufacturing networks, the ability to track and manage equipment across multiple sites becomes critical for operational efficiency and regulatory compliance. Centralized equipment databases enable companies to leverage equipment investments across their networks while maintaining proper documentation and control.\r\n\r\n## Product Release, Packaging, and Labeling\r\n\r\nProduct release, packaging, and labeling processes ensure that finished pharmaceutical products comply with all regulatory requirements and quality specifications before market release, while overseeing packaging and labeling integrity and ensuring product traceability throughout the supply chain[^1]. These processes represent the final quality assurance gatekeeping functions that determine whether products are suitable for distribution to patients.\r\n\r\n### Batch Disposition and Release\r\n\r\nBatch disposition and release involves the critical final decision-making process by which a qualified person assesses all batch-related documentation including manufacturing records, quality control test results, and deviation reports to determine if batches meet all specifications and regulatory requirements and can be released for distribution[^1]. This represents one of the most critical decisions in pharmaceutical manufacturing, as it determines whether products reach patients. The qualified person must have comprehensive knowledge of regulatory requirements, product specifications, and quality standards to make appropriate release decisions.\r\n\r\nDigital batch release hub creation establishes centralized systems or platforms where all relevant information for batch release decisions is consolidated and easily accessible, facilitating efficient and compliant release[^1]. These systems often include checks against regulatory dossiers to ensure that products meet the specifications and requirements established during the regulatory approval process. Digital systems improve the efficiency and reliability of batch release decisions while providing complete documentation of the decision-making process.\r\n\r\n### Supply Chain Integrity and Anti-Counterfeiting\r\n\r\nSupply chain integrity management implements measures like serialization (unique identification codes on each product unit) and anti-counterfeiting technologies to protect products from illicit trade, ensuring authenticity and traceability through the supply chain[^1]. These measures have become increasingly important as pharmaceutical supply chains have become more global and complex, creating opportunities for counterfeit products to enter legitimate supply chains. Serialization and other authentication technologies help ensure that patients receive genuine products while enabling rapid identification and removal of counterfeit products.\r\n\r\nThe anti-counterfeiting process includes investigating suspected counterfeit cases to determine the source and extent of counterfeiting activities[^1]. These investigations require collaboration between pharmaceutical companies, regulatory authorities, and law enforcement agencies to identify and prosecute counterfeiters while protecting patients from counterfeit products. The investigation process must be rapid and thorough to minimize patient exposure to counterfeit products.\r\n\r\n### Packaging and Labeling Control\r\n\r\nArtwork management and external labeling processes involve overseeing the creation, approval, revision, and control of all product labeling and packaging artwork including cartons, inserts, and labels to ensure accuracy, regulatory compliance including country-specific requirements, and consistency with approved dossiers[^1]. Labeling errors can have serious consequences for patient safety, making labeling control a critical quality function. The labeling process must ensure that all required information is present and accurate while meeting the specific requirements of each country where products are distributed.\r\n\r\nQuality assurance oversight for packaging and repackaging operations ensures that packaging processes, including the application of labels, are performed according to GxP and approved procedures, and that packaging materials are correctly reconciled[^1]. Packaging operations must be controlled to ensure that the correct products receive the correct packaging and labeling, preventing mix-ups that could result in patients receiving incorrect products or dosing information.\r\n\r\nAdvanced global batch traceability implements systems to track individual product batches through the entire supply chain, from raw materials to distribution, including products manufactured by Contract Manufacturing Organizations[^1]. Traceability systems enable rapid identification and removal of problematic products when quality issues are identified, minimizing patient exposure to potentially harmful products. These systems also support supply chain optimization and efficiency improvements by providing visibility into product flow throughout the supply chain.\r\n\r\n## Modern Quality Frameworks and Emerging Trends\r\n\r\nThe pharmaceutical industry has undergone significant transformation in quality approaches, evolving from traditional quality-by-testing models to more sophisticated, science-based quality management systems[^10][^12]. Quality by Design (QbD) represents a systematic, risk-based, proactive approach to pharmaceutical development that begins with predefined objectives and emphasizes product and process understanding and process control based on sound science and quality risk management[^10]. This paradigm shift moves away from empirical processes toward more scientific and risk-based approaches that provide better assurance of product quality.\r\n\r\nThe traditional Quality by Test (QbT) system ensures product quality by following a sequence of steps including raw material testing, fixed drug product manufacturing processes, and end product testing[^10]. However, this approach may lead to poor drug safety because it relies primarily on final product testing rather than process understanding and control. In contrast, QbD emphasizes understanding and controlling sources of variability throughout the manufacturing process, providing greater assurance of product quality through process design rather than end-product testing[^10].\r\n\r\nProcess Analytical Technology (PAT) has been introduced to analyze intermediate quality attributes during the process of establishing regulatory specifications and facilitating real-time release testing[^14]. PAT tools enable monitoring of the relationship between process and quality, providing greater assurance of product quality than end-product testing alone[^14]. Various frameworks and methods such as QbD, real-time release testing (RTRT), and continuous process verification (CPV) recognize that appropriate combinations of process controls and predefined material attributes may provide greater assurance of product quality than end-product testing[^14].\r\n\r\nThe FDA's Pharmaceutical Quality for the 21st Century Initiative aims to promote a maximally efficient, agile, flexible pharmaceutical manufacturing sector that reliably produces high quality drugs without extensive regulatory oversight[^19]. This initiative represents recognition of the need for regulatory approaches that keep pace with technological advancements and industry capabilities while maintaining appropriate oversight to ensure product quality and patient safety.\r\n\r\n## Conclusion\r\n\r\nThe examination of pharmaceutical quality assurance processes reveals a comprehensive, interconnected system designed to ensure the consistent production of safe, effective medicines that meet stringent regulatory requirements throughout their lifecycle. The eight critical quality assurance process areas analyzed demonstrate how modern pharmaceutical manufacturing relies on systematic approaches to documentation, training, risk management, contamination control, validation, facility management, and product release that collectively provide multiple layers of quality assurance.\r\n\r\nThe evolution from traditional quality-by-testing approaches to Quality by Design methodologies represents a fundamental shift toward science-based, proactive quality management that emphasizes process understanding and control rather than reliance on end-product testing alone. This transformation, supported by advanced technologies such as Process Analytical Technology and digital systems, enables pharmaceutical manufacturers to achieve higher levels of quality assurance while improving operational efficiency and reducing regulatory oversight requirements.\r\n\r\nThe integration of these quality assurance processes across organizational functions demonstrates the critical importance of systematic coordination and communication in maintaining product quality and regulatory compliance. As pharmaceutical supply chains become increasingly global and complex, the need for robust quality assurance systems that can ensure product integrity across multiple sites, supply chain partners, and regulatory jurisdictions becomes ever more critical for protecting patient safety and maintaining public confidence in pharmaceutical products.\r\n\r\nFuture developments in pharmaceutical quality assurance will likely continue to emphasize digitalization, automation, and data analytics while maintaining the fundamental principles of systematic process control, comprehensive documentation, and continuous improvement that form the foundation of current quality assurance practice. The success of these systems ultimately depends on the commitment of pharmaceutical organizations to maintaining quality cultures that prioritize patient safety above all other considerations.\r\n\r\n<div style=\"text-align: center\">\u2042</div>\r\n\r\n[^1]: paste.txt\r\n\r\n[^2]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4605917/\r\n\r\n[^3]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4879472/\r\n\r\n[^4]: https://www.qualifyze.com/de/resources/what-is-alcoa-data-integrity/\r\n\r\n[^5]: https://simplerqms.com/pharmaceutical-sop-management/\r\n\r\n[^6]: https://pharmuni.com/glossary/gmp-training/\r\n\r\n[^7]: https://www.scilife.io/glossary/annual-product-quality-review\r\n\r\n[^8]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9589742/\r\n\r\n[^9]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11490658/\r\n\r\n[^10]: https://pmc.ncbi.nlm.nih.gov/articles/PMC7032183/\r\n\r\n[^11]: https://pmc.ncbi.nlm.nih.gov/articles/PMC7150996/\r\n\r\n[^12]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3853691/\r\n\r\n[^13]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11416741/\r\n\r\n[^14]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8234957/\r\n\r\n[^15]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11249487/\r\n\r\n[^16]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11207386/\r\n\r\n[^17]: https://thepharmavision.com/sop-for-responsibilities-of-quality-units/\r\n\r\n[^18]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11439473/\r\n\r\n[^19]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6733282/\r\n\r\n[^20]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4452839/\r\n\r\n[^21]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9831683/\r\n\r\n[^22]: https://www.semanticscholar.org/paper/7c33871df27fd8ae609d4c8408cf82da2de0b9de\r\n\r\n[^23]: https://www.semanticscholar.org/paper/ac3db52103305992d3934d5ea8507e81a20159a9\r\n\r\n[^24]: https://pubmed.ncbi.nlm.nih.gov/39019923/\r\n\r\n[^25]: https://www.semanticscholar.org/paper/bc9fbb64441c37d02028b797fdfcc20631a8c79d\r\n\r\n[^26]: https://www.semanticscholar.org/paper/49b95c2517819309da4df898701ff1a445467e84\r\n\r\n[^27]: https://www.semanticscholar.org/paper/c23e72a570ddcd6d170c8039e8ad7b940c04a8d9\r\n\r\n[^28]: https://www.semanticscholar.org/paper/787ef87109facbbc1ab2a35dcae4aae1bb6166cb\r\n\r\n[^29]: https://www.semanticscholar.org/paper/d894598e64659301eace1489f49a13abe3224d02\r\n\r\n[^30]: https://www.semanticscholar.org/paper/9a1dfafd9db08f7bb1cc9a30828adbf94093affa\r\n\r\n[^31]: https://www.semanticscholar.org/paper/82689906ff858abb6871cb816b2ee37357700be0\r\n\r\n[^32]: https://www.ncbi.nlm.nih.gov/books/NBK570305/\r\n\r\n[^33]: https://nextpharma-logistics.com/en/solutions/pharma-support/compliance-management-quality-assurance-in-the-pharmaceutical-industry/\r\n\r\n[^34]: https://simplerqms.com/pharmaceutical-quality-assurance/\r\n\r\n[^35]: https://www.amoriabond.com/en/insights/blog/the-digitalisation-of-pharmaceutical-quality-assurance-and-quality-control/\r\n\r\n[^36]: https://www.europeanpharmaceuticalreview.com/article/78981/quality-assurance-quality-systems-making-medicinal-products/\r\n\r\n[^37]: https://www.gmpsop.com/how-to-conduct-gmp-training-for-employee/\r\n\r\n[^38]: https://www.i-pharmconsulting.com/blog/what-is-quality-assurance-in-the-drug-development-process-/\r\n\r\n[^39]: https://zamann-pharma.com/de/2024/09/02/sop-management-in-der-pharma/\r\n\r\n[^40]: https://www.semanticscholar.org/paper/ff9b9d54ad7d86e10e24ab3cf9e9d51a36f944da\r\n\r\n[^41]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10588160/\r\n\r\n[^42]: https://pubmed.ncbi.nlm.nih.gov/30231739/\r\n\r\n[^43]: https://www.semanticscholar.org/paper/1a2b01bc56857fbca621fc51db2f7f62a6fa459a\r\n\r\n[^44]: https://pubmed.ncbi.nlm.nih.gov/26244520/\r\n\r\n[^45]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8812116/\r\n\r\n[^46]: https://pubmed.ncbi.nlm.nih.gov/32557313/\r\n\r\n[^47]: https://www.semanticscholar.org/paper/cd7f2805e6793e8ed7ae678645533e6645c72145\r\n\r\n[^48]: https://www.semanticscholar.org/paper/f707e7f49f0e38b7d7e9bd2af44aa62591373c2d\r\n\r\n[^49]: https://www.semanticscholar.org/paper/e596c8239341d766ad373b349ee221e8ab514d7f\r\n\r\n[^50]: https://www.pharmaguideline.com/p/sop-for-quality-assurance.html\r\n\r\n[^51]: https://pharmadevils.com/quality-assurance/\r\n\r\n[^52]: https://www.koerber-pharma.com/glossary/standard-operating-procedure-sop\r\n\r\n[^53]: https://www.semanticscholar.org/paper/eace839e30450d9e513d751b70f4ceec5a160c81\r\n\r\n[^54]: https://pubmed.ncbi.nlm.nih.gov/11858986/\r\n\r\n[^55]: https://www.semanticscholar.org/paper/153a571da07825b7395bacaab4d4d98df989fc0c\r\n\r\n[^56]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11490658/\r\n\r\n[^57]: https://www.semanticscholar.org/paper/6234b42e6051061f9aad0423eb9d5e5ec507410b\r\n\r\n[^58]: https://www.semanticscholar.org/paper/538d5a227fb5107d88c7c8ec9e3bfc6fbae1b78c\r\n\r\n[^59]: https://www.semanticscholar.org/paper/5c4cc61186b577c92276725cb4de10c494acbb6b\r\n\r\n[^60]: https://www.semanticscholar.org/paper/248082bc644e015a29fe37da9ee097e9c07dacbf\r\n\r\n[^61]: https://www.pharmaguideline.com/p/pharma-sops.html\r\n\r\n[^62]: https://www.semanticscholar.org/paper/a618cd50cb7a34512a40dd778734437c3538e225\r\n\r\n[^63]: https://pubmed.ncbi.nlm.nih.gov/21398371/\r\n\r\n[^64]: https://pubmed.ncbi.nlm.nih.gov/39094602/\r\n\r\n[^65]: https://www.semanticscholar.org/paper/f45e009086a2391076c21a9c873e0e673074b0cc\r\n\r\n[^66]: https://www.semanticscholar.org/paper/da6c4431423961a035a5e04cb8e1e77a2e9441f3\r\n\r\n[^67]: https://www.semanticscholar.org/paper/7082591c2717eb18750524e2f8240172b50831a0\r\n\r\n[^68]: https://www.semanticscholar.org/paper/d412105e5a75c23ef35e6586a38b11d413227050\r\n\r\n[^69]: https://www.semanticscholar.org/paper/be02f8ec302f6bae0dbf6bd99b206e08cd4f385b\r\n\r\n[^70]: https://www.semanticscholar.org/paper/e99b25de8f15f1646824927880bb101e6b1e80a9\r\n\r\n[^71]: https://www.semanticscholar.org/paper/fd0ade85cb5b64a0ef3c85723d28386a8fae1dcd\r\n\r\n[^72]: https://www.gmp-verlag.de/de/sop-sammlung/sop-sammlung-pharmaindustrie\r\n\r\n[^73]: https://www.gmp-navigator.com/seminare/gmp-schulungen\r\n\r\n[^74]: https://www.apprentice.io/life-science-glossary/mbr-master-batch-record\r\n\r\n[^75]: https://www.mastercontrol.com/quality/sop-standard-operating-procedure/pharmaceutical/\r\n\r\n[^76]: https://www.alfatraining.com/einfuehrung-in-gmp/\r\n\r\n[^77]: https://www.semanticscholar.org/paper/cd56d1cc5d87ba69e9dea934da88e9b0c125ec42\r\n\r\n[^78]: https://arxiv.org/abs/2402.01717\r\n\r\n[^79]: https://www.semanticscholar.org/paper/31997063289e4c95ef5544e08d98995737c74ade\r\n\r\n[^80]: https://www.semanticscholar.org/paper/d21be27c635c199dab99c2dcf60d0c67c373a55c\r\n\r\n[^81]: https://www.semanticscholar.org/paper/e18195c6b862f080a246753dbbece5e89ed66c42\r\n\r\n[^82]: https://pubmed.ncbi.nlm.nih.gov/37160228/\r\n\r\n[^83]: https://www.semanticscholar.org/paper/890e8d29911f33b7573dd48ad50e4238ccda7c5b\r\n\r\n[^84]: https://www.semanticscholar.org/paper/5d97c810af7fb59dfefce99f4a636c45bf1e1375\r\n\r\n[^85]: https://www.semanticscholar.org/paper/bdac5fc9e91dd4c38854bedb6df8e1bba5ab4a49\r\n\r\n[^86]: https://www.semanticscholar.org/paper/69d0a63635f4b4cdcad7112146ed49e3788e3091\r\n\r\n[^87]: https://www.semanticscholar.org/paper/304044d8b28034b72ed9f57dde5c51823c007f70\r\n\r\n[^88]: https://www.semanticscholar.org/paper/caef7342cb2678ac98828379351079f45eacf808\r\n\r\n[^89]: https://www.semanticscholar.org/paper/338595f3eccc1c4fd7bb95a0d2501662ebe1a6fa\r\n\r\n[^90]: https://www.semanticscholar.org/paper/abb95289548c1a76d2054bda6e622a428972f195\r\n\r\n[^91]: https://www.semanticscholar.org/paper/a0b6da966bde8a09c2180fae1c39ead8d6bab9f7\r\n\r\n[^92]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7385541/\r\n\r\n[^93]: https://www.semanticscholar.org/paper/ccff52d901e1340e47bf05c27e0a8fdd01eb9550\r\n\r\n[^94]: https://www.semanticscholar.org/paper/a3987699475a8d6fd4ecdb4e9f2ecf16a7942f6b\r\n\r\n[^95]: https://www.assurx.com/standard-operating-procedure-sop-management-in-the-qms/\r\n\r\n[^96]: https://www.pharmaguideline.com/2016/10/quality-management-system-qms.html\r\n\r\n[^97]: https://pharmastate.academy/sop-for-quality-management-system-documentation-in-pharmaceutical-industry/\r\n\r\n[^98]: https://www.semanticscholar.org/paper/36aeb6d9292180b7acfb6cede93cf031347690ce\r\n\r\n[^99]: https://www.semanticscholar.org/paper/22dbdb84a5c19ac6b45a6083272aad649d0e01de\r\n\r\n[^100]: https://www.semanticscholar.org/paper/12a5bb2b9588274f9accae299afa3772c40f6fe9\r\n\r\n[^101]: https://www.semanticscholar.org/paper/0c914bf236d23a4e361231b9f92ad8650ec842da\r\n\r\n[^102]: https://www.semanticscholar.org/paper/46cddb20ea50e8d6596969fb21f0642e38794a36\r\n\r\n[^103]: https://www.semanticscholar.org/paper/e3c36897ac49926e97b4c17b3b3ff430d9cb718b\r\n\r\n[^104]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8366475/\r\n\r\n[^105]: https://www.semanticscholar.org/paper/5ddd3e6b3091c6054170aa682043622e423b1c31\r\n\r\n[^106]: https://pubmed.ncbi.nlm.nih.gov/15540967/\r\n\r\n[^107]: https://www.semanticscholar.org/paper/a96746be864432a32ff27f7139261f2c7804f8ae\r\n\r\n[^108]: https://www.pure11.de/de/produkte/service/glossar/change-control\r\n\r\n[^109]: https://www.freyrsolutions.com/blog/what-is-the-purpose-of-change-control\r\n\r\n[^110]: https://zamann-pharma.com/de/glossary/change-control-2/\r\n\r\n[^111]: https://www.scilife.io/blog/what-is-the-purpose-of-change-control\r\n\r\n[^112]: https://www.gmpsop.com/annual-product-quality-review-for-a-pharmaceutical-product/\r\n\r\n[^113]: https://gmpinsiders.com/quality-risk-management-in-pharmaceutical-industry/\r\n\r\n[^114]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3833692/\r\n\r\n[^115]: https://www.mastercontrol.com/gxp-lifeline/change-in-pharmaceutical-manufacture/\r\n\r\n[^116]: https://www.qbdgroup.com/en/blog/annual-product-quality-review-apqr-in-pharma/\r\n\r\n[^117]: https://www.semanticscholar.org/paper/6e0d21ead1bbcd6caf3c54372b7727b2d410b530\r\n\r\n[^118]: https://www.semanticscholar.org/paper/84c5189c6d52196f1289e1027cf1e2fef2a4ee09\r\n\r\n[^119]: https://pubmed.ncbi.nlm.nih.gov/22767885/\r\n\r\n[^120]: https://www.semanticscholar.org/paper/ddab1b338d1243d1bec5102970f308f5dc91b8a7\r\n\r\n[^121]: https://www.semanticscholar.org/paper/93490124395e30667af4029558b5c997810b538b\r\n\r\n[^122]: https://www.semanticscholar.org/paper/3b1720cbe352df86e2836744b2a0dc9e2f9bae29\r\n\r\n[^123]: https://www.compliancequest.com/bloglet/quality-assurance-in-pharmaceutical-industry/\r\n\r\n[^124]: https://www.scilife.io/blog/pharma-qa-steps\r\n\r\n[^125]: https://www.pharmatechoutlook.com/news/exploring-the-types-of-quality-assurance-in-pharmaceuticals-nwid-3065.html\r\n\r\n[^126]: https://www.semanticscholar.org/paper/cce746d4387a56b7b205c7ce2215a640492ad70f\r\n\r\n[^127]: https://www.leucine.io/mes-blogs/master-batch-record-in-pharma\r\n\r\n[^128]: https://pharmapath.in/quality-management-review/\r\n\r\n[^129]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6448014/\r\n\r\n[^130]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4037495/\r\n\r\n[^131]: https://www.zs.com/insights/pharma-optimize-external-supply-chain-contract-manufacturing\r\n\r\n[^132]: https://acrpnet.org/2023/10/17/guidance-for-preparing-standard-operating-procedures-sops\r\n\r\n[^133]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11386443/\r\n\r\n[^134]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3122044/\r\n\r\n[^135]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4765047/\r\n\r\n[^136]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6798223/\r\n\r\n[^137]: https://pmc.ncbi.nlm.nih.gov/articles/PMC5355558/\r\n\r\n[^138]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11056219/\r\n\r\n[^139]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6604032/\r\n\r\n[^140]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8519328/\r\n\r\n[^141]: https://www.koerber-pharma.com/fileadmin/user_upload/About_us/Downloads/Download-Consulting/KPKA_BR_SOP-Management-Onepager_ger.pdf\r\n\r\n[^142]: https://amplelogic.com/glossary/what-are-the-types-of-training-in-pharmaceuticals/\r\n\r\n[^143]: https://pmc.ncbi.nlm.nih.gov/articles/PMC5098449/\r\n\r\n[^144]: https://pmc.ncbi.nlm.nih.gov/articles/PMC5746753/\r\n\r\n[^145]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9050335/\r\n\r\n[^146]: https://www.infosys.com/industries/life-sciences/insights/documents/quality-assurance-pharmaceutical-industry.pdf\r\n\r\n[^147]: https://www.scilife.io/blog/employee-training-pharma\r\n\r\n[^148]: https://www.linkedin.com/pulse/working-external-partners-guide-product-managers-growjunction-vmfhc\r\n\r\n[^149]: https://www.linkedin.com/pulse/how-ai-transforming-quality-assurance-pharmaceuticals-hossain-mgo0c\r\n\r\n[^150]: https://pmc.ncbi.nlm.nih.gov/articles/PMC7385541/\r\n\r\n[^151]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6781312/\r\n\r\n[^152]: https://www.pharmasop.in/sop-for-quality-management-system-implementation/\r\n\r\n[^153]: https://simplerqms.com/pharmaceutical-document-management/\r\n\r\n[^154]: https://simplerqms.com/pharmaceutical-quality-management-system/\r\n\r\n[^155]: https://www.alphatopics.de/en/gmp-training\r\n\r\n[^156]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6863427/\r\n\r\n[^157]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9345009/\r\n\r\n[^158]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9887106/\r\n\r\n[^159]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11530517/\r\n\r\n[^160]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11682004/\r\n\r\n[^161]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8290596/\r\n\r\n[^162]: https://pmc.ncbi.nlm.nih.gov/articles/PMC7516132/\r\n\r\n[^163]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11043098/\r\n\r\n[^164]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8650306/\r\n\r\n[^165]: https://simplerqms.com/change-control-pharmaceutical/\r\n\r\n[^166]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4991121/\r\n\r\n[^167]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3227329/\r\n\r\n[^168]: https://www.qualifyze.com/resources/blog/what-is-pharmaceutical-quality-assurance\r\n\r\n[^169]: https://openmedscience.com/the-international-council-for-harmonization-ich-q10-a-model-for-a-robust-pharmaceutical-quality-management-system/\r\n\r\n[^170]: https://www.qualitaetsmanagement24.com/en/pharmaceutical-quality-management.php\r\n\r\n[^171]: https://www.qualio.com/blog/pharmaceutical-qa\r\n\r\n[^172]: https://www.ema.europa.eu/en/documents/scientific-guideline/international-conference-harmonisation-technical-requirements-registration-pharmaceuticals-human-guideline-q10-pharmaceutical-quality-system-step-5_en.pdf\r\n\r\n[^173]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9264740/\r\n\r\n[^174]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8926382/\r\n\r\n[^175]: https://www.pts.eu/gmp-seminare/\r\n\r\n[^176]: https://ispe.org/pharmaceutical-engineering/ispeak/dynamic-data-integrity-why-alcoa-keeps-evolving\r\n\r\n[^177]: https://www.cwa.de/gxp-software-sop-software-fuer-medizin-und-pharma/\r\n\r\n[^178]: https://www.concept-heidelberg.de/training/gmp-seminare.html",
        "created_at": "2025-06-06T14:05:40.147324+00:00"
      }
    ],
    "process_steps": [
      {
        "id": 1,
        "bi_id": "BEX01",
        "name": "01 | Lead to Prospect",
        "area_id": 3,
        "step_description": "The lead-to-prospect process is driven by Marketing and describes the identification of potential new contract manufacturing leads. It includes qualification of leads based on BioX strategy and corresponding acquisition focus, before assignment to respective BD&KAMs. This process translates BioX strategy and target portfolio into product/project acquisition.",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 2,
        "bi_id": "PS-QC-001",
        "name": "01 | LAB PLANNING AND SCHEDULING",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo ensure efficient use of resources with automated and data-driven laboratory planning, covering short and long-term requirements, end-to-end linked to the supply chain and production schedule, transforming raw data into actionable insights through structured planning.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Integrated Planning:** Develop a unified system for comprehensive lab scheduling, capacity planning (team/expert level), and predictive adjustments, allocating tasks based on priority and tracking equipment utilization and status.\r\n-   **Demand Forecasting:** Utilize historical data to predict testing volumes for new drug launches or seasonal production spikes, supporting strategic resource allocation.\r\n-   **Cross-Functional Collaboration:** Integrate with shift planning, production planning, and stability testing planning, aligning QC timelines with manufacturing schedules and supply chain requirements.\r\n-   **Resource Management:** Manage FTE, chemicals, and equipment for modular and flexible planning, enabling optimal resource availability.\r\n-   **Performance Monitoring:** Provide a centralized digital dashboard with real-time data on lab performance metrics (e.g., OEE, deviations, equipment failures), offering alerts and historical data analysis for continuous improvement.\r\n-   **Standardized Sourcing:** Implement a global, standardized sourcing process and system for lab materials with automated inventory tracking, replenishment triggers, and integration with quality management systems for streamlined ordering and CoA attachment.\r\n\r\n**Value:**\r\nSignificantly reduces manual scheduling effort and planning volatility, ensuring adherence to principles like FIFO. It eliminates bottlenecks, enables long-term resource planning, and provides real-time visibility into lab performance. This leads to efficient resource utilization, reduced idle time by 20-30%, optimized material ordering, and consistent, reliable lab operations.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We ensure efficient use of resources with automated & data-driven laboratory planning, covering short and long-term requirements, E2E linked to the supply chain and production schedule.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Production Planning/Manufacturing: For production schedules, incoming goods information, and IPC requirements. (QC01, page 6, USE CASE 1)\r\nSupply Chain Management (SCM): For long-term requirements and E2E linkage. (page 6)\r\nShift Planning / HR: For personnel availability and scheduling. (USE CASE 1)\r\nProcurement/Source2Pay: For ordering lab materials and supplier information. (QC03, USE CASE 3)\r\nLIMS/SAP QM: For test data, inspection plans, material master data. (USE CASE 1, USE CASE 3)\r\nEquipment Management (QC07): For equipment availability, status, and maintenance schedules. (QC01, USE CASE 1)\r\nStability Program Management: For planning stability tests. (USE CASE 1)",
        "what_is_actually_done": "Develop a unified system for comprehensive lab scheduling, capacity planning (team/expert level), and predictive adjustments. Allocate tasks based on priority and track equipment utilization and status. Integrate with shift planning, production planning, and stability testing planning. Provide a centralized dashboard with real-time data, drag-and-drop scheduling, and conflict resolution. Manage resources (FTE, chemicals, equipment) for modular and flexible planning. Enable retrospective evaluation of plan vs. reality (QC01 / USE CASE 1). Create a digital dashboard to display real-time lab performance metrics (e.g., OEE, deviations, equipment failures). Provide alerts for performance deviations. Enable historical data analysis and trend identification for performance improvement. Facilitate communication through built-in messaging and notification systems (QC02 / USE CASE 2). Implement a global, standardized sourcing process and system for lab materials with a standard catalogue. Manage inventory with automated tracking, replenishment triggers based on minimum stock levels. Integrate with quality management systems for CoA attachment and real-time order status. Harmonize ordering processes via a central system/hub (QC03 / USE CASE 3).",
        "pain_points": "Manual scheduling and planning processes with no central interface.\r\nLack of a First-In-First-Out (FIFO) principle adherence due to frequent changes.\r\nDisturbances caused by dependency on production schedules and ad-hoc changes.\r\nUnplanned activities (trainings, projects, system implementations) impacting schedules.\r\nNo possibility for long-term planning; no connection to production planning.\r\nFTE planning is primarily short-term.\r\nVolatile schedules due to manufacturing changes.\r\nNo standard system for planning & scheduling.\r\nMaster data creation process for planning is cumbersome, involving MDM and IU/Dev.\r\nHigh diversity in QC ordering systems, hindering standardization. (USE CASE 3)\r\n100% manual QC material ordering process with high effort. (USE CASE 3)\r\nManual creation of materials if not available in the system. (USE CASE 3)\r\nUncontrolled purchasing leading to higher costs. (USE CASE 3)\r\nLong material availability and delivery times. (USE CASE 3)\r\nUndefined and untraceable minimum stock levels. (USE CASE 3)\r\nManual effort to attach CoAs from suppliers. (USE CASE 3)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 3,
        "bi_id": "SPM01",
        "name": "01 | Strategy & Outsourcing Portfolio Management",
        "area_id": 2,
        "step_description": "Determining which products or processes should be externally manufactured, analyzing make-vs-buy decisions, and developing the overall CMO strategy aligned with business objectives.\r\n\r\n\r\n\r\n\r\n\r\nCMO decision tree application to determine outsourcing scope (IP ownership, MA authorization, trademark usage)\r\n\r\n\r\n\r\nExternal network portfolio planning and optimization across divisions (AH, HP, Biopharmaceuticals)\r\n\r\n\r\n\r\nMake-vs-buy analysis for manufacturing activities and development services\r\n\r\n\r\n\r\nCMO classification strategy (Differentiating, Premium, Advanced, Basic) alignment with business objectives\r\n\r\n\r\n\r\nCross-divisional CMO strategy coordination and territorial/regional planning",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 4,
        "bi_id": "SPM02",
        "name": "02 | Partner Acquisition & Contracting",
        "area_id": 2,
        "step_description": "The process of securing manufacturing partners involves researching potential CMOs, conducting assessments and audits, evaluating capabilities, and negotiating agreements. It covers initial screening to final contract execution, including quality standards, supply commitments, IP protections, pricing, and performance metrics, ensuring a smooth transition to a contractual relationship.\r\n\r\n\r\n\r\n\r\n\r\nCMO Selection and Approval process execution for network additions or technology transfers\r\n\r\n\r\n\r\nInitial CMO qualification as mandatory prerequisite for approval\r\n\r\n\r\n\r\nCommercial and quality contract negotiations (SMA/TMA agreements)\r\n\r\n\r\n\r\nDue diligence assessments covering GxP standards, IP protection, competitive pricing\r\n\r\n\r\n\r\nQuality Agreements establishment and signature policy compliance",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 5,
        "bi_id": "SPM04",
        "name": "03 | Technology Transfer & Implementation",
        "area_id": 2,
        "step_description": "Coordinating the transfer of manufacturing processes, analytical methods, and knowledge to ensure successful production implementation.\r\n\r\n\r\n\r\n\r\n\r\nProduct and process transfer coordination to qualified CMOs\r\n\r\n\r\n\r\nTechnology transfer activities per established SOPs (drug product, pharmaceutical, biologics)\r\n\r\n\r\n\r\nTransfer portfolio management and selection processes\r\n\r\n\r\n\r\nDevelopment-to-manufacturing transition for First Manufacturer designation\r\n\r\n\r\n\r\nTransfer agreements and contract amendments for investment activities",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 6,
        "bi_id": "SPM05",
        "name": "04 | Quality Oversight",
        "area_id": 2,
        "step_description": "Holistic monitoring of manufacturing quality involves overseeing partners, ensuring compliance with standards, managing deviations and CAPA processes, and coordinating with labs for testing. This ensures consistent quality and regulatory compliance across all external manufacturing relationships.\r\n\r\n\r\n\r\n\r\n\r\nCMO qualification maintenance and surveillance management\r\n\r\n\r\n\r\nQuality performance monitoring and compliance assurance\r\n\r\n\r\n\r\nDeviation management and CAPA process coordination\r\n\r\n\r\n\r\nQuality agreements management and GxP standards enforcement\r\n\r\n\r\n\r\nAudit coordination and quality performance evaluation",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 7,
        "bi_id": "SPM06",
        "name": "05 | Routine & Performance Management",
        "area_id": 2,
        "step_description": "Identifying supply vulnerabilities, developing mitigation strategies, and ensuring backup manufacturing options.\r\n\r\n\r\n\r\n\r\n\r\nDay-to-day CMO relationship management and operational oversight\r\n\r\n\r\n\r\nPerformance review meetings (BRM) for strategic CMOs and KPI tracking\r\n\r\n\r\n\r\nRisk management and supply chain vulnerability assessment\r\n\r\n\r\n\r\nCMO qualification maintenance and supplier development programs\r\n\r\n\r\n\r\nCross-functional coordination through External Network Committees",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 8,
        "bi_id": "SPM08",
        "name": "08 | Oversight and Coordination of Contract Labs",
        "area_id": 2,
        "step_description": "\u200bContract Laboratory Organizations (CLO) management within CMO framework\r\n\r\n\r\n\r\n\r\n\r\nTesting services coordination and quality oversight\r\n\r\n\r\n\r\nLab performance monitoring and compliance management\r\n\r\n\r\n\r\nCross-functional coordination for analytical and testing activities",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 9,
        "bi_id": "BEX02",
        "name": "02 | Prospect to Contract",
        "area_id": 3,
        "step_description": "The Prospect-to-Contract process outlines the steps to take a new business prospect to a signed contract with the client.The process evaluates and assesses the prospect from a business, from a capacity and from a technical standpoint. Once fully assessed, the client is involved via proposal and contract negotiations. During this process, the scope of the project\u2019s work, including timeline, deliverables, and pricing are defined.",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 10,
        "bi_id": "BEX03",
        "name": "03 | Contract to Cash - Project Phase",
        "area_id": 3,
        "step_description": "The Contract-to-Cash process covers the project phase and the commercial phase of a new customer product that is to be implemented at BI by BioX. The project Phase starts with a signed contract that includes the project plan (tech-transfer) and usually ends with submission/approval. PPM is the central hub for all project related topics and leads the cross functional project team to drive progress, to meet milestones, performs cost controlling, and to fulfil deliverables.",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 11,
        "bi_id": "03",
        "name": "03 | Tactical & Operational Supply Planning & Configuration",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nTranslates demand forecasts into executable supply plans that optimize the allocation of production, inventory, and transportation resources across the global network while maintaining service levels and regulatory compliance.\r\n\r\n**Key Tasks:**\r\n\r\n- **Network Balancing:** Optimizing production allocation across internal sites and 140+ Contract Manufacturing Organizations based on capacity, cost, and service considerations.\r\n- **Capacity Planning:** Managing production capacity utilization, identifying bottlenecks, and coordinating capacity expansion or reallocation decisions.\r\n- **Inventory Optimization:** Setting optimal inventory levels (safety stock, cycle stock, strategic stock) to balance service levels with carrying costs across all locations.\r\n- **Multi-Source Management:** Coordinating supply from multiple sources for the same product, managing interchangeability, and optimizing source allocation decisions.\r\n- **Supplier Coordination:** Planning material flows with Contract Manufacturing Organizations, managing supplier performance, and ensuring supply continuity.\r\n- **Launch Planning:** Developing detailed supply plans for new product launches, coordinating capacity allocation and inventory build strategies.\r\n\r\n**Value:**\r\nEnsures reliable product supply while minimizing total supply chain costs, optimizes asset utilization across the global network, and provides flexibility to respond to demand variability and supply disruptions\u2014maintaining high customer service levels while protecting profit margins.",
        "raw_content": "Tactical & Operational Supply Planning & Configuration: We use a network wide, unified data model to orchestrate, plan, and configure the supply chain, ensuring reliable launches, flexible supply, ideal inventory, and optimized product allocations supporting our S&OP processes. Vision statements: We use a network wide, unified data model to orchestrate, plan, and configure the supply chain, ensuring reliable launches, flexible supply, ideal inventory, and optimized product allocations supporting our S&OP processes. Pain Points: Manual Excel/Poweropoint driven process; Lack of scenario planning capabilities; no E2E view available; Large number of potentially error prone manual activities; Launch volume planning (i.e. FP demands not planned in) --> Manual planning; no differetiation between strat/safety/cycle stock; FINANCIAL INTEGRATION; High effort for preparation of a feasible plan for the E2E supply network & its configuration; Lead times for planning, replenishment and customer orders are slow; PROCESS & SYSTEMS; no stock & capacity transparency regarding CMO; Lack of simulation capabilities for tactical and operational planning; Inventory data requires acces to more systems than accross peers and BI still relies on Excel databases as well as directly pulled data from the markets; Inventory target setting runs manually only every 2nd year; Lacking support of the SC configuration and parametrization process; no system available to directly show me the financial impact (i.e. conversion); INTERCHANGABILITY; TMA (e. WCBS, syringes visibility planning, taxation; no possibility for deand planning independently from production site (global SKU); Different SKUs per site and supplier for the same product; System Supported Planning of interchangeable SKUS; Multisourcing / Interchangeability is complex, limits automatization (SKU Architecture); Active SKUs in GBS but not yet active in GRP; no supplier performance monitoring; no unique identifier for vendor/supplier; VMI Planning limited in case of hubs, etc.; Bi total inventory is wiportion of Low; Consolidated Forecasting not possible due to different material numbers; neplenishment is; Inventory write are mostly driven by shelf life expiry.",
        "summary": "Orchestrates, plans, and configures the supply chain using a network-wide data model to ensure reliable launches, flexible supply, ideal inventory, and optimized product allocations.",
        "vision_statement": "We use a network wide, unified data model to orchestrate, plan, and configure the supply chain, ensuring reliable launches, flexible supply, ideal inventory, and optimized product allocations supporting our S&OP processes.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "SAP IBP-based network planning enables system-supported capacity balancing across all internal sites (Ingelheim, Koropi, St. Cugat, Promeco, Rottendorf, Yamagata, Shanghai) and 140+ Contract Manufacturing Organizations (CMOs), automatically optimizing production schedules through linear programming algorithms, considering constraints such as capacity limits, material availability, quality requirements, and regulatory approvals. Real-time visibility into capacity, inventory, and constraints across the entire supply network provides live dashboards showing current stock levels at all locations, available production capacity by site and product line, active bottlenecks with impact analysis, supplier performance metrics with delivery reliability, and quality issue tracking with supplier scorecards.\\n\\nAutomated scenario generation and optimization propose alternative production plans considering multiple objectives (cost minimization, service level maximization, inventory optimization), allocate demand across different sites based on capacity availability and total cost of supply, evaluate make-vs-buy decisions with comprehensive financial analysis, and assess supply disruption scenarios with contingency planning. The system handles complex multi-source supply scenarios including interchangeable SKUs with automatic substitution logic, global vs. local sourcing optimization, transfer pricing optimization across legal entities, and regulatory approval mapping ensuring compliant supply sources.\\n\\nA single, harmonized master data model provides consistent product definitions across all regions and supply sources, unified location and resource data enabling global optimization, standardized supplier information with performance tracking, integrated Bill of Materials (BOM) management with version control, and synchronized regulatory approval data ensuring compliance across all markets. Consistent product definitions enable global SKU planning independent of production site through master product concepts that map to local SKUs, enabling planning for global demand while optimizing local supply execution, supporting interchangeability analysis for supply flexibility, and facilitating transfer pricing and cost allocation across the network.\\n\\nIntegrated financial data enables direct visibility of planning decision impacts through real-time calculation of total cost of supply including manufacturing costs, logistics costs, inventory carrying costs, quality costs, and risk-related costs. The system performs comprehensive cost modeling for different supply scenarios, supports transfer pricing optimization across legal entities, provides working capital impact analysis for inventory decisions, and enables margin analysis by product and channel.\\n\\nSystem-supported rough capacity planning (monthly) for the entire network including CMOs provides automated aggregation of production capacities across all sites, forecasted demand requirements with material explosion, bottleneck identification with resolution recommendations, and capacity utilization optimization with load balancing. Advanced planning algorithms consider setup times and changeover costs, batch size optimization with economic order quantities, campaign planning for efficient resource utilization, and quality control capacity with testing requirements.\\n\\nManagement of interchangeable SKUs is automated through intelligent substitution logic, demand pooling across supply sources, automatic allocation based on availability and cost, safety stock optimization considering substitutability, and real-time reallocation when supply disruptions occur. The system maintains interchangeability matrices with business rules, tracks substitution history and performance, provides recommendations for expanding interchangeability, and monitors financial impact of substitution decisions.\\n\\nFull end-to-end integration of CMOs into planning processes includes direct system integration with major contract manufacturers, real-time visibility into CMO production schedules and inventory levels, automated material supply coordination with pull/push optimization, quality data integration with real-time batch disposition, and performance monitoring with SLA tracking. Stock transparency and capacity planning for all external partners provide consolidated inventory dashboard across all CMO locations, capacity booking and reservation systems, material requirements planning with automated PO generation, and collaborative planning interfaces for capacity and demand sharing.\\n\\nUsers can easily create scenarios and run simulations through intuitive interfaces, testing impact of supply disruptions (site closures, quality issues, regulatory actions), demand surges (pandemic response, market expansions), network changes (new sites, technology upgrades, supplier changes), and portfolio changes (new launches, discontinuations, lifecycle management). Automated optimization recommendations consider multiple objectives simultaneously, suggest optimal site assignments for new products, recommend best allocation of limited capacity or materials, and provide supply network configuration optimization with total cost analysis.\\n\\nPipeline product planning includes integrated launch volume forecasting based on clinical trial data and market research, capacity allocation with early reservation systems, supply chain readiness assessment with gap analysis, technology transfer planning with timeline optimization, and regulatory approval coordination with launch timeline synchronization. The system supports phase-gate planning with milestone tracking, risk assessment for development programs, commercial readiness integration with manufacturing capability, and scale-up planning from clinical to commercial production.\\n\\nManual activities are reduced through intelligent automation including automated data entry from planning systems, routine plan adjustments based on predefined business rules, exception-based alerting for situations requiring human intervention, and machine learning algorithms that learn from planner decisions to improve automation over time. Automated alerts and recommendations provide proactive notification of potential issues, suggest planning parameter adjustments based on performance data, recommend capacity expansion or reduction based on demand trends, and identify optimization opportunities through continuous analysis of planning performance and outcomes.",
        "pain_points": "Manual Excel/Poweropoint driven process; Lack of scenario planning capabilities; no E2E view available; Large number of potentially error prone manual activities; Launch volume planning (i.e. FP demands not planned in) --> Manual planning; no differetiation between strat/safety/cycle stock; FINANCIAL INTEGRATION; High effort for preparation of a feasible plan for the E2E supply network & its configuration; Lead times for planning, replenishment and customer orders are slow; PROCESS & SYSTEMS; no stock & capacity transparency regarding CMO; Lack of simulation capabilities for tactical and operational planning; Inventory data requires acces to more systems than accross peers and BI still relies on Excel databases as well as directly pulled data from the markets; Inventory target setting runs manually only every 2nd year; Lacking support of the SC configuration and parametrization process; no system available to directly show me the financial impact (i.e. conversion); INTERCHANGABILITY; TMA (e. WCBS, syringes visibility planning, taxation; no possibility for deand planning independently from production site (global SKU); Different SKUs per site and supplier for the same product; System Supported Planning of interchangeable SKUS; Multisourcing / Interchangeability is complex, limits automatization (SKU Architecture); Active SKUs in GBS but not yet active in GRP; no supplier performance monitoring; no unique identifier for vendor/supplier; VMI Planning limited in case of hubs, etc.; Bi total inventory is wiportion of Low; Consolidated Forecasting not possible due to different material numbers; neplenishment is; Inventory write are mostly driven by shelf life expiry.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 12,
        "bi_id": "04",
        "name": "04 | Production Planning & Detailed Scheduling",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nConverts supply plans into detailed, executable production schedules that maximize manufacturing efficiency, ensure on-time delivery, and maintain product quality while optimizing resource utilization across all production facilities.\r\n\r\n**Key Tasks:**\r\n\r\n- **Production Sequencing:** Determining optimal production order and timing to minimize changeovers, maximize equipment utilization, and meet delivery commitments.\r\n- **Resource Allocation:** Assigning production capacity, materials, and labor across multiple products and production lines to optimize overall efficiency.\r\n- **Campaign Planning:** Grouping similar products into efficient production runs that minimize setup costs and maximize equipment utilization.\r\n- **Schedule Optimization:** Balancing multiple objectives including cost minimization, on-time delivery, quality requirements, and regulatory compliance.\r\n- **Bottleneck Management:** Identifying and resolving production constraints, coordinating across multiple production stages (bulk, filling, packaging).\r\n- **Contingency Planning:** Developing alternative production scenarios for equipment failures, material shortages, or demand changes.\r\n\r\n**Value:**\r\nMaximizes production efficiency and equipment utilization, ensures on-time delivery to customers, minimizes production costs through optimized sequencing and resource allocation, and maintains production flexibility to respond to changing market demands and operational disruptions.",
        "raw_content": "Production Planning & Detailed Scheduling: We use an integrated network wide data model to plan, simulate and schedule manufacturing across all relevant product levels to achieve fast time to market through reliable and efficient supply plans. Vision statements: We use an integrated network wide data model to plan, simulate and schedule manufacturing across all relevant product levels to achieve fast time to market through reliable and efficient supply plans. Pain Points: Systems supported decision mainking in prod planning; Missing optimizer for production planning (i.e. optimizing production planning); Flexibility vs. cost saving; Low volume vs. high volume products; Bottleneck / Contingency Mngt; High effort for preparation of a feasible plan for the E2E supply network & its configuration; Lead times for planning, replenishment and customer orders are slow; Lacking support of the SC configuration and parametrization process; no system available to directly show me the financial impact (i.e. conversion); Challenges with product attribute consistency; MASTER DATA; Poor Master Data single source; Standard/Split does not allows; Master Data not integrated from; between system; System needs to support communication; purchasing communication; BOPUPOPUICSCM; BioX contractual obligation vs. forecast horizon BI products; No financial data available to steer annual target setting and parametrization; Different Systems product versioning in a highly solution; Challenges with Information and; System is not built; CMOS; workarounds; Dependencies from others (i.e. supplier provides starting materials delayed); unique identifier for supplier lacking; Intercahngeability; VMI Planning not working with interchangable SKUS; Systems support; Significant manual effort needed for planning finished products, filling, and blending, including both backward and forward scheduling; Transparency; Bulk planning only partially in systems; product lifecycle information and supply chain planning; Lacking transparency latest Business; intelligence: No process/system to incl. interface monitor global; BIX@ / GoTrack; Minor system; support for; creation of; production schedules.",
        "summary": "Plans, simulates, and schedules manufacturing across all product levels using an integrated network-wide data model for fast time to market and efficient supply.",
        "vision_statement": "We use an integrated network wide data model to plan, simulate and schedule manufacturing across all relevant product levels to achieve fast time to market through reliable and efficient supply plans.",
        "in_scope": "Scheduling and coordination of manufacturing activities to ensure timely production and efficient resource utilization (equipment, personnel, materials) including detailed sequencing, batch sizing, and changeover optimization to meet demand requirements. Management of Equipment (\"Ausr\u00fcstung\") and format parts; Minor Cleaning, Major Cleaning, Cross-Cleaning.",
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "Production planning decisions are system-supported through advanced algorithms that provide automated optimization recommendations for production sequences considering setup times and costs, optimal resource allocation across multiple production lines and shifts, changeover minimization with campaign planning logic, and dynamic priority management based on customer service levels and inventory positions. AI-enhanced scheduling incorporates machine learning models for campaigning optimization that analyze historical production data to suggest optimal batch sizes and production runs, setup matrix proposals that minimize changeover times and costs, predictive maintenance integration that considers equipment reliability in scheduling decisions, and yield optimization algorithms that maximize output while maintaining quality standards.\\n\\nAn integrated optimizer for production planning considers all constraints and objectives simultaneously including material availability with real-time inventory tracking, machine capacity with detailed capability modeling, labor availability and skill requirements, quality control capacity and testing lead times, regulatory compliance requirements, and due date commitments with customer service level targets. The system performs multi-objective optimization balancing cost minimization, service level maximization, inventory optimization, and quality assurance while respecting all physical and regulatory constraints.\\n\\n'Offline' simulation capabilities enable comprehensive risk-free testing of various planning scenarios including machine breakdown scenarios with automatic rerouting logic, sudden demand spikes with capacity reallocation strategies, material shortage situations with substitution analysis, quality issues requiring batch holds or recalls, regulatory changes affecting production parameters, and new product introduction with capacity impact assessment. What-if analyses are performed for equipment failures showing how to optimally re-route production across remaining capacity, supply disruptions with alternative sourcing and allocation strategies, demand changes requiring production plan adjustments, and process improvements with productivity and cost impact modeling.\\n\\nAutomated scenario generation creates optimized contingency plans for various disruption events including natural disasters with site closure procedures, supplier failures with alternative sourcing activation, quality issues with batch segregation and investigation protocols, regulatory actions with compliance response procedures, and cyber security incidents with system isolation and recovery plans. Each scenario includes detailed response procedures, resource requirements, timeline estimates, and performance impact assessments.\\n\\nEnd-to-end transparency is maintained through real-time dashboards showing production order status across all sites, work-in-progress inventory levels and locations, quality check results with batch genealogy tracking, material movement and consumption tracking, equipment utilization and performance metrics, and exception alerts for deviations from plan. Integration between planning and execution systems ensures production schedules automatically update global supply plans, material requirements flow seamlessly to procurement systems, capacity changes immediately impact network planning, and execution feedback continuously improves planning accuracy.\\n\\nReal-time visibility into production status includes live production line monitoring with OEE (Overall Equipment Effectiveness) tracking, quality results with statistical process control charts, material availability with real-time inventory consumption, equipment status with predictive maintenance alerts, and batch tracking with complete genealogy from raw materials through finished goods. Advanced analytics provide insights into production performance, identify optimization opportunities, and predict potential issues before they impact production schedules.\\n\\nAI-driven scheduling recommendations optimize for multiple objectives including cost minimization through efficient resource utilization, service level maximization with on-time delivery optimization, quality enhancement through optimal process parameter selection, and sustainability improvement through energy and waste optimization. The system continuously learns from production outcomes to improve scheduling algorithms, incorporates real-time data for dynamic optimization, and provides explainable recommendations with clear rationale for scheduling decisions.\\n\\nAutomated campaign planning groups similar products for efficient production runs, minimizes equipment changeovers and setup costs, optimizes batch sizes considering demand patterns and shelf life, coordinates across multiple production stages (bulk, filling, packaging), and integrates with maintenance schedules to minimize disruption. Setup optimization reduces manual planning effort by automatically calculating optimal changeover sequences, suggesting batch size adjustments for efficiency gains, and coordinating maintenance activities with production schedules.\\n\\nException-based management focuses planner attention on critical decisions by flagging only orders or resources that deviate significantly from plan, prioritizing interventions based on business impact and urgency, providing automated resolution suggestions where possible, and escalating critical issues with appropriate stakeholder notification. The system learns from planner decisions to improve exception detection and automate routine corrections.\\n\\nA unique supplier identifier system enables coordinated planning across all BI systems, supporting integrated supplier performance monitoring, coordinated material requirements planning, unified supplier relationship management, and consistent supplier data across all BI locations and functions. Planning is integrated across all production levels (API, bulk intermediate, finished goods) within one comprehensive system that optimizes material flows, coordinates production sequences, manages inventory levels, and ensures quality compliance throughout the value chain.\\n\\nCoordinated scheduling across internal sites and external Contract Manufacturing Organizations includes synchronized production schedules between BI factories and contract manufacturers, integrated material supply planning with pull/push optimization, coordinated quality control with shared standards and procedures, and unified performance monitoring with comprehensive KPI tracking. The system manages complex multi-tier supply relationships with end-to-end visibility and control.\\n\\nProactive bottleneck identification uses predictive analytics to identify potential capacity constraints before they impact production, automatically generates resolution recommendations including capacity reallocation and alternative sourcing, provides early warning systems with stakeholder notification, and tracks resolution effectiveness for continuous improvement. Integrated contingency planning includes pre-approved alternative scenarios that activate automatically when disruption occurs, with detailed response procedures and resource allocation plans.\\n\\nPerformance monitoring tracks on-time completion rates, resource utilization efficiency, quality performance metrics, cost performance against targets, and customer service level achievement. Automated alerts notify stakeholders of schedule deviations, constraint violations, quality issues, cost overruns, and service level risks, with escalation procedures ensuring appropriate response and resolution.",
        "pain_points": "Systems supported decision mainking in prod planning; Missing optimizer for production planning (i.e. optimizing production planning); Flexibility vs. cost saving; Low volume vs. high volume products; Bottleneck / Contingency Mngt; High effort for preparation of a feasible plan for the E2E supply network & its configuration; Lead times for planning, replenishment and customer orders are slow; Lacking support of the SC configuration and parametrization process; no system available to directly show me the financial impact (i.e. conversion); Challenges with product attribute consistency; MASTER DATA; Poor Master Data single source; Standard/Split does not allows; Master Data not integrated from; between system; System needs to support communication; purchasing communication; BOPUPOPUICSCM; BioX contractual obligation vs. forecast horizon BI products; No financial data available to steer annual target setting and parametrization; Different Systems product versioning in a highly solution; Challenges with Information and; System is not built; CMOS; workarounds; Dependencies from others (i.e. supplier provides starting materials delayed); unique identifier for supplier lacking; Intercahngeability; VMI Planning not working with interchangable SKUS; Systems support; Significant manual effort needed for planning finished products, filling, and blending, including both backward and forward scheduling; Transparency; Bulk planning only partially in systems; product lifecycle information and supply chain planning; Lacking transparency latest Business; intelligence: No process/system to incl. interface monitor global; BIX@ / GoTrack; Minor system; support for; creation of; production schedules.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 13,
        "bi_id": "PM-02",
        "name": "02 | KPI Definition & Cascading",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo define and cascade Key Performance Indicators (KPIs) based on realistic baselines and strategic relevance, establishing a harmonized framework for transparent and measurable performance.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Harmonized KPI Framework:** Establishing a standardized and transparent KPI framework that allows for comparability across departments without enforcing one-size-fits-all targets.\r\n-   **Data-driven Definition:** Defining KPIs based on realistic baselines and data-driven assumptions, ensuring measurability and strategic relevance.\r\n-   **Critical Goal Linkage:** Ensuring all critical goals, including launch readiness initiatives, are supported by measurable and relevant KPIs.\r\n-   **Conflict Resolution:** Identifying and proactively resolving conflicting KPIs and objectives to ensure alignment and avoid redundancies.\r\n-   **Transparent Cascading:** Implementing clear methodologies for cascading KPIs from strategic to operational levels, ensuring transparency and accessibility across the organization.\r\n-   **Leveraging Existing Metrics:** Promoting the reuse and sharing of existing KPIs and tools across departments to enhance synergy and efficiency.\r\n\r\n**Value:**\r\nEstablishes a clear and consistent system for measuring performance, ensuring that all critical goals are supported by measurable indicators. This harmonized approach reduces metric overload, enhances transparency, enables proactive steering, and supports strategic alignment across the organization.",
        "raw_content": null,
        "summary": "KPIs are defined based on realistic baselines and strategic relevance. A harmonized framework ensures transparency, avoids overload, and supports all critical goals with measurable indicators.",
        "vision_statement": "Standardized KPIs are accessible and understandable at every level, enabling proactive steering and strategic alignment.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "The second process step focuses on the definition and cascading of Key Performance Indicators (KPIs) based on realistic baselines and strategic relevance. This process aims to establish a harmonized framework that ensures transparency, avoids metric overload, and supports all critical organizational goals with measurable indicators. The challenges identified in this area include the risk of setting non-achievable targets, the potential for too many KPIs that create confusion rather than clarity, and standardization issues across different departments or operational sites.\r\n\r\nPharmaceutical companies must navigate the complex task of ensuring that KPIs are realistic, measurable, and strategically relevant while avoiding both an overload of metrics and the omission of critical performance areas. The research framework emphasizes understanding how organizations typically manage potential conflicts or redundancies between KPIs and the methods used to ensure harmonization and comparability across different departments or manufacturing sites.\r\n\r\nThe cascading process represents a particularly critical aspect of KPI management, requiring clear methodologies for ensuring transparency and alignment from strategic to operational levels. This process must address the unique challenges of pharmaceutical manufacturing, including launch readiness initiatives and other strategic projects that require specialized performance indicators.",
        "pain_points": "Non-achievable targets\r\nRisk of too many KPIs\r\nWhich KPIs do we have for launch readiness?\r\nStandardization over different departments leads to unachievable targets\r\nimportant goals lack KPIs\r\nNo transparency on the KPI/Goal cascade\r\nConflicting objectives/KPIS, manage competing KPIs\r\nNo synergies and low cross usadge of existing tools or KPIs",
        "targets_text": "KPIs are defined based on data-driven baselines and realistic assumptions.\r\nA harmonized KPI framework allows for comparability without enforcing one-size-fits-all targets.\r\nClear criteria guide the selection and prioritization of KPIs (e.g., strategic relevance, measurability).\r\nAll critical goals, including launch readiness and strategic initiatives, are backed by measurable KPIs\r\nConflicting KPIs and objectives are identified and resolved early in the process.\r\nThe KPI cascade is clearly documented and accessible across all levels\r\nExisting KPIs and tools are reused and shared across departments where possible",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 14,
        "bi_id": "E01",
        "name": "E01 | Enabling",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nProvides foundational capabilities that enable all supply chain processes through high-quality master data, advanced analytics, and integrated systems that support decision-making and operational excellence across the organization.\r\n\r\n**Key Tasks:**\r\n\r\n- **Master Data Management:** Maintaining authoritative, accurate, and consistent master data for products, suppliers, customers, and locations across all supply chain systems.\r\n- **Data Governance:** Establishing and enforcing data quality standards, ownership responsibilities, and change management processes to ensure data integrity.\r\n- **Analytics & Reporting:** Providing real-time visibility into supply chain performance through dashboards, KPIs, and advanced analytics that support decision-making.\r\n- **System Integration:** Ensuring seamless data flow and process integration across all supply chain systems, from planning through execution.\r\n- **Performance Monitoring:** Tracking supply chain performance against targets, identifying improvement opportunities, and driving continuous optimization initiatives.\r\n- **Digital Infrastructure:** Maintaining robust, scalable technology platforms that support current operations and enable future digital transformation initiatives.\r\n\r\n**Value:**\r\nEnables data-driven decision-making across all supply chain processes, ensures consistent and accurate information for planning and execution, provides insights that drive continuous improvement and optimization, and creates the foundation for advanced analytics and automation that enhance operational excellence and competitive advantage.",
        "raw_content": "Enabling: This section is dedicated to foundational elements or cross-functional capabilities that enable the core Supply Chain Management process areas. It includes Master Data and Analytics & Reporting.",
        "summary": "Foundational elements supporting all SCM processes.",
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": "All critical SCM master data including materials (APIs, intermediates, finished goods, packaging components), vendors (CMOs, suppliers, service providers), customers (BOPUs, distributors, end customers), locations (production sites, warehouses, distribution centers), and bills of materials (multi-level BOMs with routing and quality specifications) is stored in a single authoritative Master Data Governance (MDG) system with clearly defined data ownership across functional areas, comprehensive data governance processes with approval workflows, and data quality monitoring with automated validation rules and exception management.\\n\\nAutomated workflows orchestrate master data lifecycle management including creation workflows with validation and approval routing, change management with impact analysis and stakeholder notification, approval processes with role-based access controls and escalation procedures, and archiving procedures with retention policy compliance and audit trail maintenance. Data quality assurance includes automated validation rules, duplicate detection algorithms, completeness checks, and consistency verification across related data objects.\\n\\nReal-time interfaces ensure immediate data synchronization by automatically pushing master data updates from the central MDG system to all dependent SCM systems including ERP systems (SAP S/4HANA, legacy SAP systems), Transportation Management Systems (TMS), Warehouse Management Systems (WMS), supplier portals and B2B integration platforms, and customer-facing systems (e-commerce, customer service). Event-driven architecture replaces batch processing with immediate updates triggered by data changes.\\n\\nAI-powered data quality management continuously monitors master data integrity through automated scanning for inconsistencies (price variations, duplicate entries, missing mandatory fields), intelligent duplicate detection using fuzzy matching algorithms and machine learning, automated correction of minor issues (standardizing formats, correcting common errors), and intelligent flagging of major discrepancies requiring human review. Machine learning algorithms learn from data steward decisions to improve automated quality management over time.\\n\\nMaster data architecture supports all product types relevant to SCM including finished pharmaceutical products with complete regulatory and quality attributes, Active Pharmaceutical Ingredients (APIs) with sourcing and quality specifications, bulk and intermediate products with processing and storage requirements, packaging materials with specifications and supplier information, and regulatory data including approvals, registrations, and compliance requirements across all markets. The system handles complex product relationships, interchangeability matrices, and lifecycle management.\\n\\nFormalized governance processes define comprehensive procedures for master data definition with standardized naming conventions and data structures, maintenance procedures with regular review cycles and update protocols, control mechanisms with approval authority matrices and segregation of duties, and performance monitoring with data quality KPIs and continuous improvement programs. Data stewardship roles are clearly defined with training programs and certification requirements.\\n\\nInteractive dashboards provide real-time visibility into critical SCM KPIs including on-time delivery performance with drill-down to root cause analysis, inventory levels with trend analysis and optimization recommendations, production adherence with schedule attainment and capacity utilization metrics, transportation costs with route optimization and carrier performance analysis, quality metrics with defect rates and supplier performance, and financial performance with cost variance analysis and margin optimization opportunities. Dashboards are role-based with personalized views and mobile accessibility.\\n\\nAI-powered predictive analytics leverage machine learning models to forecast future demand with advanced algorithms incorporating multiple data sources, predict potential capacity shortfalls with early warning systems and mitigation recommendations, identify supply chain risks including supplier financial health, quality issues, and geopolitical risks before they materialize, optimize inventory levels with dynamic safety stock calculations, and predict maintenance requirements with equipment reliability modeling and spare parts optimization.\\n\\nContinuous performance monitoring tracks supply chain performance against targets through automated KPI calculation and trend analysis, exception-based alerting for deviations including inventory outside target ranges, missed delivery commitments, quality excursions, and cost overruns, automated root cause analysis with diagnostic algorithms, and intelligent recommendations for corrective actions based on historical data and best practices. The system learns from past performance to improve prediction accuracy and recommendation quality.\\n\\nUser-friendly analytics tools democratize data access through intuitive drag-and-drop interfaces requiring no technical expertise, self-service report generation with pre-built templates and custom options, curated data lake access with governed data sets and automated data preparation, ad-hoc analysis capabilities with guided analytics and statistical functions, and collaborative analytics with sharing and commenting capabilities. Training programs and user communities support adoption and capability development.\\n\\nAdvanced decision support enables sophisticated scenario modeling including 'what-if' analyses for planning decisions such as changing production sites, supplier alternatives, inventory strategies, and network configurations. The system provides optimized solutions based on user-defined objectives including cost minimization, service level maximization, risk mitigation, and sustainability improvement. Monte Carlo simulation capabilities assess uncertainty and provide confidence intervals for decision support.\\n\\nCloud-native platform architecture migrates from legacy SAP R/3 and other on-premise systems to modern cloud-based SAP S/4HANA, providing enhanced scalability with elastic resource allocation, improved reliability with built-in redundancy and disaster recovery, automatic updates with latest functionality and security patches, and reduced total cost of ownership with infrastructure management handled by cloud providers. Hybrid cloud architecture supports both public and private cloud deployments based on data sensitivity and regulatory requirements.\\n\\nAPI-first integration architecture enables seamless connectivity through RESTful APIs for all system integrations, real-time data exchange replacing batch interfaces, microservices architecture for improved flexibility and maintainability, event-driven integration for immediate response to business events, and comprehensive API management with security, monitoring, and version control. Integration platform as a service (iPaaS) capabilities accelerate new integrations and reduce maintenance overhead.\\n\\nCentralized data platform architecture includes a comprehensive data lake storing raw and processed data from all SCM systems with support for structured, semi-structured, and unstructured data, data warehouse with optimized structures for high-performance reporting and analytics, real-time data streaming with event processing capabilities, and continuous data ingestion pipelines with automated data quality checks and transformation logic. Advanced analytics capabilities include machine learning model deployment and management.\\n\\nIntelligent process automation deploys Robotic Process Automation (RPA) bots for routine tasks including automated data entry and validation, report generation and distribution, invoice processing and matching, order acknowledgment and tracking, and compliance documentation. Intelligent automation capabilities include AI-powered document processing with natural language processing, automated decision-making based on business rules and machine learning, and cognitive automation for complex tasks requiring reasoning and judgment.\\n\\nComprehensive change management programs ensure successful digital transformation through structured training programs tailored to different user roles and skill levels, digital literacy assessments identifying training gaps and development needs, certification programs ensuring competency in new tools and processes, and ongoing support with help desk services, user communities, and continuous learning resources. Change management includes stakeholder engagement, communication planning, and resistance management.\\n\\nCross-functional improvement teams drive continuous optimization through regular identification and implementation of SCM process improvements, data-driven analysis of performance gaps and opportunities, best practice sharing across regions and business units, and systematic review cycles for KPIs and targets with adjustment based on business changes and market conditions. Innovation programs encourage employee suggestions and pilot new technologies and approaches.\\n\\nGlobal standardization establishes consistent processes and systems through standardized operating procedures (SOPs) for key SCM processes including S&OP, demand planning, supply planning, logistics, and master data management. Governance frameworks balance global consistency with local flexibility, enabling necessary adaptations for regulatory requirements, market conditions, and operational constraints while maintaining overall coherence and optimization opportunities. Regular audits and assessments ensure compliance with global standards and identify opportunities for further harmonization and improvement.",
        "interfaces_text": null,
        "what_is_actually_done": "All critical SCM master data including materials (APIs, intermediates, finished goods, packaging components), vendors (CMOs, suppliers, service providers), customers (BOPUs, distributors, end customers), locations (production sites, warehouses, distribution centers), and bills of materials (multi-level BOMs with routing and quality specifications) is stored in a single authoritative Master Data Governance (MDG) system with clearly defined data ownership across functional areas, comprehensive data governance processes with approval workflows, and data quality monitoring with automated validation rules and exception management.\\n\\nAutomated workflows orchestrate master data lifecycle management including creation workflows with validation and approval routing, change management with impact analysis and stakeholder notification, approval processes with role-based access controls and escalation procedures, and archiving procedures with retention policy compliance and audit trail maintenance. Data quality assurance includes automated validation rules, duplicate detection algorithms, completeness checks, and consistency verification across related data objects.\\n\\nReal-time interfaces ensure immediate data synchronization by automatically pushing master data updates from the central MDG system to all dependent SCM systems including ERP systems (SAP S/4HANA, legacy SAP systems), Transportation Management Systems (TMS), Warehouse Management Systems (WMS), supplier portals and B2B integration platforms, and customer-facing systems (e-commerce, customer service). Event-driven architecture replaces batch processing with immediate updates triggered by data changes.\\n\\nAI-powered data quality management continuously monitors master data integrity through automated scanning for inconsistencies (price variations, duplicate entries, missing mandatory fields), intelligent duplicate detection using fuzzy matching algorithms and machine learning, automated correction of minor issues (standardizing formats, correcting common errors), and intelligent flagging of major discrepancies requiring human review. Machine learning algorithms learn from data steward decisions to improve automated quality management over time.\\n\\nMaster data architecture supports all product types relevant to SCM including finished pharmaceutical products with complete regulatory and quality attributes, Active Pharmaceutical Ingredients (APIs) with sourcing and quality specifications, bulk and intermediate products with processing and storage requirements, packaging materials with specifications and supplier information, and regulatory data including approvals, registrations, and compliance requirements across all markets. The system handles complex product relationships, interchangeability matrices, and lifecycle management.\\n\\nFormalized governance processes define comprehensive procedures for master data definition with standardized naming conventions and data structures, maintenance procedures with regular review cycles and update protocols, control mechanisms with approval authority matrices and segregation of duties, and performance monitoring with data quality KPIs and continuous improvement programs. Data stewardship roles are clearly defined with training programs and certification requirements.\\n\\nInteractive dashboards provide real-time visibility into critical SCM KPIs including on-time delivery performance with drill-down to root cause analysis, inventory levels with trend analysis and optimization recommendations, production adherence with schedule attainment and capacity utilization metrics, transportation costs with route optimization and carrier performance analysis, quality metrics with defect rates and supplier performance, and financial performance with cost variance analysis and margin optimization opportunities. Dashboards are role-based with personalized views and mobile accessibility.\\n\\nAI-powered predictive analytics leverage machine learning models to forecast future demand with advanced algorithms incorporating multiple data sources, predict potential capacity shortfalls with early warning systems and mitigation recommendations, identify supply chain risks including supplier financial health, quality issues, and geopolitical risks before they materialize, optimize inventory levels with dynamic safety stock calculations, and predict maintenance requirements with equipment reliability modeling and spare parts optimization.\\n\\nContinuous performance monitoring tracks supply chain performance against targets through automated KPI calculation and trend analysis, exception-based alerting for deviations including inventory outside target ranges, missed delivery commitments, quality excursions, and cost overruns, automated root cause analysis with diagnostic algorithms, and intelligent recommendations for corrective actions based on historical data and best practices. The system learns from past performance to improve prediction accuracy and recommendation quality.\\n\\nUser-friendly analytics tools democratize data access through intuitive drag-and-drop interfaces requiring no technical expertise, self-service report generation with pre-built templates and custom options, curated data lake access with governed data sets and automated data preparation, ad-hoc analysis capabilities with guided analytics and statistical functions, and collaborative analytics with sharing and commenting capabilities. Training programs and user communities support adoption and capability development.\\n\\nAdvanced decision support enables sophisticated scenario modeling including 'what-if' analyses for planning decisions such as changing production sites, supplier alternatives, inventory strategies, and network configurations. The system provides optimized solutions based on user-defined objectives including cost minimization, service level maximization, risk mitigation, and sustainability improvement. Monte Carlo simulation capabilities assess uncertainty and provide confidence intervals for decision support.\\n\\nCloud-native platform architecture migrates from legacy SAP R/3 and other on-premise systems to modern cloud-based SAP S/4HANA, providing enhanced scalability with elastic resource allocation, improved reliability with built-in redundancy and disaster recovery, automatic updates with latest functionality and security patches, and reduced total cost of ownership with infrastructure management handled by cloud providers. Hybrid cloud architecture supports both public and private cloud deployments based on data sensitivity and regulatory requirements.\\n\\nAPI-first integration architecture enables seamless connectivity through RESTful APIs for all system integrations, real-time data exchange replacing batch interfaces, microservices architecture for improved flexibility and maintainability, event-driven integration for immediate response to business events, and comprehensive API management with security, monitoring, and version control. Integration platform as a service (iPaaS) capabilities accelerate new integrations and reduce maintenance overhead.\\n\\nCentralized data platform architecture includes a comprehensive data lake storing raw and processed data from all SCM systems with support for structured, semi-structured, and unstructured data, data warehouse with optimized structures for high-performance reporting and analytics, real-time data streaming with event processing capabilities, and continuous data ingestion pipelines with automated data quality checks and transformation logic. Advanced analytics capabilities include machine learning model deployment and management.\\n\\nIntelligent process automation deploys Robotic Process Automation (RPA) bots for routine tasks including automated data entry and validation, report generation and distribution, invoice processing and matching, order acknowledgment and tracking, and compliance documentation. Intelligent automation capabilities include AI-powered document processing with natural language processing, automated decision-making based on business rules and machine learning, and cognitive automation for complex tasks requiring reasoning and judgment.\\n\\nComprehensive change management programs ensure successful digital transformation through structured training programs tailored to different user roles and skill levels, digital literacy assessments identifying training gaps and development needs, certification programs ensuring competency in new tools and processes, and ongoing support with help desk services, user communities, and continuous learning resources. Change management includes stakeholder engagement, communication planning, and resistance management.\\n\\nCross-functional improvement teams drive continuous optimization through regular identification and implementation of SCM process improvements, data-driven analysis of performance gaps and opportunities, best practice sharing across regions and business units, and systematic review cycles for KPIs and targets with adjustment based on business changes and market conditions. Innovation programs encourage employee suggestions and pilot new technologies and approaches.\\n\\nGlobal standardization establishes consistent processes and systems through standardized operating procedures (SOPs) for key SCM processes including S&OP, demand planning, supply planning, logistics, and master data management. Governance frameworks balance global consistency with local flexibility, enabling necessary adaptations for regulatory requirements, market conditions, and operational constraints while maintaining overall coherence and optimization opportunities. Regular audits and assessments ensure compliance with global standards and identify opportunities for further harmonization and improvement.",
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 15,
        "bi_id": "BEX04",
        "name": "04 | Account Management",
        "area_id": 3,
        "step_description": "Account Management is responsible for steering all aspects of an account and the related project and product portfolio along an established account strategy and the associated business & action plan. Once a new contract is signed, the account undergoes an initial evaluation and ASC endorsement. Existing accounts will undergo an annual strategy review cycle. Accounts are managed by ABTs, which are led by BD&KAM, and they represent a small-sized, cross-functional & empowered team of functional leaders.",
        "raw_content": null,
        "summary": null,
        "vision_statement": null,
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": null,
        "pain_points": null,
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 16,
        "bi_id": "PM-E02",
        "name": "E02 | Cultural Change Management",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo foster a data-driven, performance-oriented mindset across all organizational levels and strengthen employees' change readiness and business acumen to embrace new ways of working.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Performance Mindset Cultivation:** Developing and reinforcing an ambitious and ownership-driven performance mindset throughout the organization.\r\n-   **Data Literacy Development:** Enhancing data-driven thinking as a core competency at all levels, enabling employees to use data for decision-making and improvement.\r\n-   **Business Acumen Enhancement:** Ensuring employees understand the broader business context and how their work contributes to strategic goals.\r\n-   **Change Readiness & Openness:** Promoting openness to change and new ways of working, framing new systems and processes as opportunities for growth.\r\n-   **Consistent Management Support:** Ensuring management consistently reinforces desired behaviors, leads by example, and addresses underperformance effectively.\r\n-   **Behavioral Transparency:** Supporting tools or processes that make individual and aggregated behavioral trends transparent to encourage desired actions.\r\n\r\n**Value:**\r\nDrives the successful adoption and sustainability of performance management initiatives by addressing the human element of change. It empowers employees, fosters accountability, and creates a culture where data is valued, leading to more effective decision-making and continuous improvement.",
        "raw_content": null,
        "summary": "A data-driven, performance-oriented mindset is fostered across all levels. Change readiness and business acumen are strengthened to support new ways of working.",
        "vision_statement": "Systems support transparency of behaviors and foster ownership and accountability for data, enabling a strong performance mindset.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "Cultural change management represents the second enabling process, acknowledging that performance management success depends heavily on fostering a data-driven, performance-oriented mindset across all organizational levels. This process addresses fundamental challenges including resistance to change, lack of data literacy among employees, and inconsistent management support for performance-oriented behaviors.",
        "pain_points": "People are sticking to familiar systems/processes\r\nLack of data savy of our employees\r\nLack of business acumen\r\nLack of ambitious Performance mindset\r\nNo consequent management",
        "targets_text": "Openness to Change and New Ways of Working\r\n--> opportunity for growth\r\nData-driven thinking becomes a core competency at all levels\r\nEmployees understand the broader business context and how their work contributes to strategic goals\r\nAmbitious and Ownership-Driven Performance Mindset\r\n-->\r\nIndividuals take ownership of their performance\r\nManagement consistently reinforces desired behaviors and addresses underperformance",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 17,
        "bi_id": "PS-QA-001",
        "name": "01 | Quality assurance enabling processes",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nEstablishes the foundational infrastructure for all quality assurance activities, ensuring operations are systematically documented, staff are highly competent, and external collaborations are managed to strict quality standards.\r\n\r\n**Key Tasks:**\r\n\r\n-   **SOP Management:** AI-assisted creation, updates, and automated translations of standard operating procedures, ensuring adherence to GxP and good writing practices.\r\n-   **Learning & Competency Management:** Implementing role-based, multimedia learning journeys, automating curriculum assignment, and integrating learning achievements with system access.\r\n-   **External Partner Integration:** Managing seamless, secure data transfer (e.g., production data, analytical results) and automated archiving of external GMP documents with Contract Manufacturing Organizations (CMOs) and sponsors.\r\n-   **Data Integrity:** Ensuring all generated and recorded data adheres to ALCOA principles (Attributable, Legible, Contemporaneous, Original, Accurate) for traceability and security.\r\n-   **MBR Review Support:** Utilizing AI to support the review of Master Batch Records for adherence to dossier documents.\r\n-   **Quality Reporting:** Automating Key Performance Indicator (KPI) calculation and quality reporting by integrating data from various sources into dashboards.\r\n-   **Guided Workflows & Information Provision:** Providing system/bot guidance for employees executing tasks according to SOPs and employing AI for need-driven retrieval of documents and content summaries.\r\n\r\n**Value:**\r\nSignificantly enhances operational efficiency and compliance by digitalizing documentation, streamlining learning, and integrating external data. This reduces manual effort, improves data integrity, enables faster information retrieval, and ensures a highly competent workforce, all critical for producing safe, compliant medicines.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We achieve efficient quality assurance enabled by a smart documentation management, employee-centric learning journey and meaningful integration of external partners",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing (PS-M-XXX): SOP execution, MBR content, training for manufacturing personnel.\r\nQuality Control (PS-QC-XXX): SOPs for QC processes, training for QC personnel, data from external labs.\r\nSupply Chain Management (PS-SCM-XXX): Processes involving external partners, data exchange.\r\nRegulatory Affairs: Dossier documents for MBR alignment, SOPs impacting submissions.\r\nIT: e-DMS (VQD), AI platforms (iQ Now), learning management systems (LOS), integration platforms (SNCP).\r\nExternal Partners (CMOs, Sponsors): Data exchange, document sharing, learning requirements.\r\nPS-QA-002 (Product related QA enabling processes): SOP updates may trigger change controls.\r\nPS-QA-004 (Non-conformance and event management): SOPs define deviation handling; external partner issues.",
        "what_is_actually_done": "Manages Standard Operating Procedures (SOPs): AI-assisted creation, updates to new templates, adherence to good writing practices, and automated translations within e-DMS (VQD). (QA01) Provides Information: Employs AI (LLM) for need-driven retrieval of documents and content summaries from e-DMS (VQD). (QA02/QA03-text) External Partner Integration: Manages seamless and secure data transfer (production data, analytical results, discrepancies, changes, CAPAs) with external partners (CMOs/sponsors) via direct integration or platforms like SNCP. (QA03/QA06-text) External GMP Document Handling: Automates archiving of external GMP documents into eDMS. (QA04/QA08-text) Learning Management: Implements role-based learning, automated curricula assignment, multimedia modules, and integrates learning achievements with system access. (QA05/QA04-text) MBR Review Support: Uses AI to support Master Batch Record (MBR) review for adherence to dossier documents. (QA06/QA07-text) Guided Workflows: Provides system/bot guidance for employees executing tasks according to SOPs. (QA07/QA02-text) Quality Reporting: Automates KPI calculation and quality reporting by integrating data from various sources into dashboards. (QA08/QA05-text) Oversees Documentation Management Systems. Manages Learning Management processes. Ensures Data Integrity principles are applied. Manages interactions and documentation related to External Management (partners, suppliers).\r\n\r\n**Purpose:**\r\nEstablishes the foundations for all QA activities\u2014ensuring operations are documented, staff are trained, and external collaborations are managed to strict quality standards.\r\n\r\n**Key Tasks:**\r\n\r\n- **SOP Management:** Writing, updating, and distributing step-by-step instructions for all operations.\r\n- **Training:** Ensuring all staff are trained and competent in procedures and quality requirements.\r\n- **External Documentation:** Managing quality documents with partners (like Contract Manufacturing Organizations).\r\n- **Data Integrity:** Ensuring all data is accurate, complete, and secure (following ALCOA principles).\r\n- **Master Batch Record Review:** Checking completed manufacturing records for compliance.\r\n- **Quality Reporting:** Monitoring and reporting on quality metrics.\r\n\r\n**Value:**\r\nThese activities ensure consistency, staff competence, and reliable data\u2014forming the basis for safe, compliant medicines.",
        "pain_points": "Manual, tedious, and complex SOP creation, update, and review processes; difficult comment management in VQD. (QA01, P26)\r\nManual effort for SOP translations and formatting. (QA01)\r\nCumbersome document/content retrieval; search not intuitive. (QA03-text)\r\nInefficient and data integrity-prone manual data transfer with external partners (copy-paste). (QA06-text, P26)\r\nRedundant manual steps in archiving external GMP documents. (QA08-text)\r\nLearning primarily based on \"reading\"; unclear data integrity definitions; time-consuming LOS recordings. (P26, QA04-text)\r\nManual MBR alignment with dossiers. (QA07-text)\r\nTedious, manual, and site-specific compilation for Quality Management Reviews (QMR). (QA05-text, P26)\r\nLack of system/interface simplicity and connectivity; disparate IT solutions. (P26)\r\nInsufficient budget for digitalization projects. (P26)\r\nData quality, connectivity, and accessibility issues for reporting and KPIs. (P26)",
        "targets_text": "This area focuses on achieving efficient quality assurance through smart documentation management, employee-centric learning journeys, and meaningful integration of external partners. It covers the lifecycle of controlled documents (like SOPs), training, data integrity, and interactions with external entities.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 18,
        "bi_id": "PS-QA-004",
        "name": "04 | Non-conformance and event management",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo automate and integrate non-conformance and event management processes, enabling intelligent systems and seamless investigation guidance to ensure prompt resolution of quality issues, prevent recurrence, and protect patient safety.\r\n\r\n**Key Tasks:**\r\n\r\n-   **eQMS Management:** Providing a fit-for-purpose electronic Quality Management System (eQMS) tool for managing non-conformances and events (including CMO-specific considerations), and assisting record creation with AI.\r\n-   **Deviation & CAPA Management:** Managing deviations (unplanned departures) and Out-of-Specification (OOS) results, and developing, implementing, and tracking Corrective and Preventive Actions (CAPAs), including modular list generation.\r\n-   **Complaint & Market Action Management:** Handling technical product complaints from the market and managing quality issues that may necessitate market actions (e.g., recalls, withdrawals).\r\n-   **Investigation Management:** Simplifying discrepancy investigations using AI for methodological support, documentation (e.g., executive summaries), and ensuring logical writing.\r\n-   **System Integration:** Fully integrating Enterprise Resource Planning (ERP) and eQMS systems for automated actions (e.g., batch blocking) and establishing an integrated eQMS foundation for improved connectivity and traceability.\r\n\r\n**Value:**\r\nEnsures only safe, compliant products reach the market by streamlining and automating the management of all quality events. This significantly reduces manual effort in investigations and record-keeping, enhances data integrity and traceability, improves decision-making by integrating systems, and enables quicker, more effective resolution of issues, driving continuous quality improvement.",
        "raw_content": null,
        "summary": "This area aims for a future where non-conformance and event management is automated, with interconnected processes, intelligent systems, and seamless investigation guidance. It includes managing discrepancies, OOS, complaints, quality issues, market actions, investigations, and CAPAs.",
        "vision_statement": "Achieve a future where non-conformance and event management is automated, with interconnected processes and intelligent systems and seamless investigation guidance",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing (PS-M-XXX): Source of deviations, events, batch information for blocking/release.\r\nQuality Control (PS-QC-XXX): OOS results, lab investigations.\r\nSupply Chain Management (PS-SCM-XXX): Market actions, recall support, complaints handling.\r\nRegulatory Affairs: Reporting critical deviations, market actions.\r\nPS-QA-001 (QA enabling processes): SOPs define handling of non-conformances.\r\nPS-QA-002 (Product related QA enabling processes): CAPAs may lead to change controls.\r\nPS-QA-003 (Audit and intelligence): Audit findings often lead to non-conformances/CAPAs.\r\nPS-QA-005 (Production and process control): Production deviations, EM excursions.\r\nPS-QA-008 (Product release, packaging & labelling): Release decisions impacted by open deviations.\r\nIT: eQMS (GoTrack), ERP (SAP), AI tools.",
        "what_is_actually_done": "eQMS Record Creation Assistance: Uses AI to provide in-system proposals for creating adequate content or verifying existing content in eQMS records. (QA16/QA19-text) Non-conformance & Event Management Tool: Provides a fit-for-purpose tool for managing non-conformances and events, including specific considerations for CMO management. (QA17/QA16-text) Deviation & CAPA List Generation: Enables modular generation of deviation and CAPA lists for easier retrieval and reporting. (QA18/QA17-text) ERP & eQMS Integration: Fully integrates ERP (e.g., SAP) and eQMS systems for automated actions like batch blocking and data retrieval. (QA19/QA20-text) Discrepancy Investigation Simplification: Simplifies investigations using AI for methodological support, documentation (e.g., executive summaries), and ensuring logical writing. (QA20/QA18-text) Integrated QMS Foundation: Establishes a new, integrated eQMS foundation for improved process connectivity and traceability of records. (QA21) Manages Discrepancy Management processes. Manages OOS-Management (Out of Specification). Handles Technical Product Complaints. Manages Quality Issues & Market Actions. Oversees Investigation Management. Manages CAPA (Corrective and Preventive Action) Management.\r\n\r\n\r\n## 4. Non-conformance and Event Management\r\n\r\n**Purpose:**\r\nManages and resolves deviations, complaints, and quality issues to prevent recurrence and protect patients.\r\n\r\n**Key Tasks:**\r\n\r\n- **Deviation Management:** Investigating and resolving unplanned events or errors.\r\n- **Out-of-Specification Results:** Handling test results that fall outside acceptable limits.\r\n- **Complaint Management:** Investigating and responding to product complaints.\r\n- **Market Actions:** Managing recalls or withdrawals if needed.\r\n- **Investigations and CAPA:** Identifying root causes and implementing corrective/preventive actions.\r\n- **ERP Integration:** Connecting quality actions with business systems to prevent release of non-conforming products.\r\n\r\n**Value:**\r\nEnsures only safe, compliant products reach the market and drives ongoing quality improvement.",
        "pain_points": "Current eQMS records are partially inconsistent and incomplete. (QA19-text)\r\nGoTrack for CMO Management may not always be fit-for-purpose (mandatory fields, process steps). (QA16-text)\r\nDifficult retrieval of deviation/CAPA lists. (QA17-text)\r\nLack of full, seamless integration between ERP and eQMS (GoTrack); manual data transfer for batch blocking, etc. (QA20-text, P27)\r\nInvestigations are high-effort; documentation is complex; need for AI to support good writing and methodology. (QA18-text, P27)\r\neQMS modules are siloed, lacking interconnectivity and traceability (e.g., between CAPAs and source). (QA21, P27)\r\nRecord creation and processing not possible for external partners. (P27)\r\nDeviation 2.0 GoTrack module not fully matching 3PQM needs. (P27)\r\nUnclear restrictions in GoTrack regarding user permissions. (P27)\r\nCross-checking during investigations is a manual task. (P27)\r\nNo direct data support from systems available to investigators during investigations. (P27)\r\nQuality Issues & Market Action processes are not integrated with other core processes (Dev, TPC, OOX). (P27)\r\nHigh manual effort in creating and processing Technical Product Complaints; Complaint Mgt lacks full MDG linkage. (P27)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 19,
        "bi_id": "PS-QA-003",
        "name": "03 | Audit and intelligence",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo provide maximum quality oversight with minimum effort by seamlessly integrating AI-supported audit and intelligence processes, ensuring continuous compliance and proactive adaptation to evolving regulatory landscapes.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Quality Auditing:** Performing systematic evaluations of internal departments (e.g., manufacturing, QC) and external partners (e.g., suppliers, CMOs) for compliance with GxP, internal procedures, and agreements.\r\n-   **Regulatory & Pharmacopoeial Intelligence (RIN/PIN):** Continuously monitoring and analyzing new or updated regulations and pharmacopoeial requirements, using AI for automated checks, impact assessment, and change request generation.\r\n-   **Audit & Inspection Learnings:** Leveraging AI to summarize audit reports, ensure regulatory basis for observations, and effectively communicate findings across the organization.\r\n-   **Automated Observation Follow-up:** Automating the tracking and management of audit observations, including assigning Corrective and Preventive Actions (CAPAs) to internal and external parties and ensuring timely completion.\r\n\r\n**Value:**\r\nEnhances quality oversight and ensures continuous compliance by automating and integrating audit and intelligence processes. This reduces manual effort, improves the accuracy and timeliness of regulatory adaptation, facilitates proactive issue resolution, and ensures a robust, audit-ready quality system, thereby minimizing regulatory risks and fostering continuous improvement.",
        "raw_content": null,
        "summary": "This area aims to achieve maximum quality oversight with minimum effort through seamlessly integrated, AI-supported audit and intelligence processes. It covers quality audits, regulatory intelligence, and pharmacopoeial intelligence.",
        "vision_statement": "Achieve a future where seamlessly integrated, Al- supported audit and intelligence processes allow maximum quality oversight at minimum efforts",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing Sites (PS-M-XXX): Subject to audits, implement changes from RIN/PIN.\r\nQuality Control Labs (PS-QC-XXX): Subject to audits.\r\nExternal Partners/Suppliers: Subject to audits, follow-up on observations.\r\nRegulatory Authorities: Inspections, source of regulatory intelligence.\r\nPS-QA-001 (QA enabling processes): Internal standards (SOPs) checked against external requirements, external partner management.\r\nPS-QA-002 (Product related QA enabling processes): RIN/PIN updates may trigger change controls.\r\nPS-QA-004 (Non-conformance and event management): Audit findings often result in CAPAs.\r\nIT: AI tools, intelligence platforms (PowerApp for PIN), GoTrack audit module.",
        "what_is_actually_done": "Regulatory & Pharmacopoeial Intelligence (RIN/PIN): Manages RIN/PIN using AI for automated checks of external requirements against internal standards, proposing adaptations, generating change requests, and supporting impact assessments. (QA13) Audit & Inspection Learnings: Leverages learnings from audits/inspections, using AI to summarize reports, ensure regulatory basis for observations, and communicate findings effectively. (QA14) Observation Follow-up Automation: Automates the follow-up of audit observations, including assigning CAPAs to external parties and tracking completion. (QA15) Conducts Quality Audits (internal, external/supplier). Manages Regulatory Intelligence processes. Manages Pharmacopoeial Intelligence processes.\r\n\r\n## 3. Audit and Intelligence\r\n\r\n**Purpose:**\r\nProvides ongoing oversight, ensuring compliance with regulations and adapting to new requirements.\r\n\r\n**Key Tasks:**\r\n\r\n- **Quality Audits:** Systematic checks of internal departments and external partners for compliance.\r\n- **Regulatory Intelligence:** Monitoring new or updated regulations and assessing their impact.\r\n- **Learning from Audits:** Documenting and acting on audit findings to drive improvements.\r\n- **Observation Follow-up:** Tracking and ensuring completion of corrective actions.\r\n\r\n**Value:**\r\nMaintains high standards, ensures compliance, and helps the company adapt to regulatory changes.",
        "pain_points": "Manual, time-consuming, and risk-prone RIN/PIN processes, especially for supporting CMOs with RI. (QA13, P26)\r\nPIN/RIN data handled in non-validated systems (PowerApp for PIN) lacking IT support and struggling with data volume. (P26)\r\nDifficult to connect audit data to sites; lack of structured fields. (P26)\r\nAudit observations not consistently attributed to correct categories. (P26)\r\nMedDev/CP requirements not widely known by auditors/auditees. (P26)\r\nLow quality of Master Data Management (MDM) for vendors/suppliers in GoTrack audit module. (P26)\r\nDelays and confidentiality issues in documenting passive audit information. (P26)\r\nSignificant time demanded from local sites for audit preparations due to lack of continuous audit readiness. (P26)\r\nInconsistent/inefficient QMS categories for audit findings. (P26)\r\nLack of an easily accessible overview of audit results. (P26)\r\nAuditor qualification is a manual and error-prone process. (P26)\r\nMandatory impact assessment for sites potentially affected by audit/RIN/PIN findings. (P26)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 20,
        "bi_id": "PS-QA-006",
        "name": "06 | Validation and qualification",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo accelerate industrialization and enable data-driven decisions by providing purposefully tailored data and automating qualification and validation processes across the entire product and system lifecycle.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Validation Document Generation:** Automating the generation of System Life Cycle (SLC) and product lifecycle document drafts (e.g., for Computer System Validation (CSV), Data Integrity Risk Assessments, qualification, validation) using AI and incorporating risk-based approaches.\r\n-   **Digital Document Integration:** Ensuring SLC and all validation/qualification documents are digitally integrated over their lifecycle for enhanced traceability.\r\n-   **Process Validation:** Providing documented evidence that manufacturing processes consistently produce quality products meeting predetermined specifications.\r\n-   **Cleaning & Transport Validation:** Ensuring cleaning procedures consistently remove residues from manufacturing equipment and that transport conditions maintain product quality during transit.\r\n-   **Computer System Validation (CSV):** Verifying that computer systems used in GxP-regulated activities function as intended, maintain data integrity, and comply with regulatory requirements.\r\n-   **Equipment Qualification:** Documented verification that manufacturing and lab equipment is suitable for its intended purpose through Installation (IQ), Operational (OQ), and Performance Qualification (PQ).\r\n\r\n**Value:**\r\nAccelerates product industrialization and strengthens regulatory compliance by automating and integrating validation processes. This reduces manual effort, improves consistency and traceability of documentation, enables data-driven decision-making, and provides robust assurance that all equipment, systems, and processes reliably produce high-quality, safe products.",
        "raw_content": null,
        "summary": "This area focuses on accelerating industrialization and enabling data-driven decisions through purposefully tailored data provision and automated qualification and validation processes across the product and system lifecycle.",
        "vision_statement": "With purposefully tailored data provision and automated qualification & validation we accelerate industrialization and data-driven decisions",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing (PS-M-XXX): Processes, equipment, and systems requiring validation/qualification.\r\nQuality Control (PS-QC-XXX): Analytical methods validation, lab equipment qualification.\r\nEngineering/Maintenance (PS-MAINT-XXX): Facility, utility, and equipment qualification.\r\nIT: Computer systems requiring validation (CSV), data sources for AI-assisted documentation.\r\nSupply Chain Management (PS-SCM-XXX): Transport validation.\r\nPS-QA-002 (Product related QA enabling processes): Changes to products/processes trigger re-validation.\r\nPS-QA-005 (Production and process control): CCS linked to cleaning validation.\r\nDevelopment/R&D: Input for process validation (e.g., development data for transfer plans).",
        "what_is_actually_done": "Automated Document Draft Generation: Automates the generation of System Life Cycle (SLC) document drafts (e.g., for CSV, Data Integrity Risk Assessments) and product lifecycle document drafts (qualification, validation) using AI, incorporating risk-based approaches and historical data. (QA24) Digital Document Integration: Ensures SLC and other validation/qualification documents are digitally integrated over their lifecycle for enhanced traceability. (QA25) Manages Transport Qualification/Validation. Oversees Process Validation activities. Manages Cleaning Validation. Manages Computer System Validation (CSV).\r\n\r\n## 6. Validation and Qualification\r\n\r\n**Purpose:**\r\nProvides documented proof that equipment, systems, and processes consistently meet required standards.\r\n\r\n**Key Tasks:**\r\n\r\n- **Equipment Qualification:** Verifying equipment is fit for use.\r\n- **Process Validation:** Proving that manufacturing processes consistently deliver quality products.\r\n- **Cleaning Validation:** Ensuring cleaning procedures prevent cross-contamination.\r\n- **Computer System Validation:** Ensuring IT systems work as intended and protect data.\r\n- **Transport Qualification:** Making sure transport conditions don\u2019t harm product quality.\r\n- **Documentation:** Keeping thorough records for all validation activities.\r\n\r\n**Value:**\r\nAssures regulators and patients that products are made with reliable, capable processes and equipment.",
        "pain_points": "Inefficient, inconsistent, and manual creation of SLC, qualification, and validation documents. (QA24)\r\nLack of AI-supported writing for Validation Documents. (P27)\r\nLimited experience with external launches concerning validation efforts. (P27)\r\nNeed for automated testing for validation purposes. (P27)\r\nChallenging application of statistical approaches (matrixing/bracketing, sampling plans) in transfers/Process Validation. (QA24, P27)\r\nContinued Process Verification (CPV) is still very manual with minimal data integration. (P27)\r\nDifficult traceability of SLC documents throughout their lifecycle. (QA25)\r\nLack of automated traceability for validation documentation. (P27)\r\nValidation reports, including data assessment, are mainly created manually. (P27)\r\nBenchmarking and authority trends for validation strategies are not easily accessible. (P27)\r\nUnclear validation requirements (what to check against what). (P27)\r\nNo central overview/repository for stability data relevant to PV. (P27)\r\nSignificant manual execution in cleaning validation (sampling, batch marking, translating results to master recipes). (P27)\r\nInconsistent risk-based approaches for cleaning validation across sites for similar equipment. (P27)\r\nRisk assessments and testing strategies are not effectively integrated into data systems for leverage in validation. (P27)\r\nNeed for connectivity to master data (GBS) for Medical Devices, Data Integrity, CSV. (P27)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 21,
        "bi_id": "PS-QC-003",
        "name": "03 | SAMPLING AND SAMPLE STORAGE",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo automate sampling, handling, and storage activities, ensuring they are traceable and synchronized with real-time visibility and efficient distribution, mitigating sampling errors.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Automated Sample Tracking:** Implement automated systems (e.g., RFID, barcodes, cameras) for real-time tracking of samples throughout their lifecycle, including location updates in storage and alerts for movement/status deviations.\r\n-   **Condition Monitoring:** Ensure proper sample conditions with guided workflows, triggering warnings if samples are handled or stored incorrectly (e.g., temperature excursions).\r\n-   **Paperless Documentation:** Implement paperless, electronic documentation for all sampling events, digitally logging data, ensuring real-time entry and validation, and integrating with existing documentation systems (SAP QM, MES).\r\n-   **Automated Storage Systems:** Utilize automated storage systems to efficiently manage large volumes of samples with intelligent temperature/humidity control and digital authorization for access.\r\n-   **Seamless Production-Lab Interface:** Develop a seamless interface between production (MES) and lab software (LIMS/SAP QM) to automate sample transfer, enable real-time data synchronization (e.g., 'Live-Tracking' of Batch status), and facilitate IPC result transfer.\r\n\r\n**Value:**\r\nReduces sampling errors and ensures sample integrity through end-to-end traceability and real-time condition monitoring. It eliminates manual, paper-based processes, reduces operator workload, improves data integrity by minimizing system breaks, and significantly accelerates sample retrieval, ensuring proper sample handling from collection to disposal.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Sampling, handling and storage activities are automated, traceable, and synchronized, with real-time visibility and efficient distribution",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing Execution Systems (MES) / Production: For initiating sampling, sample labeling, and receiving sample status/IPC results. (QC10, QC12)\r\nLaboratory Information Management Systems (LIMS) / SAP QM: For receiving sample data, managing test orders, and storing sampling documentation. (QC10, QC12)\r\nInventory Management Systems: For tracking sample locations and quantities. (QC09)\r\nEquipment Management (QC07): For ensuring availability of sampling equipment.\r\nTesting Preparation and Execution (QC04): For handover of samples for testing.\r\nAsset Administration Shell: For live-tracking of batch status. (USE CASE 10)",
        "what_is_actually_done": "Implement an automated system (e.g., using RFID, barcodes, cameras) for tracking samples throughout their lifecycle. Provide real-time tracking, location updates (including digital localization in fridges), and alerts for sample movement/status. Ensure proper sample conditions with guided workflows and trigger warnings if handled/stored incorrectly. Integrate with lab and inventory systems (QC09 / USE CASE 12). Implement paperless, electronic documentation for all sampling events. Ensure digital logging of sampling events, real-time data entry and validation. Integrate with existing documentation systems (SAP QM, MES) for secure storage and easy retrieval. Document all information on how a sample is handled, including temperature control and other live data (QC10 / USE CASE 11). Utilize automated storage systems to efficiently manage large volumes of samples. Implement intelligent storage with temperature and humidity control. Ensure storage is locked and accessible only with digital authorization (e.g., card reader) (QC11 / USE CASE 13). Develop a seamless interface between production (MES) and lab software (LIMS/SAP QM). Automate the process of sending samples for analysis, including sample transfer from production to lab. Enable real-time data synchronization, including sample status ('Live-Tracking' of Batch) and IPC result transfer. Support sampling/labeling in MES with data transfer to LIMS (QC12 / USE CASE 10).",
        "pain_points": "No clear approach for sample handover.\r\nDifficulties in reconciliation of samples.\r\nUnclear documentation location for sampling (Production vs. QC).\r\nLack of sample tracking, especially for temperature-controlled samples.\r\nManual paper-based and copy/paste processes for sampling documentation.\r\nSampling and labeling in MES, but data transfer to/from LIMS is problematic.\r\nDifficulty identifying samples in freezers.\r\nInadequate sample tracking from sampling until disposal.\r\nOperator needs to switch between multiple systems (and learn them).\r\nSampling documentation is often paper-based (SDI).\r\nQualification of sample takers needs to be verifiable by QC.\r\nDifferent UIs for several software systems, high training effort, system breaks. (USE CASE 10)\r\nAccess for sample takers to SAP/QM often not given. (USE CASE 11)\r\nData integrity issues due to system breaks in manual data transfer. (USE CASE 11)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 22,
        "bi_id": "PS-QA-008",
        "name": "08 | Product release, packaging & labelling",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo ensure that only compliant, correctly labeled, and authentic products are released to market by establishing fully digitalized processes and seamless data integration across the supply chain, enabling automated batch release and full product traceability.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Digital Batch Release Hub:** Establishing a centralized digital platform for batch disposition, consolidating all relevant information to support automated release decisions, dossier compliance checks, and compliant certificate generation (CoA/CoC).\r\n-   **Advanced Global Batch Traceability:** Implementing comprehensive global batch traceability, including for CMOs and potentially down to unit-level, using technologies like blockchain for security and integrity.\r\n-   **Integrated Artwork Management:** Managing the creation, approval, and revision of all product labeling and packaging artwork via an integrated tool to ensure accuracy, regulatory compliance, and seamless data handover.\r\n-   **AI-supported Anti-Counterfeiting:** Managing anti-counterfeiting investigations and activities using AI for detection (on/offline), intelligence gathering, case management, risk-based measure bundling, and effectiveness assessment.\r\n-   **Packaging & Logistics Oversight:** Providing Quality Assurance oversight for packaging/repackaging operations and logistics/distribution to ensure GxP adherence and supply chain integrity.\r\n\r\n**Value:**\r\nSafeguards patient safety and company reputation by ensuring only high-quality, authentic, and compliant products reach the market efficiently. This digital transformation reduces manual errors and effort, accelerates batch release, enhances global traceability, strengthens anti-counterfeiting measures, and streamlines labeling processes, minimizing market actions and ensuring reliable product supply.",
        "raw_content": null,
        "summary": "This area focuses on achieving fully digitalized processes and seamless data integration across the supply chain to enable automated, compliant batch release and full product traceability.",
        "vision_statement": "Fully digitalized processes and seamless integration of data and supply chain enables automated batch release and full traceability of our products",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing (PS-M-XXX): Batch records, packaging information, production data for release.\r\nQuality Control (PS-QC-XXX): Batch testing results for release.\r\nSupply Chain Management (PS-SCM-XXX): Logistics, distribution, inventory, serialization, anti-counterfeiting operations, artwork lifecycle management.\r\nRegulatory Affairs: Approved labeling, dossier information for release compliance, country-specific requirements.\r\nPS-QA-004 (Non-conformance and event management): Open deviations or investigations impacting batch release.\r\nExternal Partners (CMOs): Batch release information, traceability data from/to CMOs.\r\nLegal: Anti-counterfeiting activities, market actions.\r\nIT: Batch release systems, traceability platforms, artwork management tools, AI for anti-counterfeiting.",
        "what_is_actually_done": "Digital Batch Release Hub: Establishes a centralized digital hub for batch release, providing all relevant information at a glance, supporting automated release decisions, dossier compliance checks (vs. RIM/CPD3), and flexible generation of certificates (CoA/CoC). (QA28) Advanced Global Batch Traceability: Implements comprehensive global batch traceability, including for CMOs and potentially down to unit-level, using technologies like blockchain for security and integrity. (QA29/QA30-text) AI-supported Anti-Counterfeiting: Manages anti-counterfeiting investigations and activities using AI for detection (on/offline), intelligence gathering, case management, risk-based measure bundling, and effectiveness assessment. (QA30/QA31-text) Integrated Artwork Management: Implements an integrated tool for artwork management to reduce manual effort and ensure seamless handover of labeling data (from RA to packaging). (QA31/QA29-text) Ensures Supply Chain Integrity (coding, anti-counterfeiting). Manages Artwork Management & External Labeling processes. Provides QA oversight for Packaging & Repackaging operations. Provides QA oversight for Logistics & Distribution. Manages Batch Disposition processes.\r\n\r\n\r\n## 8. Product Release, Packaging \\& Labelling\r\n\r\n**Purpose:**\r\nEnsures only compliant, correctly labeled products are released, with full traceability and protection against counterfeiting.\r\n\r\n**Key Tasks:**\r\n\r\n- **Batch Release:** Final review and approval of each batch before it goes to market.\r\n- **Digital Release Systems:** Centralizing information for efficient, compliant release.\r\n- **Supply Chain Integrity:** Using serialization and anti-counterfeiting measures.\r\n- **Artwork and Labeling:** Managing creation and approval of all packaging and labels.\r\n- **Packaging Oversight:** Ensuring correct and compliant packaging.\r\n- **Logistics Oversight:** Ensuring proper storage and transport.\r\n- **Batch Traceability:** Tracking products through the entire supply chain.\r\n\r\n**Value:**\r\nProtects patients and the company\u2019s reputation by ensuring only high-quality, authentic products reach the market[^1].",
        "pain_points": "Lack of a central system for batch release; manual compliance checks; all relevant data for release not in one system. (QA28, P28)\r\nIncomplete global batch traceability, especially for CMOs and down to unit-level. (QA30-text, P28)\r\nManual, potentially biased screening and management of anti-counterfeiting measures; Case IQ not globally rolled out. (QA31-text, P28)\r\nManual work and disconnects in artwork management processes between Medicine & OPS. (QA29-text)\r\nGS1 not established as a central standard for BI products. (P28)\r\nHighly complex, manual systems to ensure country-specific suitability for OCs (Pharma LIMS). (P28)\r\nProduct development information (IU) not easily accessible to OPS for troubleshooting. (P28)\r\nHigh number of potential market actions due to labeling issues. (P28)\r\nUpcoming system changes (GBS United) might negatively impact paperless release potential. (P28)\r\nManual transfer of variable data requirements to packaging lines. (P28)\r\nComplex batch record review for new/launch products due to multiple requirement sources. (QA28, P28)\r\nLack of a global Batch Release Hub. (P28)\r\nChallenges with label/packaging material reconciliation. (P28)\r\nNo end-to-end approach for label data and changes. (P28)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 23,
        "bi_id": "PS-QC-005",
        "name": "05 | RESULT GENERATION, EVALUATION & RELEASE",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo ensure efficient and accurate results through AI-supported evaluation and automated review by exception, accelerating the release process.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Automated Result Comparison:** Automate the comparison of analytical results and executed steps against predefined limits and procedures, requiring manual review/approval only in case of exceptions (OOS, deviations, pattern violations).\r\n-   **AI-Based Batch Simulation:** Utilize AI-based batch simulation to potentially reduce the number of quality tests required.\r\n-   **One-Button Batch Release:** Implement a \"one-button\" batch release or a batch release cockpit with interfaces to all source systems, automating SAP QM usage decisions and generating harmonized CoAs automatically.\r\n-   **Real-Time Dashboards:** Provide real-time QC dashboards for status, automated checks, and validations of results and test status.\r\n-   **Automated Result Processing & Evaluation:** Automate QC result generation (data processing, calculation) and evaluation against predefined limits, processing raw data through different layers and using AI/machine learning for pattern evaluation.\r\n-   **Guided Review Workflows:** Implement automated, step-by-step workflows for QC review and release when \"review by exception\" is not fully in place, digitalizing paper checklists and automating task assignments and compliance checks.\r\n\r\n**Value:**\r\nAccelerates batch release by automating data evaluation, comparison, and approval processes, reducing manual checks and the risk of human error. It enables a \"review-by-exception\" model, freeing up resources and ensuring faster time-to-market. AI support improves accuracy, identifies potential issues proactively, and streamlines compliance checks, providing a robust and efficient release mechanism.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We uses AI-supported evaluation and automated review by exception, to ensure efficient and accurate results",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Testing Preparation and Execution (QC04): For receiving raw data and test records.\r\nSpecification Creation and Handling (QC02): For specifications and limits.\r\nLIMS/LES/AMET: For accessing results, methods, and managing release status. (QC20, QC21, QC22)\r\nERP (e.g., SAP QM): For usage decisions and batch release. (QC21)\r\nData Analytics Platforms (QC06): For providing data for trending and receiving insights that might influence release decisions.\r\nDocument Management Systems: For storing CoAs and release documentation. (QC21)\r\nCompliance Management Systems: For automated compliance checks. (QC20, QC23)\r\nQuality Assurance (QA): For final batch disposition after QC release.",
        "what_is_actually_done": "Automate the comparison of analytical results and executed steps against limits and procedures. Require manual review/approval by compliance teams only in case of exceptions (OOS, deviations, pattern violations). Utilize AI-based batch simulation to potentially reduce the number of quality tests. Integrate with compliance management systems for automated checks and notifications (QC20 / USE CASE 22). Implement a \"one-button\" batch release or a batch release cockpit with interfaces to all source systems. Automate SAP QM usage decisions. Provide real-time QC dashboards for status, automated checks and validations of results and test status. Automate plausibility checks of analytical results and raw data. Generate harmonized CoA automatically (QC21 / USE CASE 21). Automate QC result generation (data processing, calculation) and evaluation against predefined limits. Process raw data automatically through different layers. Consider the whole analytical panel of a product for evaluation. Transfer results automatically from source systems into LIMS. Use AI/machine learning for pattern evaluation. Provide standardized QC result reports and automated notifications (QC22 / USE CASE 23). Implement automated, step-by-step workflows for QC review and release if \"review by exception\" is not fully in place. Digitalize paper checklists. Automate task assignments, tracking, and compliance checks for GxP data. Integrate with QC management systems (QC23 / USE CASE 25).",
        "pain_points": "Functionalities of existing systems are not equally adopted.\r\nManual comparison of test results against ranges (at some sites).\r\nQC KPIs are manually created, heterogeneous, leading to a lack of actionability.\r\nNo common understanding of Out of Specification (OoS).\r\nMissing interface to the LIMS layer, leading to manual data transfer and high review effort (time, money).\r\nNo automated comparison against specifications/limits.\r\nLack of governance (should be 1 product, 1 standard).\r\nVendor software is not user-friendly, outdated, and buggy.\r\nData Integrity (DI) gaps in standard solutions from instrument suppliers.\r\nMany manual checks creating high effort for QC release. (USE CASE 21)\r\nVery difficult to check all data in all systems for release. (USE CASE 21)\r\nRisk of human error in manual checks. (USE CASE 21)\r\nPlausibility checks are high effort and complex. (USE CASE 21)\r\nManual checks, multiple review and approval steps. (USE CASE 22)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 24,
        "bi_id": "PS-QC-007",
        "name": "07 | QC EQUIPMENT READINESS",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo ensure standardized lab equipment is fully connected, providing constant transparency on equipment-related data and status for seamless operation, maximizing uptime.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Unified Equipment Management System:** Maintain a comprehensive digital database and logbook (e.g., SAP PM) for all equipment data (qualifications, calibrations, history, maintenance, status), providing a centralized repository with a traffic light system for current status and blocking usage if not ready.\r\n-   **Predictive Maintenance:** Optimize maintenance activities based on use cycles/historical data (AI-based) and use IoT for equipment connectivity, enabling real-time monitoring and data collection to predict equipment failures proactively.\r\n-   **Global Standardization:** Establish and govern global standards for lab equipment catalogue, assets tracking, purchase, replacement, and Capex planning, focusing on standardized equipment across all sites.\r\n-   **Automated Periodic Review:** Automate (or semi-automate) the periodic review for computer systems, equipment, methods, and validations, ensuring the review considers all relevant data and evaluates for negative trends.\r\n-   **Digital Maintenance Logbooks:** Implement digital equipment logbooks interfaced with LIMS, Trackwise, etc., digitalizing paper checklists and enabling paperless documentation and logbook entries for maintenance with mobile capabilities.\r\n-   **Harmonized Maintenance Organization:** Establish a harmonized and centralized organization for QC maintenance activities.\r\n\r\n**Value:**\r\nMaximizes equipment uptime and efficiency by providing real-time transparency on status and automating maintenance planning. It reduces unplanned outages, minimizes costs associated with non-standard equipment purchases and varied procedures, and streamlines compliance through automated periodic reviews and digital documentation. This ensures consistent lab operations and reduces training and spare part inventories.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We use standardized lab equipment, that is fully connected, while always having transparency on equipment related data and status to operate seamlessly",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Lab Planning and Scheduling (QC01): To provide equipment availability and status for planning. (QC27)\r\nTesting Preparation and Execution (QC04): To ensure equipment is ready for use and to block usage if not. (QC27)\r\nProcurement/Finance: For Capex planning, purchasing, and supplier management. (QC28)\r\nLIMS/Trackwise: For interfacing digital logbooks and maintenance data. (QC31)\r\nSAP PM: As a potential central system for equipment management and maintenance. (QC27, QC31)\r\nIT Systems: For IoT connectivity and data platforms. (QC30)\r\nValidation Departments: For periodic reviews of validated systems/methods. (QC29)\r\nExternal Suppliers/Maintenance Providers: For maintenance activities and data handover. (QC27)",
        "what_is_actually_done": "Maintain a comprehensive digital database and logbook (e.g., SAP PM) for all equipment data (qualifications, calibrations, daily checks, history, maintenance, status). Provide a centralized equipment data repository with a traffic light system for current status. Block equipment usage if not ready. Optimize maintenance activities based on use cycles/historical data (AI-based). Enrich metadata in SAP/PM for harmonization (QC27 / USE CASE 31). Establish and govern global standards for lab equipment catalogue, assets tracking, purchase, replacement, and Capex planning. Implement process/system control points to check purchases against the standard equipment catalogue. Focus on standardized equipment across all sites (QC28 / USE CASE 32). Automate (or semi-automate initially) the periodic review for computer systems, equipment, methods, validation, and Excel files. Ensure the review considers all relevant data (events, deviations, changes, SLC docs). Evaluate for negative trends (QC29 / USE CASE 35). Use IoT for equipment connectivity, enabling real-time monitoring and data collection. Implement predictive maintenance, supported by AI, based on available data and usage. Predict equipment failures proactively. Flexibly connect EQs and solutions in a standardized way via an architectural connectivity layer (QC30 / USE CASE 34). Implement digital equipment logbooks interfaced with LIMS, Trackwise, etc. Digitalize paper checklists for lab equipment maintenance. Make all system-related tasks and statuses visible and checked by electronic systems (no stickers except ID on equipment). Enable paperless documentation and logbook entries for maintenance, with connected systems and mobile maintenance capabilities. Use predictive models (AI-driven) to forecast maintenance needs and enable proactive scheduling (QC31 / USE CASE 33). Establish a harmonized and centralized organization for QC maintenance activities, potentially starting semi-automated (USE CASE 36).",
        "pain_points": "Equipment is not standardized.\r\nDifferent equipment from different vendors requires multiple systems.\r\nDifferent, non-standardized procedures for calibration and set-up of equipment.\r\nNo transparency on equipment status.\r\nNo central equipment inventory (status, calibration, etc.).\r\nManual periodic review for lab equipment.\r\nNo (physical) equipment standards.\r\nNo global (protocol) standard for equipment set-up.\r\nNo lab equipment database (e.g., available equipment in my lab).\r\nNo electronic handover of documentation from supplier to BI.\r\nBusiness process for usage of SAP/PM not globally standardized.\r\nGxP logbook for computerized systems (IT, Business, etc.) frontend not user-friendly.\r\nEquipment information is not available in a harmonized, transparent system. (USE CASE 31)\r\nInformation required for planning lab activities, maintenance, etc., is time-consuming to obtain. (USE CASE 31)\r\nNo strong central governance on equipment purchases by sites against global standard catalogue. (USE CASE 32)\r\nPotential for lost/mis-allocated Capex investments due to non-standard equipment purchases. (USE CASE 32)\r\nMaintenance documentation is often paper-based. (QC31 / USE CASE 33)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 25,
        "bi_id": "PS-MFG-002",
        "name": "02 | MANUFACTURING PROCESSES",
        "area_id": 7,
        "step_description": "**Purpose:**\r\nTo execute commercial, test, and technical batches through automated, intelligent, and integrated processes, driving efficiency and continuous improvement throughout the product and process lifecycle.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Digital Batch Execution:** Creating, managing, and executing digitally supported Master Batch Records (MBRs) and master recipes with standardized templates for consistent and compliant production.\r\n-   **Automated Data Collection:** Automatically collecting and transferring process data to/from equipment and in-process control (IPC) devices, ensuring vertical integration and harmonized data definitions.\r\n-   **Real-time Monitoring:** Monitoring process parameters in real-time using inline measurements and sensors, providing dashboards and alerts for negative trends to enable early intervention.\r\n-   **Anomaly Detection & Troubleshooting:** Utilizing data simulation, AI, and machine learning to proactively detect anomalies, identify potential process or equipment issues, and support incident resolution.\r\n-   **Knowledge Transfer & Risk Assessment:** Leveraging a unified data source for R&D and Operations to assess process risks, define control strategies, and enable feedback loops for product/process development.\r\n-   **Operator Assistance:** Employing Augmented Reality (AR) to guide operators and mechanics through complex tasks like troubleshooting, process execution, and changeovers.\r\n\r\n**Value:**\r\nEnhances manufacturing efficiency and product quality by automating data flows, enabling real-time process monitoring, and providing proactive anomaly detection. This reduces manual errors, accelerates batch release processes, ensures consistent product quality, and facilitates seamless knowledge transfer from development to production, ultimately leading to more robust processes and faster delivery of medicines.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Automated, intelligent and integrated processes drive efficiency and continuous improvement throughout process and product lifecycle.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Production Planning & Scheduling: Receives production orders and schedules.\r\nSupply Chain Management (SCM): For intra-plant logistics until handover to production.\r\nQuality Control (QC): For IPC sampling, lab analysis (though aiming to reduce with inline testing), and batch release data.\r\nQuality Assurance (QA): For MBR compliance, deviation management, and batch release oversight.\r\nEngineering (GFE) / Automation: For equipment integration, sensor implementation, and automation solutions.\r\nIT & GBS: For MES, LIMS, ERP integration, data platforms (Dataland), and MBR system support.\r\nInnovation Unit Development (IU Dev): For seamless drug product knowledge transfer, DoE, and FMEA.\r\nMaintenance: For equipment status and troubleshooting (supported by AR).",
        "what_is_actually_done": "Conducting commercial production, test and technical batches, and new product introductions. Creating, managing, and executing digitally supported MBRs and master recipes, aiming for standardization, automated generation from templates, and a harmonized MBR library (M04). Automatically collecting and transferring data to/from equipment and IPC devices, ensuring vertical integration and harmonized data definitions (e.g., for draw, sample, analyze procedures) (M06). Monitoring process parameters in real-time using inline measurements and sensors, with dashboards and alerts for negative trends to enable early reaction and correction (M03). Using data simulation, AI, and machine learning to detect anomalies, identify potential process problems or equipment issues proactively during production, and support incident tackling (M08). Performing IPCs and leveraging PAT. Utilizing a unified data source/platform for IU Dev and Operations to assess process risks, define control strategies (FMEA, CSS), monitor product/process robustness, and enable a feedback loop from production to development (M05). Using AR for guiding operators/mechanics in tasks like troubleshooting, process execution (e.g., complex changeovers), setup, and identifying errors (M09). Collecting data relevant for batch release from the execution process (M07 related activities). Managing intra-plant logistics (including material introduction to lines) and packaging operations.",
        "pain_points": "System breaks and lack of harmonization in MBR design and execution across sites.\r\nManual data transfer between systems and equipment; lack of fully vertical integration.\r\nDelayed identification and reaction to negative process trends or anomalies.\r\nHigh manual effort in launches and transfers due to fragmented drug product knowledge.\r\nLack of a unified data source between IU Dev and Operations for product knowledge.\r\nDifficulties in accessing real-time, comprehensive data for troubleshooting and process optimization.\r\nInconsistent IPC practices and data collection.\r\nLimited use of PAT and inline measurements, leading to reliance on time-consuming lab analytics.\r\nSuboptimal equipment utilization due to unforeseen failures or disturbances.\r\nLanguage differences and varying factory designs hindering process harmonization.\r\nHigh effort for MBR creation and review; lack of automated generation and validation.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 26,
        "bi_id": "PS-MFG-004",
        "name": "04 | EQUIPMENT & AUTOMATION LIFECYCLE PROCESS",
        "area_id": 7,
        "step_description": "**Purpose:**\r\nTo ensure full transparency of all equipment-related data throughout its lifecycle, from design to decommissioning, enabling efficient manufacturing and informed cross-functional decision-making.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Lifecycle Management:** Defining user requirements and technical specifications, factory planning, and managing how equipment is used and re-used across its lifecycle.\r\n-   **Real-time Status Tracking:** Implementing systems (e.g., geo-localization, NFC/RFID, online dashboards) to provide real-time transparency on the location and status (e.g., clean, calibrated, in use) of movable equipment and format parts.\r\n-   **Centralized Database:** Establishing and maintaining a globally accessible database of all production equipment, including performance data, qualification documents (URS, IQ, OQ, PQ), modification history, and standards.\r\n-   **Standardization & Harmonization:** Driving the standardization of equipment, vendors, and qualification procedures across sites to reduce variability and effort.\r\n-   **Data-driven Insights:** Supporting AI-assisted information retrieval from the equipment database to aid in decision-making and continuous improvement.\r\n\r\n**Value:**\r\nBoosts manufacturing efficiency and reduces operational risks by providing complete and real-time transparency into equipment status and history. This streamlines equipment management, reduces manual search times, facilitates standardization across global sites, simplifies audits, and enables data-driven decisions for equipment investments and maintenance, ultimately reducing downtime and enhancing compliance.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Throughout the life-cycle we have transparency on all equipment related data enabling efficient manufacturing and cross-functional decision making.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Engineering (GFE): For equipment design, URS, factory planning, automation solutions, and maintenance planning.\r\nIT: For database implementation, tracking systems, and data integration.\r\nMaintenance: For equipment history, calibration status, and maintenance procedures.\r\nQuality Assurance (QA): For qualification documentation, equipment standards, and validation.\r\nProduction Planning & Scheduling: For information on equipment availability and status.\r\nManufacturing Processes: For actual usage of equipment and feedback on performance.\r\nProcurement: For new equipment purchases and supplier selection based on standards.\r\nSupply Chain Management (SCM): Potentially for tracking of large containers or inter-factory equipment movements.",
        "what_is_actually_done": "Defining user requirements specifications (URS), technical specifications (TS), and factory planning for operating equipment and automation solutions. Managing the process of how equipment is used and re-used throughout its lifecycle. Implementing systems (e.g., geo-localization with trackers, NFC/RFID, online dashboards) to provide real-time transparency on the location and status (e.g., clean, calibrated, in use) of movable equipment and format parts. This includes automated identification and cross-checks (M14). Establishing and maintaining a globally accessible database of all production equipment, including performance data, qualification documents (URS, IQ, OQ, PQ), modification history, and standards. This supports equipment standardization, facilitates transfers/launches, and enables AI-assisted information retrieval (M15). Driving standardization of equipment, vendors (where feasible), and qualification procedures to reduce variability and effort.",
        "pain_points": "Different work processes and methods for demand management, validation, etc., between IT, GBS, GFE, and Business units.\r\nKnowledge management and best practices for equipment are highly person-dependent.\r\nLack of systematic tracking of equipment within factories (manual search).\r\nMedia breaks in engineering planning tools, limiting interoperability.\r\nVarying 'quality standards' for similar equipment across different sites.\r\nIncomplete or missing equipment history.\r\nScattered accountability for equipment lifecycle management.\r\nEquipment data (e.g., qualification status, performance) is not consistently or fully digitally available.\r\nEquipment is often managed disparately at each site (ordering, information, integration).\r\nDifficult to access and consolidate qualification data for equipment.\r\nManual and error-prone processes for tracking equipment and parts.\r\nSupplier selection processes do not sufficiently consider digital capabilities.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 27,
        "bi_id": "PS-MFG-005",
        "name": "05 | PRODUCT, SITE, PROCESS DATA USAGE",
        "area_id": 7,
        "step_description": "**Purpose:**\r\nTo make all production and process data easily accessible, of high quality, and usable by the right people at the right time, generating insights for production robustness and performance improvement.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Data Accessibility:** Making comprehensive production data, including data science insights, discrepancy management, and master batch records, readily available and usable.\r\n-   **Continuous Process Verification (CPV):** Utilizing real-time process data for continuous verification of process robustness and product quality, instead of relying solely on lab data.\r\n-   **Feedback Loops:** Establishing direct feedback mechanisms from manufacturing data to R&D (Innovation Unit Development) for continuous product and process improvement.\r\n-   **Assisted Deviation & CAPA Management:** Using AI and real-time data pools to accelerate deviation investigations and CAPA management, ensuring seamless product traceability and automated summary creation.\r\n-   **Self-Service Analytics:** Providing self-service data platforms for business users to perform their own analyses and evaluations, ensuring transparency of process, equipment, and product data.\r\n-   **Automated Documentation:** Automatically preparing documentation for audits and generating approval documents (e.g., registration documents) using development and production data, leveraging AI.\r\n-   **Multi-Site Comparison:** Comparing IPC, lab, and process data across internal sites and CMOs for multi-site CPV, batch comparison, troubleshooting, and process optimization using AI.\r\n\r\n**Value:**\r\nDramatically improves process robustness and performance by transforming raw production data into actionable insights. This accelerates deviation resolution, streamlines compliance documentation, enables proactive continuous improvement through data-driven feedback, and fosters a culture of data-informed decision-making across the organization, leading to higher quality products and reduced operational costs.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Our process & product data are easily accessible by the right person at the right time with the right quality and enables us to generate insights for production robustness & performance.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing Processes: Source of production data (IPC, equipment data, batch records).\r\nQuality Control (QC): Lab data, IPC data, data for deviation management.\r\nQuality Assurance (QA): Data for CPV, deviation/CAPA management, audit preparation, approval documents.\r\nInnovation Unit Development (IU Dev): For data exchange related to launches, transfers, process robustness, and feedback for product/process development.\r\nIT & GBS: For data platforms (Dataland, GDTS), MES, LIMS, data governance, and AI tool support.\r\nData Science Teams: For advanced analytics, process modeling, and AI-driven insights.\r\nRegulatory Affairs (RA): For automated creation of registration documents.\r\nCorporate Quality Audits & Inspection: For automated audit preparation.",
        "what_is_actually_done": "Making production data (including data science insights, discrepancy management, data integrity information, and master batch records) available and usable. Using real-time data for Continuous Process Verification (CPV) and assessing 'Prozessrobustheit' (process robustness). Establishing feedback loops from manufacturing to IU (Innovation Unit Development) for continuous improvement. Using AI and real-time data pools to speed up deviation investigations and CAPA management, including seamless product traceability and automated summary creation (M16). Providing self-service data platforms (connected to Dataland) to enable business units to perform their own data analyses and evaluations, ensuring transparency of process, equipment, and product data (M17). Automatically preparing documentation for audits using production and quality data to reduce preparation time (M18). Using AI to automatically generate approval documents, such as registration documents, based on development and production data (MBRs, SOPs, etc.) (M19). Comparing IPC, lab data, and other process data across internal sites and CMOs for continuous process verification (Multi-Site-CPV), batch comparison, troubleshooting, and process optimization, leveraging AI where applicable (M20).",
        "pain_points": "Lack of equipment standards, including interface definitions for data exchange.\r\nNo unified system for data analysis; data often siloed.\r\nUncertainty regarding data storage locations and inconsistent data quality.\r\nDifficulties in transferring data smoothly from launch to routine production phases.\r\nLimited mobile availability of data.\r\nMissing batch context for sensor trend data, hindering analysis.\r\nProcess modeling and mining are not yet fully utilized.\r\nCPV monitoring relies heavily on lab data from LIMS instead of real-time IPC/process data.\r\nData, knowledge, and best-practice sharing across sites is manual or non-existent.\r\nMaster data processes are not well-established to ensure high-quality master data.\r\nLimited use of AI for data-driven support and insights.\r\nLack of a digital data backbone for shared use of batch data between Product Development (IU) and Product Lifecycle Management (HPS).\r\nMissing tools for self-service data access and analysis by business users.\r\nManual and time-consuming preparation of audit and approval documents.\r\nInefficient deviation and CAPA management due to manual data collection and analysis.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 28,
        "bi_id": "02",
        "name": "02 | Demand Planning / Sales Forecasting",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nGenerates accurate, consensus-driven demand forecasts that serve as the foundation for all supply chain planning, enabling optimal resource allocation and inventory management across the global network.\r\n\r\n**Key Tasks:**\r\n\r\n- **Statistical Forecasting:** Developing baseline demand forecasts using advanced analytics, historical data, and market intelligence across all product lifecycle phases.\r\n- **Commercial Integration:** Incorporating market insights, promotional plans, competitive intelligence, and physician adoption patterns into demand projections.\r\n- **Consensus Planning:** Facilitating cross-functional collaboration between commercial, medical, and supply chain teams to align on realistic demand expectations.\r\n- **Forecast Accuracy Management:** Monitoring forecast performance, identifying bias patterns, and implementing continuous improvement initiatives to enhance accuracy.\r\n- **Pipeline Forecasting:** Estimating demand for products in development to enable early capacity planning and supply chain preparation.\r\n- **Market Intelligence:** Analyzing external factors including competitive dynamics, regulatory changes, and economic conditions that impact demand patterns.\r\n\r\n**Value:**\r\nEnables right-sized production and inventory plans that balance customer service with cost efficiency, reduces inventory write-offs and shortages, and provides reliable foundation for capacity and financial planning\u2014ultimately ensuring patients have access to medicines when needed while optimizing working capital.",
        "raw_content": "Demand Planning / Sales Forecasting: We create consensus demand plans using a segmented approach, combining automated statistics and manual inputs to deliver realistic 36 months forecasts across all life cycle phases. Vision statements: We enable accurate planning through integrated next-generation real-time data and extended planning horizons. We drive forecast precision with an integrated 36-month sales forecast real-time data access across the supply chain. We optimize demand visibility through seamless forecasting with integrated systems and real-time data availability. Pain Points: SC Planning depending on forecast accuracy and BIAS; Today only 24M, 36M needed; Interfacing efforts and not on demand availability of latest sales forecast figures in SCM planning system; Distributor FC not available; Consolidation of data - time lag; Tender Planning missing / link to simulation?; Different granularity in planning levels US plans in group SKUs and manually split the volumes in the corresponding local SKUs.; Manual adjustments to the demand planning forecast need to be consolidated in the global SKU.",
        "summary": "Creates consensus demand plans with segmented approach, combining automation and manual inputs for 36-month forecasts across all life cycle phases.",
        "vision_statement": "We create consensus demand plans using a segmented approach, combining automated statistics and manual inputs to deliver realistic 36 months forecasts across all life cycle phases.",
        "in_scope": "Prediction and consolidation of future product demand to create accurate market forecasts including volume planning, market trends analysis, and new product launch planning to ensure reliable input for supply chain planning processes; Describe what we need (link to NGSF project).",
        "out_of_scope": "M&S Forecast System; Validated Batch size determined; Maintenance; Spare-part management.",
        "interfaces_text": "Next Gen sales forecast.",
        "what_is_actually_done": "An integrated SAP IBP-based forecasting system replaces multiple FuturCast instances, providing a single global forecasting platform with unified data model, consolidated regional inputs through standardized interfaces, integrated workflow for forecast approval and consensus, and comprehensive audit trail for forecast changes. Real-time data integration eliminates weekly consolidation bottlenecks by ensuring continuous data flow from syndicated data sources (IQVIA, internal sales systems, marketing campaign management tools), avoiding batch processing delays through event-driven updates, providing instant visibility of market changes and competitive actions, and enabling rapid response to demand signals and market disruptions.\\n\\nMachine learning-based statistical forecasting automatically identifies complex patterns in historical data using advanced algorithms (ARIMA, neural networks, ensemble methods), generates highly accurate baseline forecasts with confidence intervals, incorporates external factors (seasonality, promotions, economic indicators), and continuously learns from forecast performance to improve accuracy. Advanced analytics combine multiple data sources including syndicated market data for competitive intelligence, social media sentiment analysis for brand perception trends, economic indicators for market growth projections, prescription data for physician adoption patterns, and patient adherence data for real-world effectiveness insights.\\n\\nSegmented forecasting approaches are tailored to different product lifecycle phases (launch, growth, maturity, decline) using distinct mathematical models, market characteristics (primary care vs. specialty, acute vs. chronic conditions), and geographical considerations (developed vs. emerging markets, regulatory environments). Automated bias detection and correction mechanisms systematically identify over/under-forecasting patterns by region/product, implement statistical correction factors, track bias improvement over time, and provide coaching recommendations for forecast analysts to improve their forecasting techniques.\\n\\nDemand planning and sales forecasting extend to a 36-month horizon supporting strategic capacity planning, long-term supplier contract negotiations, regulatory approval timeline planning, and investment decision making. Integration with long-range commercial planning (LRCP) ensures seamless planning across time horizons using consistent assumptions about market growth, competitive dynamics, pricing strategies, and regulatory timelines. Pipeline product forecasting supports early launch planning and capacity allocation by forecasting demand for products in development phases II and III, allowing early resource reservation and supply chain preparation, and enabling go/no-go decision support with commercial viability assessment.\\n\\nStreamlined consensus planning process includes integrated workflow with role-based approval hierarchies, automated conflict resolution suggestions, escalation procedures for unresolved disputes, and comprehensive documentation of forecast rationale. Real-time collaboration tools provide shared workspaces for cross-functional teams, integrated messaging and commenting systems, mobile access for field-based commercial teams, and video conferencing integration for virtual planning sessions. Exception-based management focuses planner attention on significant changes through intelligent alerting for unusual demand patterns, automated identification of forecast outliers, prioritized task lists based on business impact, and escalation procedures for critical forecast changes.\\n\\nSeamless integration with supply chain planning systems includes automated forecast publishing to MRP systems, real-time demand signal transmission to production planning, integrated S&OP process with supply/demand matching, and automatic trigger of supply plan updates based on forecast changes. Automated forecast distribution pushes updated forecasts to downstream planning processes including material requirements planning with explosion across BOMs, capacity planning with constraint checking, logistics planning with distribution requirements, and financial planning with revenue and cost implications. Real-time forecast performance monitoring includes accuracy dashboards with drill-down capabilities, automated alerts when accuracy drops below thresholds, root cause analysis for forecast errors, and continuous improvement recommendations based on performance analytics.",
        "pain_points": "SC Planning depending on forecast accuracy and BIAS; Today only 24M, 36M needed; Interfacing efforts and not on demand availability of latest sales forecast figures in SCM planning system; Distributor FC not available; Consolidation of data - time lag; Tender Planning missing / link to simulation?; Different granularity in planning levels US plans in group SKUs and manually split the volumes in the corresponding local SKUs.; Manual adjustments to the demand planning forecast need to be consolidated in the global SKU.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 29,
        "bi_id": "06",
        "name": "06 | Logistics",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nManages the safe, compliant, and efficient storage and handling of pharmaceutical products throughout the supply chain, maintaining product integrity while optimizing warehouse operations and distribution processes.\r\n\r\n**Key Tasks:**\r\n\r\n- **Warehouse Management:** Operating warehouses and distribution centers with optimal space utilization, efficient material flows, and strict environmental controls.\r\n- **Inventory Control:** Maintaining accurate inventory records, managing stock movements, and ensuring proper rotation of products based on expiry dates (FEFO principles).\r\n- **Material Handling:** Safely handling pharmaceutical products with appropriate environmental controls (temperature, humidity) and security measures.\r\n- **Quality Assurance:** Maintaining product integrity through proper storage conditions, contamination prevention, and batch tracking throughout the distribution process.\r\n- **Compliance Management:** Ensuring adherence to Good Distribution Practice (GDP), serialization requirements, and other regulatory standards across all logistics operations.\r\n- **Distribution Optimization:** Optimizing distribution networks, consolidating shipments, and managing last-mile delivery to minimize costs and maximize service levels.\r\n\r\n**Value:**\r\nMaintains product quality and safety throughout the distribution process, ensures regulatory compliance and traceability, optimizes logistics costs through efficient operations and network design, and provides reliable product availability to support customer service commitments and patient needs.",
        "raw_content": "Logistics: Our E2E logistics processes, based on real-time data, are digitalized, automated, and compliant to ensure adaptability and effective product supply across sites and networks. Vision statements: We store all our critical system that meets safety, customs, and environmental standards. Our smart coding and standard labels seamlessly connect every operation. Every step-from order entry to shipping and planning is fully digital. We rely on a single, reliable source of data that complies with all regulations. Our consistent coding approach and uniform labels integrate every facet of our operations. From receiving orders to shipping and capacity planning, every process is completely digital. All our data is housed in one trusted system ensuring full compliance with safety and legal requirements. Our clear coding strategy and standardized labels unify every step of our work. From order intake to shipping and capacity planning, every operation is fully digitized. Our Logistics execution processes, build on integrated real time data sets, are E2E (from supplier to 1st paying customer) digitalized, automized and compliant (EHS, legal, GDP, tax, customs) as to ensure adaptiveness to current and future requirements. This ensures efficient and effective supply of our products within the sites and the networks. Pain Points: No environmental condition concept for Boehringer (interface topic); S&A: automation of alert handling, alert transparency, trending; GPaS => Boehringer platform for patient interaction based on QR code on pack; Manual measurement of TOCS (temperature out of Cooled storage); Danger. goods classification (Interface between EHS+S System and BIX@); Import and Export Managment; Packaging Data are missing / Problem with EWM callculation and BIX@ packaging data; No E2E TOOR process in place across functions & sites; Manual Managemgmt. of (time-critical) non-standard transport issues; No paperless logistics: Goods receive order Checklists Internal Transportorders Picking Order Transport order; No Accurate Forecast (inbound and outbound) on the exact date; automatic production supply requires master data which logistics doesnt easily get from production planner or the one setting up the master data.; standardization - same labels for all would save time for relabeling, avoid mix ups; Pallet labels and container labels must be re-labeled; Standard for lables and codes: Foster harmonization/stan dardization (e.g. GS1) of product carton/shipping case and handling unit labelling (relevant information scannable) at P-OPUS/CMOs to allow for automated transportation planning / processes at sending and receiving sites and to ensure supply chain integrity; missing capability to plan WH capacity based/linked to FC, portfolio, material classification (DG, TMA, company, temp, status...); currently a lot of expired stock is not destroyed its booked as maschine test product - challenge is the differentiation for every factory; No set-up / support for production consolidation data.; Warehousing can limited production consolidation capacities (depending on product portfolio) -- > i.e. deep freeze storage; currently no automized proposal of MoT possible; Manual truck optimization done in Excel; equipment in correct unit of measure (change from units to pallets); Transport plannig with Excel.",
        "summary": "Digitalized, automated, and compliant E2E logistics processes based on real-time data to ensure adaptable and effective product supply across sites and networks.",
        "vision_statement": "Our E2E logistics processes, based on real-time data, are digitalized, automated, and compliant to ensure adaptability and effective product supply across sites and networks.",
        "in_scope": "Execution and tracking of physical product movements between company locations including shipping documentation, customs clearance for international shipments, carrier coordination, and delivery confirmation to ensure reliable product transfer. Guidance for Manufacturing (SOP, MBR, ....); Automized Process & Equipment Alerts - exception based.",
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "AI-driven warehouse capacity planning utilizes machine learning algorithms to predict future space needs based on demand forecasts, product portfolio changes, seasonal variations, and new product launches. The system optimizes storage layouts dynamically considering product characteristics (dimensions, weight, handling requirements), storage requirements (temperature, humidity, security), access frequency patterns, and material flow optimization. Automated storage assignment considers FEFO (First Expired, First Out) principles for pharmaceutical products, ABC analysis for optimal placement of fast/slow-moving items, batch segregation requirements for quality control, and cross-docking opportunities for direct shipments.\\n\\nReal-time inventory visibility across all locations provides accurate, up-to-the-minute stock counts for all products and locations, automated cycle counting with exception-based physical verification, real-time tracking of material movements and transactions, integration with production systems for work-in-progress visibility, and automated exception management with immediate alerts for discrepancies, negative stock situations, or unauthorized movements. The system maintains complete batch genealogy and traceability for all pharmaceutical products.\\n\\nComplete paperless logistics transformation eliminates manual documentation through digital receiving processes with barcode/RFID scanning and automated quality checks, electronic picking instructions with voice picking and RF scanning confirmation, digital packing with automated documentation generation and label printing, and electronic shipping processes with integrated carrier communication and tracking initiation. The system maintains complete digital audit trails for regulatory compliance and quality assurance.\\n\\nDigital documentation and workflow management include electronic checklists and work instructions accessible via mobile devices, automated routing for approvals with role-based access controls, digital signature capture for compliance documentation, and automated archive and retention management for regulatory requirements. Error reduction is achieved through validation rules, mandatory field checks, and automated data consistency verification.\\n\\nAutomated goods receipt, picking, and shipping processes include intelligent put-away optimization with system-directed location assignment, guided picking with optimized pick paths and wave planning, automated packing with dimension and weight verification, and automated loading with load planning optimization and trailer utilization maximization. Exception-based manual intervention ensures human attention focuses only on situations requiring judgment or problem-solving.\\n\\nIntegrated simulation tools for warehouse capacity and transport planning connect directly to supply chain systems, enabling simulation of new product launch impacts on warehouse space requirements, optimization of fleet size and composition based on demand patterns, analysis of peak season capacity requirements with temporary resource planning, and evaluation of automation investments with ROI analysis and implementation planning.\\n\\nAutomated transport mode selection utilizes decision engines that evaluate air, ocean, and ground transport options based on shipment characteristics (urgency, value, size, weight), cost considerations (freight rates, fuel surcharges, accessorial fees), service requirements (transit time, delivery windows, tracking needs), and sustainability goals (carbon footprint, environmental impact). The system continuously learns from historical performance to improve selection algorithms.\\n\\nIntelligent consolidation planning optimizes cost, service, and sustainability across the network by combining multiple smaller shipments into full truckloads, coordinating shipments across different customers and products, optimizing routing for multi-stop deliveries, and balancing consolidation benefits against service level requirements. Advanced algorithms consider inventory carrying costs, customer service requirements, and transportation cost structures.\\n\\nGlobal standardization implements a single BI pallet and case label standard across all locations and suppliers, ensuring consistent labeling format for all incoming and outgoing goods, standardized dimensions and specifications for handling equipment compatibility, integrated tracking and identification systems, and supplier compliance programs ensuring adherence to BI standards from point of origin.\\n\\nHarmonized product labeling and coding strategy includes comprehensive Serialization & Authentication (S&A) implementation with unique product identifiers and anti-counterfeiting measures, Global Patient Authentication Service (GPaS) enabling patient interaction through QR codes for product verification and information access, consistent use of barcodes, 2D codes, and RFID tags for tracking and identification, and integrated track-and-trace capabilities meeting regulatory requirements across all markets.\\n\\nStandardized processes and systems across all sites provide common operating procedures for all warehousing activities while maintaining flexibility for local regulatory requirements, unified training programs ensuring consistent skill levels globally, shared best practices with continuous improvement programs, and common technology platforms enabling global visibility and optimization while accommodating local system requirements.\\n\\nEnd-to-end TOOR (Temperature Out of Refrigerator) processes provide comprehensive cold chain management with continuous temperature monitoring from production through delivery, automated alerts for temperature excursions with immediate stakeholder notification, real-time visibility of cold chain status across all locations and transportation modes, and automated documentation for regulatory compliance and quality assurance. The system maintains complete temperature history for all temperature-sensitive products.\\n\\nComprehensive environmental condition management extends beyond temperature to include humidity monitoring and control for moisture-sensitive products, controlled atmosphere storage for specialized products, clean room and sterile storage capabilities, and hazardous material storage with appropriate safety and regulatory controls. Automated monitoring systems provide continuous surveillance with exception-based alerting and trending analysis.\\n\\nAutomated compliance monitoring ensures adherence to Good Distribution Practice (GDP) requirements with automated documentation and audit trail generation, Environmental Health and Safety (EHS) compliance with incident tracking and corrective action management, customs and trade compliance with proper documentation and declarations, and quality system compliance with batch tracking, deviation management, and CAPA (Corrective and Preventive Action) integration.\\n\\nGPaS (Global Patient Authentication Service) platform enables comprehensive patient interaction including QR code scanning for product authenticity verification, access to patient information and support resources, adverse event reporting with direct connection to pharmacovigilance systems, and medication adherence support with reminders and education materials. The platform supports multiple languages and regional requirements while maintaining global consistency.\\n\\nSingle source of truth for logistics data consolidates all relevant information including product master data with complete logistics attributes, location master data with capabilities and operating parameters, transportation master data with routes, carriers, and service levels, regulatory data with requirements by country and product, and performance data with KPIs and benchmarks for continuous improvement.\\n\\nS&A (Serialization & Authentication) automation provides comprehensive anti-counterfeiting protection through unique serial number generation and tracking, automated detection of suspicious activity patterns, real-time verification capabilities for patients and healthcare providers, and integrated reporting to regulatory authorities and law enforcement. Advanced analytics identify counterfeit trends and support investigation activities.\\n\\nReal-time data availability across all logistics processes eliminates delays and enables immediate decision-making through instant updates on stock movements and availability, real-time shipment status and location tracking, immediate visibility of capacity and resource utilization, and dynamic updates of delivery schedules and customer notifications. Integration with all supply chain systems ensures consistent, accurate information across all functions.\\n\\nIntegrated master data management ensures data consistency and accuracy through central management of all logistics-related master data, automated synchronization across all systems and locations, comprehensive data governance with quality controls and validation rules, and role-based access controls ensuring data security and integrity. Advanced analytics provide insights into logistics performance including inventory turnover analysis with optimization recommendations, picking efficiency metrics with process improvement opportunities, transportation cost analysis with benchmarking and optimization suggestions, and overall logistics performance dashboards with drill-down capabilities for root cause analysis and continuous improvement.",
        "pain_points": "No environmental condition concept for Boehringer (interface topic); S&A: automation of alert handling, alert transparency, trending; GPaS => Boehringer platform for patient interaction based on QR code on pack; Manual measurement of TOCS (temperature out of Cooled storage); Danger. goods classification (Interface between EHS+S System and BIX@); Import and Export Managment; Packaging Data are missing / Problem with EWM callculation and BIX@ packaging data; No E2E TOOR process in place across functions & sites; Manual Managemgmt. of (time-critical) non-standard transport issues; No paperless logistics: Goods receive order Checklists Internal Transportorders Picking Order Transport order; No Accurate Forecast (inbound and outbound) on the exact date; automatic production supply requires master data which logistics doesnt easily get from production planner or the one setting up the master data.; standardization - same labels for all would save time for relabeling, avoid mix ups; Pallet labels and container labels must be re-labeled; Standard for lables and codes: Foster harmonization/stan dardization (e.g. GS1) of product carton/shipping case and handling unit labelling (relevant information scannable) at P-OPUS/CMOs to allow for automated transportation planning / processes at sending and receiving sites and to ensure supply chain integrity; missing capability to plan WH capacity based/linked to FC, portfolio, material classification (DG, TMA, company, temp, status...); currently a lot of expired stock is not destroyed its booked as maschine test product - challenge is the differentiation for every factory; No set-up / support for production consolidation data.; Warehousing can limited production consolidation capacities (depending on product portfolio) -- > i.e. deep freeze storage; currently no automized proposal of MoT possible; Manual truck optimization done in Excel; equipment in correct unit of measure (change from units to pallets); Transport plannig with Excel.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 30,
        "bi_id": "PM-E01",
        "name": "E01 | Data Collection & Analysis",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo establish a unified, real-time data foundation that enables automated, AI-supported analysis, ensuring consistent, reliable, and scalable performance insights across the organization.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Single Source of Truth:** Implementing a centralized, trusted data platform (e.g., data lake) that integrates data from all relevant systems as the single source of truth for performance management.\r\n-   **Harmonized Data Model:** Developing a harmonized data foundation and information model to ensure seamless integration, consistent definitions, and accurate interpretation of data across departments.\r\n-   **Automated KPI Calculation:** Automating KPI calculation in real-time, incorporating forward-looking capabilities like forecasting and trend analysis.\r\n-   **Advanced Analytics Tools:** Providing easy implementation and access to basic and advanced analytical tools, including AI-supported analysis for anomaly detection and pattern recognition.\r\n-   **Interconnected Data:** Ensuring data from different sources are interconnected, enabling holistic analysis and decision-making.\r\n-   **Smart Alerting Systems:** Implementing intelligent alerting systems to notify users of deviations, risks, or opportunities automatically.\r\n\r\n**Value:**\r\nProvides a robust and reliable data backbone for all performance management activities, eliminating manual effort, reducing data inconsistencies, and enabling rapid, data-driven decision-making. This fosters a common understanding of performance, supports advanced analytics, and ensures scalability across the organization.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Data from all relevant sources is seamlessly connected through standardized systems and available in real time, enabling smooth flexible analysis and decision-making across all levels.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "The first enabling process addresses data collection and analysis, recognizing that effective performance management requires unified, real-time data foundations that enable automated, AI-supported analysis. This process must overcome significant challenges including the absence of single sources of truth, lack of harmonized data foundations, and the prevalence of manual data entry processes that limit scalability and reliability.",
        "pain_points": "No single source of truth\r\nNo harmonized data foundation & information model\r\nvarious systems for the same purpose (PowerBI, Tableau, SAC, ....)\r\nNo real time, no forward looking automated KPI calculation\r\nstill many manual entries needed\r\nNo advanced/ AI supported analysis tools\r\nno automated aggregation\r\nNot inter linked data\r\nNot harmonized data in different sources\r\nNo alerting system (AI supported recognition of tendencies, abnormalities etc.)\r\nOften no sustainable data provision (Excel, paper sheets) -> not necessarily easy to integrate, manual effort required\r\ndata resolution and thereby interpretation is different\r\ndigital system incentivises positive behaviour instead of punishing the wrong one",
        "targets_text": "A centralized, trusted data platform ensures consistency and reliability across all performance data\r\nHarmonized Data Foundation and Information Model enables seamless integration and interpretation across systems and departments\r\nKPIs are calculated automatically in real time, with forward-looking capabilities (e.g., forecasting, trend analysis).\r\nRedundant tools (e.g., Power BI, Tableau, SAC) are streamlined or integrated into a cohesive analytics environment.\r\nData entry and aggregation are automated wherever possible\r\nData from different sources is interconnected\r\nsmart alerting systems notify users of deviations, risks, or opportunities in real time\r\nData is provided through robust, scalable systems\r\nData granularity is harmonized to support consistent interpretation across departments",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 31,
        "bi_id": "PS-QA-002",
        "name": "02 | Product related QA enabling processes",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo proactively manage changes and risks throughout the product lifecycle, ensuring sustained product quality and compliance through guided actions and data-driven insights.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Change Control Management:** Operating a harmonized, user-friendly system, leveraging AI for impact assessment, identifying recurrent events, and highlighting risks.\r\n-   **Annual Product Quality Reviews (APQR):** Automating or semi-automating APQR generation, including trend analysis and identifying improvement opportunities, and internalizing CMO Product Quality Reviews (PQRs).\r\n-   **Quality Risk Management:** Implementing proactive, automated risk management tools with AI-supported communication and an automated, centralized risk register.\r\n-   **Multi-site Data Analysis:** Comparing product quality data across manufacturing sites for proactive trend detection and differentiation of site vs. product issues.\r\n\r\n**Value:**\r\nEnsures consistent product quality and accelerates time-to-market by proactively managing changes and risks with enhanced data visibility. This reduces manual effort in complex processes, improves decision-making through automated insights, and maintains continuous compliance, preventing costly recalls and ensuring patient safety.",
        "raw_content": null,
        "summary": "This area focuses on proactively managing company risks and changes related to products, leveraging technology to enable guided actions and ensure high quality. It includes change control, APQR, and risk management for products.",
        "vision_statement": "Company's risks and changes are proactively managing leveraging technology to enable guided actions at all times to ensure high quality",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing (PS-M-XXX): Product/process changes, data for APQRs and risk assessments.\r\nQuality Control (PS-QC-XXX): Data for APQRs, analytical changes, risk assessments.\r\nRegulatory Affairs: Changes impacting regulatory submissions, risk information.\r\nSupply Chain Management (PS-SCM-XXX): Product-related risks, changes affecting supply.\r\nPS-QA-001 (QA enabling processes): SOP updates leading to changes.\r\nPS-QA-004 (Non-conformance and event management): Deviations triggering changes or risk reviews.\r\nPS-QA-005 (Production and process control): Data input for APQR, risk management.\r\nExternal Partners (CMOs): Data for APQRs (CMO PQR internalization), changes at CMOs.",
        "what_is_actually_done": "Change Control Management: Manages changes via a harmonized, user-friendly system, potentially using AI for impact assessment, identifying recurrent events, and risk highlighting. (QA09) APQR Generation: Automates or semi-automates Annual Product Quality Review generation, including trend analysis and identifying improvement opportunities. (QA10) Risk Management: Implements proactive and automated risk management tools, including AI-supported risk communication and an automated risk register from various sources. (QA11/QA12-text) Multi-site Data Analysis: Compares multi-site data (e.g., from APQRs) for proactive trend detection to differentiate site vs. product issues, potentially AI-supported. (QA12/QA11-text) Manages Quality Risk Management processes for products. Addresses QA aspects of Medical Devices & Combination Products. Oversees the Change Management process. Manages the Annual Product Quality Review process.\r\n\r\n\r\n## 2. Product-Related QA Enabling Processes\r\n\r\n**Purpose:**\r\nManages changes and risks related to products, ensuring quality is maintained as products or processes evolve.\r\n\r\n**Key Tasks:**\r\n\r\n- **Change Control:** Formal process for assessing and approving any changes that could affect quality.\r\n- **Annual Product Quality Reviews:** Yearly review of product data to spot trends and areas for improvement.\r\n- **Risk Management:** Identifying and controlling potential quality risks throughout a product\u2019s life.\r\n- **Multi-site Data Analysis:** Comparing data across sites to identify trends and share best practices.\r\n\r\n**Value:**\r\nEnsures product quality is maintained and improved, even as changes occur, and risks are proactively managed.",
        "pain_points": "Change Control (CC) process in GoTrack is not user-friendly and too complex. (QA09, P26)\r\nSignificant manual data screening required for APQRs; APQRs not generated automatically or easily. (QA10, P26)\r\nHigh effort for internalizing CMO Product Quality Reviews (PQRs). (P26)\r\nLack of a centralized company risk register; quality risks captured in disparate IT systems. (QA12-text, P26)\r\nManual impact assessment and identification of changes. (P26)\r\nInsufficient know-how and willingness for data-driven decision-making. (P26)\r\nChange control process involves high manual user interaction and often overly complex risk assessments. (P26)\r\nDevice lifecycle management is a manual, paper-based process. (P26)\r\nChallenges with using supplier/external partner data and interfaces for product quality. (P26)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 32,
        "bi_id": "05",
        "name": "05 | Global supply & Transportation Management",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nExecutes the physical movement of products across the global network, managing intercompany orders, transportation logistics, and regulatory compliance to ensure products reach customers safely, on time, and in full compliance with all requirements.\r\n\r\n**Key Tasks:**\r\n\r\n- **Order Management:** Processing intercompany sales and purchase orders, coordinating stock allocation, and managing order fulfillment across global entities.\r\n- **Transportation Planning:** Optimizing shipping routes, modes, and carriers based on cost, service, and sustainability requirements while ensuring regulatory compliance.\r\n- **Carrier Management:** Selecting and managing relationships with freight forwarders and carriers, monitoring performance, and negotiating contracts and rates.\r\n- **Customs & Compliance:** Managing customs clearance, dangerous goods handling, and trade compliance across international borders and regulatory jurisdictions.\r\n- **Shipment Tracking:** Monitoring shipment progress, managing exceptions, and providing visibility to internal stakeholders and external customers.\r\n- **Cost Management:** Controlling transportation costs through rate optimization, invoice verification, and continuous improvement initiatives.\r\n\r\n**Value:**\r\nEnsures reliable, cost-effective delivery of products to customers worldwide, maintains regulatory compliance across all markets, optimizes transportation costs while meeting service commitments, and provides end-to-end visibility that enables proactive issue resolution and customer communication.",
        "raw_content": "Global supply & Transportation Management: We ensure reliable, efficient and compliant supply within our networks through harmonized, automated processes, leveraging integrated datamodels, as to flexibly react to quickly changing market dynamics. Our transportation strategy is built on a business intelligence process that makes performance transparent and tracks trends. Pain Points: freight settlement; Invoice verfication: Provides transparency and real time information about transportation costs. Is basis for 100%-verification of related invoices.; CoD Costs Management; CO2E Data and Reporting: Provides transparency and real time information about CO2e emissions. Is basis for internal CO2e calculation and reporting.; master data governance, transparency, availability (GXP and non GxP); long Change of timelines for transportation steps; Route Management: Provides functionality to set up and select (alternative) routes based on given parameters.; transport Tender Management: Provides accurate data for tender execution, selection process of service providers, and reduces efforts to maintain tender results in master data.; Track & Trace: Provides transparency about shipments and real-time event recognition. Provides data for real time TPT calculation. TM & execution; T&T as required (real time, location, conditions). define level of FF integration; Business intelligence: No process/system to monitor global regulations (wrt GDP, EHS, resilience, sustainability, S&A), interpret for Boehringer & implement.; FF performance: measure TPT.",
        "summary": "Ensures reliable, efficient, and compliant global supply and transportation through automated processes and integrated data models, with outstanding sustainability and cost management.",
        "vision_statement": "We ensure reliable, efficient and compliant supply with automated processes and integrated data models to respond to market dynamics. Our sustainablity and cost management is outstanding.",
        "in_scope": "Optimization and scheduling of transportation activities to ensure timely and compliant delivery of products and materials including carrier selection, route planning, capacity booking, and transportation cost management to support overall supply chain efficiency; User requirements specification (URS), TS, Factory Planning. Creation and processing of transfer orders between internal company entities including order validation, pricing application, and documentation management to facilitate compliant and efficient product flow within the company network; Real-Time-Process Monitoring > CPV, \"Prozessrobustheit\"; Manufacturing feedback loop to IU; Continuous improvement; Data availability for launch & transfer.",
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "A comprehensive Transport Management System (TMS), serving as the BIX@ successor, provides end-to-end transportation management including automated freight tendering with RFQ generation and bid evaluation, comprehensive contract management with rate optimization and compliance tracking, intelligent route optimization considering multiple constraints and objectives, real-time shipment execution with carrier coordination and tracking, automated freight audit with 100% invoice verification, and performance analytics with carrier scorecards and cost optimization recommendations.\\n\\nTransport planning and execution are fully automated through seamless integration with supply chain planning systems, where production schedules automatically generate transport requirements, MRP systems trigger material movement orders, inventory optimization drives consolidation decisions, and customer order fulfillment creates delivery schedules. Real-time integration ensures transport orders are automatically created from supply plans with optimal timing and routing, dispatched to carriers through EDI or web portals, tracked throughout execution with real-time status updates, and integrated back into planning systems for accurate delivery date management.\\n\\nIntelligent route optimization and carrier selection utilize advanced algorithms considering multiple factors including total cost optimization (freight rates, fuel costs, accessorial charges), service level requirements (transit time, delivery windows, special handling), sustainability metrics (CO2 emissions, fuel efficiency, modal optimization), capacity constraints (truck availability, weight limits, cube utilization), and regulatory compliance (dangerous goods regulations, customs requirements, driver hours of service).\\n\\nAutomated invoice verification provides 100% coverage through systematic matching of invoices to contracts and shipments, automated detection of billing discrepancies and overcharges, exception-based approval workflows for disputed charges, and real-time cost visibility with budget tracking and variance analysis. The system maintains comprehensive audit trails for financial compliance and provides detailed cost analytics for continuous improvement opportunities.\\n\\nComprehensive carrier performance monitoring includes automated scorecards tracking key metrics such as on-time delivery performance with root cause analysis, transit time accuracy compared to committed schedules, damage and loss rates with trend analysis, cost competitiveness benchmarked against market rates, service quality assessments from customer feedback, and compliance performance for regulatory requirements. Performance data drives carrier selection decisions and contract negotiations.\\n\\nTotal cost of transportation optimization encompasses direct freight costs with rate optimization, indirect costs including inventory carrying costs and expedite fees, service level costs balancing speed and cost, sustainability costs including carbon pricing and environmental impact, and risk costs considering supply chain resilience and diversification. The system continuously analyzes tradeoffs between these factors to optimize total supply chain cost.\\n\\nReal-time track & trace provides comprehensive shipment visibility including GPS location tracking with geofencing capabilities, temperature and humidity monitoring for cold chain products, security monitoring with tamper detection and alerts, customs clearance status with documentation tracking, and estimated time of arrival with dynamic updates based on actual progress. Proactive exception management automatically detects delays, route deviations, temperature excursions, security breaches, and documentation issues, with immediate stakeholder notification and resolution workflows.\\n\\nIntegrated analytics provide deep insights into transportation performance including planned versus actual shipping times with variance analysis and root cause identification, carrier performance benchmarking with market comparisons, route optimization opportunities with cost and service improvement potential, modal analysis comparing air/ocean/ground options, and customer service impact assessment measuring delivery performance against customer requirements.\\n\\nComprehensive CO2e tracking and reporting includes automated collection of emissions data from all transportation modes, calculation of carbon footprint per shipment with route-specific factors, aggregated reporting for sustainability initiatives and external disclosure requirements, carbon offset program integration with verified offset purchasing, and sustainability optimization identifying opportunities to reduce environmental impact while meeting service requirements.\\n\\nAutomated compliance monitoring ensures all shipments adhere to complex regulatory requirements including dangerous goods regulations with proper classification and documentation, customs and trade compliance with accurate declarations and duty optimization, transportation security requirements with proper screening and documentation, and country-specific import/export regulations with automated documentation generation and validation.\\n\\nSustainable transportation optimization balances multiple objectives including carbon footprint reduction through modal optimization and route efficiency, cost optimization with total cost of ownership analysis, service level maintenance with customer satisfaction tracking, and regulatory compliance with automated monitoring and reporting. The system identifies opportunities for consolidation, modal shifts, and carrier partnerships that improve sustainability while maintaining cost and service objectives.\\n\\nAutomated tender management streamlines carrier selection through systematic RFQ generation based on shipping requirements, automated bid collection and evaluation with scoring algorithms, contract award automation with approval workflows, and performance monitoring with continuous improvement feedback. The system maintains comprehensive vendor databases with qualification tracking and relationship management.\\n\\nIntelligent transportation planning optimizes multiple variables simultaneously including load planning with cube and weight optimization, consolidation opportunities across multiple shipments and customers, route planning with multi-stop optimization and time window constraints, modal selection based on cost/service/sustainability tradeoffs, and capacity planning ensuring adequate transportation resources for demand fulfillment.\\n\\nException-based management focuses attention on critical issues through intelligent prioritization of alerts and notifications, automated resolution of routine issues where possible, escalation procedures ensuring appropriate stakeholder involvement, and continuous learning algorithms that improve exception detection and resolution over time. The system minimizes human intervention while ensuring critical issues receive immediate attention.\\n\\nGlobal standardization harmonizes transportation processes across all regions and product types through consistent procedures for order entry and shipment creation, standardized documentation and labeling requirements, unified carrier management with global contracts and performance standards, and common KPIs and reporting metrics enabling global visibility and optimization. The system accommodates local regulatory requirements while maintaining global consistency and efficiency.\\n\\nIntegrated master data management provides a single source of truth for all transportation information including comprehensive carrier database with capabilities, rates, and performance history, route master data with distances, transit times, and regulatory requirements, product shipping attributes including dangerous goods classifications and special handling requirements, and location master data with addresses, capabilities, and operating hours. This foundation enables automated decision-making and optimization across the entire transportation network.",
        "pain_points": "freight settlement; Invoice verfication: Provides transparency and real time information about transportation costs. Is basis for 100%-verification of related invoices.; CoD Costs Management; CO2E Data and Reporting: Provides transparency and real time information about CO2e emissions. Is basis for internal CO2e calculation and reporting.; master data governance, transparency, availability (GXP and non GxP); long Change of timelines for transportation steps; Route Management: Provides functionality to set up and select (alternative) routes based on given parameters.; transport Tender Management: Provides accurate data for tender execution, selection process of service providers, and reduces efforts to maintain tender results in master data.; Track & Trace: Provides transparency about shipments and real-time event recognition. Provides data for real time TPT calculation. TM & execution; T&T as required (real time, location, conditions). define level of FF integration; Business intelligence: No process/system to monitor global regulations (wrt GDP, EHS, resilience, sustainability, S&A), interpret for Boehringer & implement.; FF performance: measure TPT.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 33,
        "bi_id": "PS-QA-005",
        "name": "05 | Production and process control",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo establish fully digitalized and integrated Production Control Strategy (CSS) and Contamination Control Strategy (CCS) systems, allowing for automated assessments and reducing error-prone manual efforts to maintain stringent control over manufacturing processes and environments.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Contamination Control Strategy (CCS) & Control Strategy (CSS) Management:** Digitally managing the lifecycle of CCS and CSS via an integrated tool, including risk management, multi-site product interfaces, and AI-assisted risk assessments, especially for aseptic manufacturing.\r\n-   **Environmental Monitoring (EM):** Overseeing EM programs that routinely monitor microbial and particulate levels in controlled manufacturing environments (e.g., cleanrooms) to ensure they remain within specified limits.\r\n-   **Incident Monitoring:** Providing transparent, connected monitoring of incidents (e.g., microbiological events) with batch data, including automated summaries of affected batches.\r\n-   **Aseptic Manufacturing Oversight:** Providing quality oversight for manufacturing operations designed to prevent microbial contamination of sterile products.\r\n\r\n**Value:**\r\nSignificantly enhances product quality and patient safety by digitalizing and integrating contamination and process control strategies. This reduces manual effort, improves transparency, enables rapid incident response, and ensures consistent adherence to critical quality parameters, particularly in aseptic manufacturing.",
        "raw_content": null,
        "summary": "This area aims for fully digitalized and integrated Production Control Strategy (CSS) and Contamination Control Strategy (CCS) systems, allowing for automated assessments and reducing error-prone manual efforts in maintaining control over manufacturing processes.",
        "vision_statement": "Achieve fully digitalized and integrated Production & Product CS systems, allowing for automated assessments, cutting error prone manual efforts",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Manufacturing (PS-M-XXX): Execution of aseptic processes, environmental monitoring, implementation of control strategies, batch data.\r\nQuality Control (PS-QC-XXX): Microbiological testing, EM data analysis and trending.\r\nEngineering/Maintenance (PS-MAINT-XXX): Facility design, equipment qualification, maintenance related to CCS/CSS.\r\nPS-QA-002 (Product related QA enabling processes): Control strategies are key product knowledge and subject to change control.\r\nPS-QA-004 (Non-conformance and event management): EM excursions or process deviations are managed as events/non-conformances.\r\nPS-QA-006 (Validation and qualification): Validation of aseptic processes and cleaning is linked to CCS.\r\nIT: Digital tools for CSS/CCS management, EM data systems.",
        "what_is_actually_done": "CCS & CSS Lifecycle Management: Manages the lifecycle of Contamination Control Strategy (CCS) and general Control Strategies (CSS) via a digital tool, including risk management and interfaces for multi-site products/CMOs. AI assists in risk assessment. (QA22) Incident Monitoring: Provides transparent monitoring of incidents (e.g., microbiological events) connected to batch data, with automated summaries of affected batches. (QA23) Oversees Aseptic Manufacturing processes, including Contamination Control Strategy. Manages Environmental Monitoring programs, including micro-testing. Defines and maintains Control Strategies for products and processes.\r\n\r\n## 5. Production and Process Control\r\n\r\n**Purpose:**\r\nEnsures manufacturing environments and processes are controlled to prevent contamination and maintain quality.\r\n\r\n**Key Tasks:**\r\n\r\n- **Aseptic Oversight:** Ensuring sterile manufacturing is free from contamination.\r\n- **Contamination Control Strategy:** Planning and managing measures to prevent contamination.\r\n- **Environmental Monitoring:** Regularly checking cleanrooms and controlled areas for contaminants.\r\n- **Control Strategies:** Defining key process parameters and quality attributes.\r\n- **Incident Response:** Detecting and managing contamination events.\r\n\r\n**Value:**\r\nPrevents contamination, especially in sterile products, ensuring patient safety and product efficacy.",
        "pain_points": "Manual, paper-based, and inefficient CSS/CCS lifecycle management; complex manual integration of CMO-related CSS. (QA22)\r\nChallenging CSS establishment and maintenance for multi-site products. (P27)\r\nCSS information often resides in Excel (XLS) with manual data entries. (P27)\r\nContamination Control Strategy not fully digitalized (QRM GoTrack adoption in progress). (P27)\r\nControl strategy and associated risk management are not digitalized; knowledge pool is hardly accessible. (P27)\r\nLack of automated connection between CSS, Manufacturing Instructions (HU), Master Validation Plans, etc. (P27)\r\nManual calculation of results for control limits. (P27)\r\nData integrity gaps in global Environmental Monitoring (EM) software. (P27)\r\nCSS system is largely manual (xlsx) with no interaction with other systems like GoTrack. (P27)\r\nNeed for continuous assessment of CSS with CPV to reduce effort in low-risk areas. (P27)\r\nManual review of affected batches in case of microbiological events. (QA23)\r\nNeed for continuous EM monitoring to optimize QC tasks. (P27)\r\nLack of connectivity to master data (GBS) for EM/CSS. (P27)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 34,
        "bi_id": "PS-QA-007",
        "name": "07 | Facility and equipment lifecycle",
        "area_id": 9,
        "step_description": "**Purpose:**\r\nTo establish real-time, end-to-end lifecycle transparency for facility and equipment status, enabling streamlined asset management, cleaning, maintenance, and calibration to consistently ensure fitness for purpose and GxP compliance.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Digital Cleaning Documentation:** Managing and tracking cleaning for rooms and equipment digitally, potentially via an electronic logbook, providing real-time room status.\r\n-   **Global Equipment Transparency:** Maintaining a central digital database for global manufacturing and analytical equipment status (including lab equipment), supporting efficient asset management and transferability of lifecycle documents.\r\n-   **Maintenance & Calibration Oversight:** Providing Quality Assurance oversight for critical equipment maintenance and calibration programs, ensuring regular servicing and accurate measurements.\r\n-   **Facility & Utility Oversight:** Ensuring manufacturing facilities and critical utilities (e.g., purified water, HVAC, compressed air) meet GxP requirements for design, cleaning, monitoring, and maintenance, including appropriate zoning and cleanroom classifications.\r\n\r\n**Value:**\r\nEnhances product quality and regulatory compliance by ensuring facilities and equipment are consistently maintained and controlled. This provides real-time transparency, prevents contamination and equipment failures, optimizes asset utilization across sites, and reduces manual effort in documentation and oversight, thereby protecting product integrity and patient safety.",
        "raw_content": null,
        "summary": "This area aims to establish real-time, end-to-end lifecycle transparency for facility and equipment status to enable streamlined asset management, including cleaning, maintenance, and calibration.",
        "vision_statement": "Real-time, End2end-lifecycle transparency on equipment & facility status for streamlined asset management",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Maintenance (PS-MAINT-XXX): Calibration and maintenance activities, equipment status, work orders.\r\nManufacturing (PS-M-XXX): Equipment usage, room cleaning, facility status information.\r\nQuality Control (PS-QC-XXX): Lab equipment lifecycle, status, calibration.\r\nEngineering: Facility and equipment design, lifecycle documentation.\r\nIT: Databases for equipment status, electronic logbook systems.\r\nPS-QA-005 (Production and process control): Zoning, environmental control linked to facilities.",
        "what_is_actually_done": "Digital Cleaning Documentation: Manages digital cleaning documentation for rooms, potentially via an electronic logbook framework and tracking solution, providing real-time room status accessible at the location. (QA26) Global Equipment Transparency: Provides global digital transparency of manufacturing and analytical equipment status (including lab equipment) through a central database, enabling transferability of lifecycle documents and supporting initiatives like Lab4U. (QA27) Manages QA oversight of Utilities. Manages QA oversight of Facilities. Manages QA oversight of Zoning. Manages QA oversight of Maintenance & Calibration programs (interfacing with Maintenance).\r\n\r\n\r\n## 7. Facility and Equipment Lifecycle\r\n\r\n**Purpose:**\r\nKeeps facilities and equipment in a state of control and suitable for their intended use.\r\n\r\n**Key Tasks:**\r\n\r\n- **Utility Oversight:** Monitoring systems like water and air that affect product quality.\r\n- **Facility Oversight:** Ensuring buildings meet cleanliness and design standards.\r\n- **Zoning:** Managing areas with different cleanliness needs.\r\n- **Maintenance and Calibration:** Regularly servicing and calibrating equipment.\r\n- **Digital Cleaning Records:** Using digital systems to track cleaning.\r\n- **Equipment Records:** Keeping a central record of equipment status and history.\r\n\r\n**Value:**\r\nPrevents contamination and equipment failures, supporting consistent product quality.",
        "pain_points": "Insufficient transparency of clean room status due to paper-based or non-integrated cleaning documentation. (QA26)\r\nLack of global digital transparency of equipment status across sites, hindering transfer planning and asset utilization. (QA27)\r\nLow guidance for calibration and maintenance; decisions based on individual site/equipment; lack of usable data for assessment. (P28)\r\nData-driven review of calibration/maintenance intervals is not performed or is a manual process. (P28)\r\nAutomated assessment/review of \"roombooks\" for zoning not possible; difficult to compare site definitions. (P28)\r\nFacility/equipment data often entered and managed in Excel files. (P28)\r\nLack of automated engineering guidance based on assessable best practice data. (P28)\r\nNo automated check of affected materials/batches in case of facility/equipment non-compliance. (P28)\r\nChallenges posed by aging and existing facilities. (P28)\r\nNeed for shared facility risk assessment, cross-site checks, and evaluation of identified risks. (P28)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 35,
        "bi_id": "01",
        "name": "01 | Strategic S&OP & SC Design",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nEstablishes long-term strategic direction for the supply chain through integrated portfolio, capacity, and financial planning that aligns supply capabilities with business strategy and market demands over 3-5 year horizons.\r\n\r\n**Key Tasks:**\r\n\r\n- **Portfolio Planning:** Analyzing product lifecycle trajectories, market dynamics, and competitive landscapes to optimize product portfolio decisions and investment priorities.\r\n- **Network Design:** Configuring the global manufacturing and distribution network to optimize cost, service, risk, and regulatory compliance across all markets.\r\n- **Capacity Investment:** Making strategic decisions on manufacturing capacity, technology investments, and facility expansions based on long-term demand projections.\r\n- **Supplier Strategy:** Developing strategic supplier relationships, evaluating make-vs-buy decisions, and designing supplier networks for resilience and competitiveness.\r\n- **Scenario Planning:** Creating and evaluating multiple strategic scenarios to assess portfolio changes, market disruptions, and competitive responses.\r\n- **Financial Integration:** Aligning supply chain strategies with financial objectives, including capital allocation, cost optimization, and margin improvement initiatives.\r\n\r\n**Value:**\r\nOptimizes long-term profitability and competitiveness by ensuring supply chain capabilities support business growth, enables proactive response to market changes, and maximizes return on supply chain investments while maintaining strategic flexibility for future opportunities.",
        "raw_content": "Strategic S&OP & SC Design: For the entire portfolio, we enable transparent cross functional strategic planning to optimize decisions with an integrated system for demand, capacity, and financial scenario planning. Vision statements: We drive planning excellence through a transparent platform connecting all functions, supporting pipeline products, and ensuring governed master data. We optimize decisions through an integrated systems for product reviews, scenario modeling, and capacity visualization with governed master data. We enable transparent planning and with this optimize decision making with a unified system for demand-supply integration, pipeline management, and scenario capabilities. FG: 'We enable transparent long term planning and with this optimize decision making with a unified system for demand-supply integration, pipeline management, and scenario capabilities.' Optimize the entire portfolio from finished goods to starting materials across the network, balancing demands and capacities while maximizing financial and sustainability value through scenario planning and capacity simulation. Pain Points: Missing Harmonization of prouct relevant master data across sites and no Governance concept defined; manual activites to overcome missing availability of single source of truth; Decoupling points between tactical and strategic horizon leading to manual work to translate to correct materials; Excel driven process; system breaks between strategiic hrizons; no process/system support to calculate total cost of supply so it cannot be used as steering parameter; Low Sales Forecast Accuracy (especially US, China); Product Review highly manual (ppt & excel) knowledge based on SMEs; Lack of reconciliation options for demand scenarios; Total supply chain cost in % of normalized COGS too high, basically linked to inventories (disputed).",
        "summary": "Enables transparent cross-functional strategic planning for the entire portfolio to optimize demand, capacity, and financial scenario planning.",
        "vision_statement": "For the entire portfolio, we enable transparency across functional strategic planning to optimize decisions with an integrated system for demand, capacity, and financial scenario planning.",
        "in_scope": "Balancing demand requirements with supply capabilities across the global manufacturing network to optimize resource allocation and ensure adequate product availability while considering capacity constraints, inventory targets, and production efficiencies. Commercial production, Production of test & tech batches, New product introduction, Batch release, IPC/PAT, Packaging, Intra-plant-logistics (incl. \"Einschleusen von Material\").",
        "out_of_scope": "M&S Forecast System; Validated Batch size determined; Maintenance; Spare-part management.",
        "interfaces_text": "Next Gen sales forecast.",
        "what_is_actually_done": "A single integrated SAP IBP-based system connects Finance (budgeting, cost modeling, investment planning), Therapeutic Areas/Asset Teams (portfolio strategy, product lifecycle planning), and Launch & Indication teams (market entry planning, competitive analysis) for collaborative strategic planning. The system provides a shared data model with consistent definitions across functions, common planning interface with role-based access controls, real-time updates with change impact analysis, and integrated workflow for cross-functional approval processes. Real-time integration ensures that changes in demand planning immediately reflect in capacity needs through automated MRP explosions, financial modeling with updated P&L projections, investment planning with revised capital requirements, and supply network optimization with constraint analysis.\\n\\nUsers can easily create and compare strategic scenarios through intuitive interfaces, viewing detailed profit & loss impact including revenue projections by product/market, cost implications across the value chain, working capital requirements, and return on investment calculations. Automated 'what-if' analyses are performed for portfolio changes (impact of new product launches, discontinuation effects, lifecycle extensions), capacity investments (ROI analysis for new facilities, technology upgrades, automation investments), and supply network modifications (nearshoring/reshoring analysis, supplier diversification strategies, vertical integration assessments). Long-term forecast accuracy (ARC, LTF) and supply adherence are tracked through automated deviation calculations with root cause analysis, performance dashboards with drill-down capabilities, benchmark comparisons against industry standards, and predictive analytics identifying accuracy improvement opportunities.\\n\\nInternal and external capacity is visualized across different time horizons (5-year strategic, 2-year tactical, 6-month operational) with real-time updates showing current utilization by site and product line, projected bottlenecks with early warning systems, capacity expansion scenarios with timeline and cost implications, and CMO capacity integration with contract performance tracking. Total cost of supply is calculated as a key steering parameter through comprehensive cost modeling including direct materials, manufacturing costs, logistics and distribution, quality and compliance costs, inventory carrying costs, and risk-related costs (supply disruption, quality incidents). Investment planning is integrated with capacity utilization and demand scenarios by linking capital expenditure plans directly to projected demand growth, capacity needs analysis with utilization optimization, technology roadmap alignment with strategic priorities, and financial scenario modeling with sensitivity analysis.\\n\\nAll site and product master data has a single defined data owner with global governance through clearly established roles and responsibilities matrix, automated workflows for data change management, data quality scorecards with improvement tracking, and governance committees with cross-functional representation. Harmonized master data concepts support automated planning and optimization through standardized naming conventions across all systems, consistent data structures enabling seamless integration, unified data quality rules with automated validation, and master data lifecycle management with automated archiving and retention policies. The master data architecture is designed to enable future automation and optimization by providing clean, consistent data to AI/ML models, supporting real-time analytics and reporting, enabling predictive maintenance and quality analytics, and facilitating supply chain digital twin implementation.\\n\\nThe system design enables future automation of routine strategic planning activities including automated data aggregation from multiple sources, intelligent report generation with narrative insights, basic plan adjustments based on predefined rules, and exception-based alerting for human intervention. Integration points support AI-driven optimization and recommendation engines through RESTful APIs for external AI tool integration, real-time data streaming for machine learning models, automated recommendation incorporation with human approval workflows, and continuous learning feedback loops. Long-range commercial planning (LRCP) updates are regular and automated, with demand version updates triggered by forecast changes, supply plan updates reflecting capacity and network changes, cross-functional impact analysis with automated stakeholder notification, and integrated timeline management ensuring planning cycle adherence.",
        "pain_points": "Missing Harmonization of prouct relevant master data across sites and no Governance concept defined; manual activites to overcome missing availability of single source of truth; Decoupling points between tactical and strategic horizon leading to manual work to translate to correct materials; Excel driven process; system breaks between strategiic hrizons; no process/system support to calculate total cost of supply so it cannot be used as steering parameter; Low Sales Forecast Accuracy (especially US, China); Product Review highly manual (ppt & excel) knowledge based on SMEs; Lack of reconciliation options for demand scenarios; Total supply chain cost in % of normalized COGS too high, basically linked to inventories (disputed).",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 36,
        "bi_id": "PS-MFG-001",
        "name": "01 | PRODUCTION PLANNING & SCHEDULING PROCESS",
        "area_id": 7,
        "step_description": "**Purpose:**\r\nTo precisely plan, simulate, and schedule all manufacturing operations from material and equipment readiness to personnel allocation, ensuring rapid product launches and consistent, reliable supply of medicines to patients.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Integrated Planning:** Conducting comprehensive operations, capacity, day-to-day, and campaign planning, including maintenance, calibration, and changeovers, to ensure resource availability.\r\n-   **Scenario Simulation:** Simulating various production scenarios and new plant layouts to optimize building and facility utilization, supporting new product introductions and transfers.\r\n-   **Schedule Optimization:** Scheduling production runs and optimizing sequences by considering material, equipment, and personnel availability, capacity constraints, and required times, including re-planning for contingencies.\r\n-   **Launch & Shift Planning:** Managing detailed launch plans for new products and optimizing shift schedules to align with production demands.\r\n-   **Data Integration:** Utilizing centralized planning tools (e.g., SAP APO, OR-Soft) that integrate data from supply chain, manufacturing, engineering, and quality for holistic planning.\r\n-   **Predictive Analysis:** Leveraging AI for demand forecasting and analyzing historical production times to optimize planning and warehousing, aiming for setup-optimized production.\r\n\r\n**Value:**\r\nSignificantly accelerates time-to-market for new therapies and ensures reliable product supply by integrating fragmented planning processes into a single, dynamic system. This reduces manual effort, enhances responsiveness to changes, enables quick scenario evaluation, and optimizes resource utilization, thereby minimizing production bottlenecks and ensuring timely patient access to critical medicines.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We use an integrated data model to plan, simulate and schedule the manufacturing process to achieve fast time-to-market and reliable supply",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Supply Chain Management (SCM): Receives global SCM information (demand forecasts, production plans) as a prior process; interacts for replenishment planning, material availability, and MRP.\r\nMaintenance: Integrated planning of maintenance activities.\r\nEngineering (GFE): Planning for new buildings/facilities (plant modeling), equipment availability.\r\nQuality (QC/QA): Planning for cleaning validation, calibration.\r\nIT & GBS: For planning tool implementation, data integration, and standardized planning processes.\r\nInnovation Unit Development (IU Dev): For plant modeling and simulation for new product introductions and transfers.",
        "what_is_actually_done": "Performing operations planning (material, equipment, personnel), capacity planning (including test and tech validation), day-to-day planning, and integrated planning for maintenance, calibration, and changeovers. Simulating various production scenarios, scheduling production runs, and optimizing schedules considering material and equipment availability, capacity constraints, and required times. This includes re-planning due to contingencies and managing campaign planning (number of batches), shift planning, and launch planning. Utilizing a centralized planning tool (or tools like SAP APO, OR-Soft) that integrates data from various disciplines (SCM, Manufacturing, Engineering, CPT, Cleaning Validation) and production systems. This includes managing manufacturing lead times, Bills of Material (BOM), and equipment/system availability. Potentially using AI for demand forecasting to optimize production and warehousing, and analyzing historical production times for predictive planning. Aims for setup-optimized production planning. Simulating new plant layouts and operations to optimize building and facility utilization, supporting transfers and launches by modeling processes with attributes like parameters, equipment data, timelines, and capacity (M02).",
        "pain_points": "Decentralized planning in multiple Excel sheets; lack of a single, integrated tool.\r\nSlow and inefficient re-planning after production changes or unforeseen events.\r\nManual cross-checks required for maintenance, production, and material availability.\r\nDifficulties in scenario planning and simulation to check possible outcomes quickly.\r\nForecast data not directly integrated into planning systems.\r\nManual effort in transferring SCM's high-level plan to local detailed plans.\r\nComplex planning due to diverse products with different process/equipment requirements.\r\nLack of a central tool for detailed shop-floor scheduling (Feinplanung).\r\nInadequate tools for managing changeover data and optimizing changeover sequences.\r\nMissing central database for supplier material qualification.\r\nPlanning processes are not standardized or automatically networked with SCM.\r\nHigh manual effort in risk analysis for aseptic facilities (related to plant modeling).",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 37,
        "bi_id": "PS-MFG-003",
        "name": "03 | CHANGE OVERS",
        "area_id": 7,
        "step_description": "**Purpose:**\r\nTo minimize production downtime during equipment changes, cleaning, and sterilization through transparent, automated, and digitally supported changeover processes.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Physical Changeover & Cleaning:** Performing equipment set-up, cleaning (minor, major, cross-cleaning), sterilization, and conditioning of systems.\r\n-   **Equipment Management:** Efficiently managing and locating necessary equipment and format parts for changeovers.\r\n-   **Optimization & Standardization:** Analyzing, optimizing, and standardizing changeover processes, including setup sequences and product sequence optimization, using historical data, simulation (Digital Twin), and AI-supported guidance.\r\n-   **Automated Cleaning Release:** Implementing automated testing (e.g., TOC analysis via inline sensors) and release procedures for cleaning processes, potentially allowing for approval by exception.\r\n-   **Automated Recipe Loading:** Automatically loading recipes and machine settings onto equipment to reduce manual effort and errors.\r\n-   **Real-time Progress Visibility:** Providing real-time visibility (e.g., via digital info boards) into the progress of changeover activities and potential disruptions for all relevant personnel.\r\n\r\n**Value:**\r\nDramatically reduces production downtime and increases equipment utilization by optimizing and automating changeover procedures. This minimizes manual effort, ensures consistent and compliant cleaning processes, and provides real-time transparency, leading to higher throughput, lower operational costs, and more efficient production schedules.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We achieve minimal down times through transparent, automated and digital supported change overs.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Production Planning & Scheduling: Receives changeover schedules and provides feedback on actual durations.\r\nManufacturing Processes: Precedes and follows the actual manufacturing of batches.\r\nQuality Control (QC): For cleaning validation, release of cleaned equipment (though aiming for automation).\r\nQuality Assurance (QA): Oversight of cleaning validation and changeover documentation.\r\nMaintenance: Involved in equipment setup, adjustments, and ensuring equipment readiness.\r\nEngineering (GFE) / Automation: For automation of settings, Digital Twin development for optimization.\r\nIT: For systems supporting live status tracking, Digital Twins, and automated recipe loading.",
        "what_is_actually_done": "Performing the physical changeover process, including equipment set-up, cleaning (minor, major, cross-cleaning), sterilization, and conditioning of systems. Managing equipment ('Ausr\u00fcstung') and format parts required for changeovers. Using historical data, simulation (Digital Twin), and AI-supported operator guidance to analyze, optimize, and standardize changeover processes, including setup sequences and product sequence optimization (M10). Implementing automated testing (e.g., TOC analysis via inline sensors) and release procedures for cleaning processes, potentially with approval by exception (M11). Automatically loading recipes and machine settings onto equipment to reduce manual effort and errors (M12). Providing real-time visibility (e.g., via digital info boards) into the progress of changeover activities and any potential disruptions for operators, coaches, and team leads (M13).",
        "pain_points": "Manual search for equipment and format parts.\r\nLack of clear visualization of where equipment needs to go or how it should be configured.\r\nChangeover information often tracked in Excel or based on empirical knowledge of shift leaders.\r\nNo standardized changeover procedures across all factories or for all equipment.\r\nProduction downtime due to necessary training on the machine during changeovers.\r\nFrequent and complex setups due to a high number of format parts.\r\nInefficient cleaning processes, especially manual processes in Pharma (sampling, analytics, release iterations) compared to automated processes in Bio.\r\nFixed cleaning volumes (e.g., water) used per SOP, irrespective of actual need.\r\nLack of real-time visibility into changeover progress and potential issues.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 38,
        "bi_id": "00",
        "name": "00 | Product Lifecycle Management",
        "area_id": 1,
        "step_description": "**Purpose:**\r\nOrchestrates the complete lifecycle of pharmaceutical products from development through market withdrawal, ensuring rapid, compliant market entry and efficient management of product changes throughout their commercial life.\r\n\r\n**Key Tasks:**\r\n\r\n- **Launch Coordination:** Managing end-to-end product launches across 100+ countries, coordinating regulatory approvals, manufacturing readiness, and market entry timing.\r\n- **Version Management:** Handling product changes (formulation, packaging, labeling) through systematic version control, ensuring seamless transitions while maintaining supply continuity.\r\n- **Material Creation:** Establishing new product codes, specifications, and master data across all systems, reducing creation time from 6 months to weeks.\r\n- **Change Implementation:** Processing regulatory changes, packaging updates, and production modifications through controlled workflows with full traceability.\r\n- **Regulatory Coordination:** Synchronizing product approvals, batch releases, and compliance requirements across multiple regulatory authorities (FDA, EMA, PMDA).\r\n- **Launch Risk Management:** Identifying and mitigating risks that could delay market entry or disrupt supply during critical launch phases.\r\n\r\n**Value:**\r\nAccelerates time-to-market for new therapies, ensures regulatory compliance across global markets, and maintains uninterrupted supply during product transitions\u2014directly supporting patient access to medicines while maximizing commercial opportunities and minimizing compliance risks.",
        "raw_content": "Product Lifecycle Management: We enable rapid product launches and changes with an integrated, user-friendly E2E PLM platform that automates data validation, accelerates material creation, supports scenario planning, and simulation. Further evolution to no-touch prediction and automized implementation of scenarios after decision making. Pain Points: no process in place for launch at risk and beyond / limited flexibility in our systems; no fast track launch process in compliance with systems; no segmentation; API/WIP SKUS: Articel logistics data are missing; low flexibility to process new technologies / products; High manual effort for data validation which could be partially automated.; special requirements from Regulatory do not fit in PLM standard buy solution; Implementation of new changes can take years but not reflected in SLCI yet (i.e. stopper change) --> disconnected DP/DS planning required; 'Interchangeability' of SKUS / Multisource SKUS; AWM: process for safety relevant label changes too slow; difficulty with version handling to get PLM off the shelf; complicated access management, full access for users required that execute only minor tasks in the system; no access automation in place; Early creation of SKUS >2 years prior to launch to enable system supported planning of pipeline SKUS; little/no automation for Product/SKU termination; currently systems were bought and implemented which potentially could be covered in a E2E PLM solution; change mgmt process not supported by the systems, especially cumbersome for early products with many changes; SLCI Limitations; Create material process takes too long (up to 6M); no simulation capability; Do we measure how long he different steps take for launch/change aunch/chang and report/take measures?; no single source of truth established for relevant data; Mgmt of non-SLCI relevant changes (i.e. prolongation of reference standard); Version Mgmt (potentially impacting >36 months --> LRCP).",
        "summary": "Enables rapid product launches and changes with an integrated, user-friendly E2E PLM platform, automating data validation and supporting scenario planning.",
        "vision_statement": "We enable rapid product launches and changes through an end-to-end, integrated, user-friendly PLM platform that validates data automatically, streamlines and accelerates material creation, and provides simulation capabilities, to enable scenario planning for strategic market dynamics. Further evolution to no-touch prediction and automized implementation of scenarios after decision making.",
        "in_scope": "test",
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "Launch activities are seamlessly integrated between regulatory approval systems (SLCI), supply chain planning (GRP/IBP), and market execution systems (BIX@/UnITed). Real-time visibility of launch readiness across all functions and geographies is achieved through central dashboards showing approval status by country, batch release timelines, production readiness, and market availability dates. Coordination of launch activities from bulk production through market availability is automated, including task assignment across POPUs/BOPUs, status tracking with escalation protocols, and dependency management ensuring sequential approval processes are optimized.\\n\\nIntelligent version transition planning automatically coordinates inventory rundown strategies, production switchovers with minimized downtime, and regulatory approval timing across 100+ countries and multiple supply sources. Predictive analytics optimize version transition timing by analyzing historical transition data, suggesting optimal switchover dates based on inventory velocity, safety stock adjustments considering shelf life constraints, and minimizing inventory obsolescence through dynamic pricing and allocation strategies. Automated compliance tracking validates against regional pharmacovigilance regulations, generates compliance reports for all regulatory frameworks (FDA, EMA, PMDA, etc.), and maintains audit trails for regulatory inspections.\\n\\nAI-powered data validation automatically verifies completeness and accuracy of product data across all master data objects (materials, BOMs, routing, quality specs), checking for mandatory field completion, correct data types and value ranges, and cross-system consistency. Machine learning algorithms identify potential data quality issues including duplicate entries with fuzzy matching logic, inconsistent units of measure across systems, statistical outliers in cost/yield data, and temporal inconsistencies in lifecycle dates before they impact operations. New master data records are automatically drafted using templates and historical patterns, with exception-based approval workflows routing unusual configurations for human review and parallel approval processes reducing cycle time from 6 months to days.\\n\\nUsers can simulate comprehensive launch scenarios including market entry sequencing for multiple countries, evaluation of alternative supply sources with capacity and cost implications, timing optimization considering regulatory approval dependencies, and portfolio impact assessment. Financial impact modeling performs detailed analysis for different launch strategies including revenue projections by market and time period, cost of goods analysis across different manufacturing scenarios, inventory carrying costs with optimized safety stock levels, and version transition approaches with obsolescence risk quantification. Risk assessment and mitigation planning are integrated into launch decision-making through automated identification of potential risks (supply shortages, regulatory delays, competitive threats), Monte Carlo simulation for risk quantification, and automated generation of mitigation steps with responsibility assignment and timeline tracking.\\n\\nMaterial creation is instant through streamlined, automated processes where the system automatically assigns material numbers following global numbering conventions, populates standard attributes based on product classification and regulatory requirements, validates data completeness using AI-powered checks, and initiates parallel approvals across quality, regulatory, and supply chain functions. Early SKU creation (>2 years prior to launch) enables system-supported long-term planning by pre-populating future planning systems with preliminary demand forecasts, allowing long-term capacity reservations with financial commitment tracking, and enabling scenario planning for pipeline products with sensitivity analysis. Fast-track pathways are established for urgent launches and safety-relevant changes utilizing dedicated expedited workflows with reduced approval steps, automated prioritization based on patient safety impact, emergency approval protocols with post-approval validation, and real-time status tracking with executive visibility for critical changes affecting patient safety or regulatory compliance.",
        "pain_points": "no process in place for launch at risk and beyond / limited flexibility in our systems; no fast track launch process in compliance with systems; no segmentation; API/WIP SKUS: Articel logistics data are missing; low flexibility to process new technologies / products; High manual effort for data validation which could be partially automated.; special requirements from Regulatory do not fit in PLM standard buy solution; Implementation of new changes can take years but not reflected in SLCI yet (i.e. stopper change) --> disconnected DP/DS planning required; 'Interchangeability' of SKUS / Multisource SKUS; AWM: process for safety relevant label changes too slow; difficulty with version handling to get PLM off the shelf; complicated access management, full access for users required that execute only minor tasks in the system; no access automation in place; Early creation of SKUS >2 years prior to launch to enable system supported planning of pipeline SKUS; little/no automation for Product/SKU termination; currently systems were bought and implemented which potentially could be covered in a E2E PLM solution; change mgmt process not supported by the systems, especially cumbersome for early products with many changes; SLCI Limitations; Create material process takes too long (up to 6M); no simulation capability; Do we measure how long he different steps take for launch/change aunch/chang and report/take measures?; no single source of truth established for relevant data; Mgmt of non-SLCI relevant changes (i.e. prolongation of reference standard); Version Mgmt (potentially impacting >36 months --> LRCP).",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 39,
        "bi_id": "PS-MFG-006",
        "name": "06 | WORKPLACE & OPERATOR ASSISTANCE",
        "area_id": 7,
        "step_description": "**Purpose:**\r\nTo empower employees with easy, real-time access to relevant knowledge and digitally supported learning processes, enabling them to upskill independently and efficiently, while providing robust operational support.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Knowledge Management:** Providing tools for managing and accessing critical knowledge, including SOPs, MBRs, technical documentation, and training materials.\r\n-   **Digital Onboarding & Training:** Implementing digital onboarding plans with role-based training assignments, flexible adjustments, and digital signatures, alongside leveraging AR/VR for immersive training.\r\n-   **Operational Guidance:** Providing clear, context-sensitive guidance for manufacturing operations through digital SOPs, MBRs, and AI-powered Q&A tools.\r\n-   **Automated Alerts & Translations:** Implementing automated process and equipment alerts for exception-based intervention and providing real-time, overarching translation for manufacturing information.\r\n-   **Supplier Qualification Oversight:** Establishing a global database or dashboard for reliable identification of supplier qualification data for raw and packaging materials.\r\n-   **AI-Powered Assistance:** Providing AI-powered assistance (e.g., Process CoPilot) for operators to quickly find information, understand processes, get context-sensitive support, and manage incidents.\r\n\r\n**Value:**\r\nEnhances workforce efficiency, reduces onboarding time, and minimizes operational errors by providing immediate access to critical knowledge and intelligent assistance. This empowers operators, overcomes language barriers, streamlines training, and ensures consistent adherence to procedures, leading to improved compliance, higher productivity, and reduced reliance on individual experts.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We empower employees to upskill themselves independently and efficiently by easy access to relevant knowledge and digitally supported learning processes",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Human Resources (HR): For onboarding processes, training programs, and qualification management (e.g., BI University).\r\nQuality Assurance (QA): For SOP management, training records, GMP compliance, and supplier qualification.\r\nManufacturing Processes: Operators interact with these systems during their daily work.\r\nIT & GBS: For digital tool implementation (AR/VR, AI assistants, translation tools, knowledge platforms, MES interfaces like Veeva Vault).\r\nEngineering (GFE): For technical documentation and equipment-related knowledge.\r\nProcurement/Supply Chain Management (SCM): For supplier qualification data.\r\nCompliance: For ensuring GxP compliance of digital tools and translated information.",
        "what_is_actually_done": "Providing tools and processes for managing and accessing knowledge, including SOPs, MBRs, technical documentation, and training materials. Managing employee qualifications and providing training, including shift planning and leveraging digital tools like AR/VR. Providing clear guidance for manufacturing operations through SOPs, MBRs, etc. Implementing automated process and equipment alerts for exception-based intervention. Implementing digital onboarding plans with role-based assignment of training and SOPs, flexible interfaces for individual plan adjustment, and digital signatures (M21). Providing real-time, overarching translation for manufacturing information to overcome language barriers, potentially integrated into systems like MES or via tools like Copilot (M22). Establishing a global database or dashboard for reliable identification of supplier qualification data (e.g., which raw/packaging material is qualified for which product at which site) (M23). Providing AI-powered assistance (e.g., Process CoPilot, Q&A tools) for operators to quickly find information in SOPs/MBRs, understand processes, get context-sensitive support, and manage incidents (M24). Using AI to support knowledge management through tools like AI-powered Q&A for SOPs, GenAI for finding answers, digital logbooks, and SOP knowledge graphs for visualizing hierarchies and contexts (M25).",
        "pain_points": "Multiple unaligned VR training projects across sites.\r\nLong onboarding times for new employees and high workload/fluctuation rates.\r\nAlerts from different systems are not aggregated or easily accessible.\r\nMissing interface between Veeva Vault and MES for integrated display of SOPs during shop floor onboarding.\r\nToo many SOPs, making MA onboarding lengthy and inefficient.\r\nLack of fully integrated VR/AR glasses for training and operational support.\r\nErgonomically challenging processes.\r\nLimited AI support for manufacturing staff.\r\nDifficulty in efficiently reading and understanding numerous SOPs; information is not readily available.\r\nCritical knowledge is often concentrated within a small group of experts.\r\nLanguage barriers in a global environment.\r\nDifficult access to reliable, centralized information on supplier qualifications.\r\nChallenges in accessing and utilizing dispersed knowledge effectively.",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 40,
        "bi_id": "PM-03",
        "name": "03 | Monitoring & Performance Dialogues",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo systematically monitor performance and track KPIs through structured dialogue processes, ensuring data quality, consistency, and accessibility for rapid, data-driven gap closure.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Real-time Monitoring:** Tracking process parameters and KPIs in real-time using standardized dashboards and automated data collection.\r\n-   **Automated Deviation Detection:** Implementing automated systems (e.g., trend analysis, simulations, AI-supported recognition) to detect KPI deviations, risks, and opportunities.\r\n-   **Structured Performance Dialogues:** Institutionalizing regular performance dialogues (daily, weekly, monthly) across all organizational levels to discuss deviations, identify root causes, and initiate corrective actions.\r\n-   **Unified Data & Tools:** Utilizing a centralized, harmonized data foundation and a unified dashboard tool to provide reliable and consistent data for all dialogues.\r\n-   **Proactive Alerting:** Implementing smart alerting systems to notify users of deviations or negative trends in real-time, enabling early intervention.\r\n-   **Action-focused Dashboards:** Developing dashboards that go beyond data collection to provide immediate conclusions and suggest actions, supporting faster decision-making.\r\n\r\n**Value:**\r\nEnhances decision-making speed and efficiency by providing reliable, real-time performance insights. This enables automated deviation detection, facilitates structured and frequent performance discussions, and supports rapid, data-driven gap closure across all units, fostering continuous improvement.",
        "raw_content": null,
        "summary": "Performance is monitored via real-time, standardized dashboards. Automated alerts and structured dialogues enable fast, data-driven gap closure across all units.",
        "vision_statement": "Automated, standardized monitoring ensures comparable, actionable insights and fosters continuous performance discussions throughout the organization.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "The third core process step examines how pharmaceutical manufacturers typically monitor performance and track KPIs through structured dialogue processes. This element of the framework recognizes that effective performance management requires more than just data collection; it demands systematic approaches to ensure data quality, consistency, and accessibility across the organization.\r\n\r\nThe research framework identifies the need to understand common structures and frequencies of performance dialogues at different organizational levels, including daily stand-ups, weekly reviews, and monthly business reviews. These dialogues serve as critical touchpoints for discussing performance deviations, identifying root causes, and initiating corrective actions based on real-time or near-real-time data analysis.\r\n\r\nEffective monitoring systems in pharmaceutical manufacturing must address significant challenges including inconsistent performance dialogues, varying data resolution across business units, manual KPI deviation detection processes, and difficulties in retrieving data from complex enterprise systems. The desired state envisions standardized KPI definitions, reliable real-time data for dialogues, automated deviation detection, and institutionalized performance dialogue processes that enable rapid, data-driven gap closure.",
        "pain_points": "No process for closing the GAP - focus is not sufficient - process too slow\r\nno data driven approach\r\nKPI definitions are challenged too often\r\nPerformance Dialogues not existing everywhere\r\nData resolution is different in different BU's\r\nAggregated data doesn't allow adequated analysis and action definition\r\nManual KPI deviation detection with trend monitoring and simulation\r\nDifficult and long proccess to get SAP data\r\nNo notifications via smart devices and real-time counter measures recommendations\r\nNo standardized dashboard tool is available --> everyone is using a different tool\r\nstatic PDMs, few or no digital access to real-time KPIs",
        "targets_text": "KPI definitions are standardized and accepted across all business units\r\nPerformance dialogues are based on reliable, real-time data\r\nKPI deviations are detected automatically using trend analysis and simulations.\r\nPerformance dialogues are institutionalized across all units and levels.\r\nStructured and Fast Gap-Closing Process\r\nData granularity is aligned across business units to enable meaningful comparisons and analysis\r\nA unified dashboard tool is used across the organization\r\nManual data retrieval is eliminated through automation",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 41,
        "bi_id": "PM-04",
        "name": "04 | Gap Closure & Continuous Improvement",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo systematically analyze identified performance gaps, determine root causes, and implement effective corrective or improvement actions, driving continuous improvement and innovation.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Root Cause Analysis:** Employing structured methodologies (e.g., PDCA, A3 problem-solving) and system-supported analysis to identify main drivers for performance deviations.\r\n-   **Predictive Analysis:** Utilizing forward-looking or predictive KPIs and performance pattern analysis to anticipate gaps, detect risks, and identify opportunities early.\r\n-   **Action Proposal & Simulation:** Leveraging historical data and AI to suggest proven countermeasures for recurring problems and using scenario simulations to evaluate potential actions, including financial impact.\r\n-   **Action Tracking & Accountability:** Implementing standardized tools for tracking improvement actions, ensuring clear accountability, follow-up, and timely resolution.\r\n-   **Effectiveness Measurement:** Systematically evaluating the impact and efficiency of implemented improvement measures and countermeasures.\r\n-   **Opportunity Identification:** Actively using KPI insights to uncover improvement potential and innovation opportunities beyond immediate gap closure.\r\n\r\n**Value:**\r\nTransforms data insights into actionable improvements, enabling proactive problem prevention and continuous enhancement of operational performance. This shortens the time to close gaps, ensures sustainable improvements, and fosters a culture of innovation, ultimately leading to higher efficiency and better outcomes.",
        "raw_content": null,
        "summary": "Risks and opportunities are identified early using predictive KPIs and pattern analysis. Scenario simulations and standardized actions enable fast, data-driven gap closure and continuous improvement.",
        "vision_statement": "Risks and opportunities are identified through automated, data-driven analysis, enabling proactive action and continuous improvement measures including linkage to financial impact.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "The fourth process step addresses how pharmaceutical companies typically analyze identified performance gaps, determine root causes, and implement corrective or improvement actions. This aspect of performance management represents the critical link between monitoring activities and actual performance improvement, requiring sophisticated approaches to transform data insights into actionable improvements.\r\n\r\nThe research framework emphasizes understanding common methodologies for developing, selecting, and implementing corrective actions, specifically mentioning established frameworks such as Plan-Do-Check-Act (PDCA) and A3 problem-solving approaches. These structured methodologies provide pharmaceutical companies with systematic approaches to ensure that improvement efforts are both effective and sustainable over time.\r\n\r\nForward-looking or predictive KPIs represent an advanced aspect of this process, enabling organizations to anticipate and prevent future performance issues rather than simply reacting to problems after they occur. The research seeks to understand how pharmaceutical companies typically leverage performance data to identify opportunities for continuous improvement and innovation beyond just addressing immediate performance deficits.",
        "pain_points": "No automate proposals for solving similar known problems\r\nNo Performance pattern analysis to identify performance drivers\r\nno integrated scenario development to close gaps\r\nlack of understanding of dependencies between KPIs => single green KPI might not be according to benchmark\r\nno appropriate actions taken and no standardized tracking tool for actions\r\nlack of forward looking KPIs prevents early gap closure measures\r\nKPIs are currently not sufficiently used to identify opportunities or continuous improvmenet\r\nNo sufficient measurement of efficiency of measures",
        "targets_text": "The system leverages historical data to suggest proven countermeasures for recurring problems\r\nPatterns are used proactively to detect risks and opportunities early\r\nKPIs are actively used to uncover improvement potential and innovation opportunities\r\nScenario simulations are embedded in the performance process to evaluate potential actions\r\nPredictive indicators are used to anticipate performance gaps and trigger early interventions\r\nAccountability and follow-up are embedded in the process\r\nThe impact of improvement measures is systematically evaluated\r\nKPI relationships are visualized and understood to avoid misleading interpretations",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 42,
        "bi_id": "PM-E03",
        "name": "E03 | Employee qualification & development",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo provide tailored training and development approaches that build both technical capabilities and cultural alignment, ensuring employees are skilled and confident in utilizing performance management systems and data.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Personalized Training:** Offering personalized, knowledge-based training recommendations that reflect individual skill levels, roles, and development goals, moving away from a \"one-size-fits-all\" approach.\r\n-   **Digital Application Training:** Providing practical, hands-on training and user-friendly handbooks for new digital applications and solutions to build confidence and proficiency.\r\n-   **Data Mindset Integration:** Incorporating training that helps employees understand how to effectively use data for decision-making and performance improvement.\r\n-   **Performance Management Playbook:** Developing a clear, accessible playbook outlining the performance management process, expectations, and roles for all staff.\r\n-   **Continuous Development Tracking:** Ensuring transparent and regular tracking of performance development and target achievement.\r\n-   **Automated Learning Suggestions:** Implementing systems that proactively recommend relevant training based on performance gaps and future needs.\r\n\r\n**Value:**\r\nEmpowers employees with the necessary skills and knowledge to actively participate in and drive performance management initiatives. This personalized and practical approach ensures that learning is effective, scalable, and directly contributes to improved performance and successful adoption of digital tools across the organization.",
        "raw_content": null,
        "summary": "Training is tailored to individual needs using system-generated suggestions. Hands-on formats and playbooks support digital skills and performance management.",
        "vision_statement": "Digitalization empowers employee development by making learning more personalized, accessible, data-driven, and scalable across the organization.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": null,
        "what_is_actually_done": "The third enabling process focuses on employee qualification and development, recognizing that effective performance management requires tailored training approaches that build both technical capabilities and cultural alignment. This process must address challenges including generic training approaches that fail to meet specific role requirements and the absence of comprehensive performance management resources that support practical application.",
        "pain_points": "System generated training proposals based on excisting knoledge\r\nTrainings are the same for each employee and independant of knowledge base\r\nMissing data mindset\r\nNo monthly updated MAG target achievement overview\r\nNo training suggestions generated by the system\r\nNo hands-On training and handbooks for new digital applications/solutions\r\nNo playbook for performance management including training for all staff",
        "targets_text": "Personalized, Knowledge-Based Training Recommendations\r\nTrainings are no longer \u201cone-size-fits-all\u201d but reflect individual skill levels and development goals\r\nEmployees understand how to use data for decision-making and performance improvement\r\nTransparent and Regular Performance Development Tracking\r\nPractical, scenario-based training and user-friendly handbooks are available for all new digital applications\r\nRole based learning:\r\nThe system proactively recommends relevant training based on role, performance gaps, and future needs\r\nA clear, accessible playbook outlines the performance management process and expectations",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 43,
        "bi_id": "PS-QC-002",
        "name": "02 | SPECIFICATION CREATION AND HANDLING",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo establish a strong foundation through automated, standardized, and globally unified procedures and specification management, defining the boundaries of product acceptability for compliance.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Centralized Management:** Develop and maintain a global system for all specifications and analytical procedures, ensuring centralized control with versioning, change tracking, and user access controls.\r\n-   **Global Harmonization:** Harmonize procedures and limits cross-site and cross-product with global standards, reducing redundant \"n-methods\" and managing updates through automated versioning and guided workflows.\r\n-   **Automated Transfer & Generation:** Implement systems for automatically transferring specifications to subsequent systems (LIMS, LES) and automating the generation of inspection plans and workflows for robotics/lab execution from specifications.\r\n-   **Master Data Governance:** Establish a single, global master data setup for inspection plans per product, standardizing data structures and defining clear responsibilities for creation and maintenance.\r\n-   **AI-Powered Translation:** Utilize AI to automatically translate documents (e.g., specifications, VQDs) while maintaining layout and formatting, supporting multiple languages and integrating with document management systems.\r\n-   **AI-Assisted Procedure Development:** Use an authoring tool with an easy front-end and structured back-end for creating analytical procedures, enabling AI-assisted creation and standardization through building block-based authoring, integrating Innovation Unit (IU) processes for GMP-ready SOPs.\r\n\r\n**Value:**\r\nEnsures global standardization and regulatory agility by eliminating fragmented approaches and manual errors. This reduces effort, improves data integrity and consistency across sites, accelerates the deployment of new protocols, and minimizes interpretation errors, enhancing overall compliance and audit readiness.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "We establish a strong foundation through automated, standardized, and globally unified procedures & specification management",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Lab Execution Systems (LES) / LIMS: For transferring specifications, inspection plans, and analytical procedures. (QC04, QC05, QC08)\r\nManufacturing Execution Systems (MES): If inspection plans or specifications are used directly in production-related checks.\r\nRegulatory Information Management Systems (RIMS): For managing specifications and handling regulatory changes. (QC05)\r\nChange Control Systems: For managing changes to specifications and ensuring compliance. (QC05)\r\nDocument Management Systems: For storing and retrieving original and translated documents. (QC07)\r\nInnovation Unit (IU) / R&D: For initial creation and handover of analytical procedures and specifications. (QC05, QC08)\r\nMaster Data Management (MDM): For global standards and governance. (QC04, QC06)\r\nRobotics Systems: For transferring automated workflows. (QC05)",
        "what_is_actually_done": "Develop and maintain a global system for all specifications and analytical procedures. Ensure centralized control with versioning, change tracking, and user access controls. Integrate with other enterprise systems (e.g., LIMS, LES) for real-time collaboration and updates. Harmonize procedures and limits cross-site and cross-product, with global standards in English. Manage updates through automated versioning and guided workflows (QC04 / USE CASE 4). Implement a system for automatically transferring specifications to subsequent systems (LIMS, LES). Ensure real-time synchronization, error detection, and customizable transfer rules. Automate the generation of inspection plans and workflows (for robotics, lab execution) from specifications. Establish governance to ensure global master data is changed only by authorized persons (QC05 / USE CASE 5). Establish a single, global master data setup for inspection plans per product. Standardize and harmonize plans and data structures across all sites. Define clear responsibilities for master data creation and maintenance (QC06 / USE CASE 8). Utilize AI to automatically translate documents (e.g., specifications, VQDs) while maintaining layout and formatting. Support multiple languages, use glossaries for context-specific terminology, and integrate with document management systems. Provide real-time translation previews and continuous learning for translation models (QC07 / USE CASE 6). Use an authoring tool with an easy front-end and structured back-end for creating analytical procedures. Enable automated \"transcription\" into other software solutions (LIMS testing plans, LES workflows). Support AI-assisted creation and standardization through building block-based authoring. Integrate IU (Innovation Unit) processes for co-creation of GMP-ready SOPs (QC08 / USE CASE 7).",
        "pain_points": "Design of analytical procedures does not always support automated workflow creation.\r\nRisk-based implementation of regulatory change controls is challenging.\r\nSiloed approach between IU and Operations for methods.\r\nLack of a global Control Test Specification (TS) for the same product.\r\nInefficient tracking of regulatory change controls.\r\nNo global standardization of methods and specifications, leading to n-methods and inefficiency.\r\nDifferent methods/specifications for the same products with no governance process.\r\nGSPECS system is complicated and not user-friendly, leading to high effort. (USE CASE 5)\r\nLack of automated recipe generation and inspection instruction. (USE CASE 5)\r\nUsers do not see the benefit of current specification systems (e.g., GSPECS). (USE CASE 5)\r\nEach site creates its own \"Pr\u00fcfvorschrift\" (inspection instruction). (USE CASE 5)\r\nCurrent document translation is not high quality initially, requiring revision effort. (USE CASE 6)\r\nTranslation is time-consuming, variable in quality, and expensive. (USE CASE 6)\r\nTranslation step delays new project/system roll-outs. (USE CASE 6)\r\nMaster data setup for inspection plans is per site, leading to potential compliance risks if plans diverge. (USE CASE 8)\r\nChange management for inspection plans needed for every site separately. (USE CASE 8)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 44,
        "bi_id": "PS-QC-004",
        "name": "04 | TESTING PREPARATION AND EXECUTION",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo ensure lab operations are automated or guided by digital workflows following standardized methods, with review by exception, accelerating analysis and minimizing errors.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Unified Lab Execution System (LES):** Implement a unified LES with guided, system-based instructions (recipes) for test preparation and execution, providing harmonized global recipes and standardized preparation templates.\r\n-   **Automated Workflows & Robotics:** Automate sample preparation and testing execution using robotics and advanced automation, integrating with laboratory management systems for seamless operation and activity feedback to planning.\r\n-   **In-Line Testing & PAT:** Increase in-line testing and leverage production process data (e.g., Near-infrared (NIR) probes) to reduce or eliminate traditional In-Process Controls (IPCs) by feeding real-time content uniformity data to QC.\r\n-   **Automated Quality Event Documentation:** Automatically generate quality event documentation (OOS, discrepancies) during the QC process, utilizing AI for detection and real-time alerts, connecting deviation tools to LIMS and other systems.\r\n-   **Automated Inventory & Sourcing:** Implement automated systems for storing and managing compounds (chemicals, columns) and reagents, linked to order management for automated ordering based on stock and needs.\r\n-   **Supplier Data Integration:** Automate the transfer of data from suppliers (e.g., CoA via XML import, text recognition) into internal systems to reduce manual effort.\r\n-   **Connected Systems Integration:** Ensure seamless, vertical E2E integration of all layers (ERP/LIMS/AMET/VSIMS/Software/Equipment) to eliminate manual data transfer, ensure data integrity, and reduce effort.\r\n\r\n**Value:**\r\nSignificantly reduces manual effort and human error through extensive automation and guided workflows. It accelerates testing, streamlines data transfer between systems, and reduces complexity and costs associated with redundant methods and systems. This improves data integrity, enables proactive detection of quality events, and optimizes resource management for lab materials.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Our lab operations are automated or guided by digital workflows following standardized methods with review by exception",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Lab Planning and Scheduling (QC01): For receiving test orders and providing feedback on test execution status. (QC14)\r\nSpecification Creation and Handling (QC02): For receiving test methods and specifications. (QC14)\r\nSampling and Sample Storage (QC03): For receiving samples.\r\nResult Generation, Evaluation & Release (QC05): For forwarding raw data and test execution records.\r\nLIMS/LES/AMET: Central to test execution, data capture, and workflow management. (QC13, QC14, QC19)\r\nERP (e.g., SAP QM): For master data, batch information, and potentially inventory management. (QC17, QC18, QC19)\r\nEquipment/Instruments: Direct connection for control and data acquisition. (QC13, QC19)\r\nManufacturing Systems (MES/PCS): For in-line testing data and sample draw. (QC16)\r\nProcurement/Order Management (QC01): For reagent and compound inventory management and ordering. (QC17)\r\nSupplier Systems: For CoA and other data. (QC18)\r\nDeviation Management Systems (e.g., GoTrack): For automated event creation. (QC15)",
        "what_is_actually_done": "Implement a unified Lab Execution System (LES) with guided, system-based instructions (recipes) for test preparation and execution. Provide harmonized global recipes (e.g., Lab4U for AMET) and standardized preparation templates. Offer a user-friendly, harmonized UI independent of underlying tools/EQs, displaying necessary settings and step-by-step worker assistance. Connect with all equipment software solutions for online checks and system-supported deviation detection. Enable digital guided workflows with review by exception (QC13 / USE CASE 14). Automate sample preparation (stock solutions, solvents, mobile phases, pipetting) and testing execution using robotics and advanced automation. Utilize modular, repository-based robotics solutions with workflows derived from testing specifications. Integrate with laboratory management systems for seamless operation and activity feedback to planning/scheduling. Implement automated visual inspection (QC14 / USE CASE 15). Automatically generate quality event documentation (OOS, discrepancies) during the QC process step. Utilize AI for QC data processing, automated OOS/discrepancy detection, and real-time alerts. Connect deviation tools (e.g., GoTrack) to LIMS and other systems for automated event creation and data transfer. Link deviation information/reports to batch/lab documentation (QC15 / USE CASE 18). Increase in-line testing and leverage production process data to reduce or eliminate traditional In-Process Controls (IPCs). Integrate with manufacturing systems for actual drawing of samples for in-line tests (QC16 / USE CASE 20). Implement automated systems for storing and managing compounds (chemicals, columns). Utilize a digital tool with harmonized master data to manage reagents. Link to order management (process step 1) for automated ordering based on stock and needs (QC17 / USE CASE 17). Automate the transfer of data from suppliers (e.g., CoA via XML import files, scan with text recognition) into internal systems (e.g., SAP QM). Reduce manual effort in transferring supplier information (QC18 / USE CASE 19). Ensure seamless, vertical E2E integration of all layers (ERP/LIMS/AMET/VSIMS/Software/Equipment). Eliminate manual data transfer and system interfaces to ensure data integrity and reduce effort. Provide interfaces to pre/subsequent systems (QC19 / USE CASE 16).",
        "pain_points": "Testing Preparation:\r\nLabs buying reagents themselves without central control.\r\nEvery lab can order what they want, leading to variability.\r\nWorkflow creation for execution systems is manual and time-consuming.\r\nMultiple (e.g., ~10) systems to handle for end-users.\r\nMany different systems and UIs for end-users.\r\nManual naming conventions.\r\nTesting Execution:\r\nRedundant testing methods due to small deviations.\r\nNeed to set up the same master data at different sites.\r\nPaper-based assay documentation.\r\nMany different software solutions/UIs.\r\nRedundant systems, high complexity, and costs.\r\nOld test execution methods that are time-consuming (e.g., overnight).\r\nLack of interfaces between LIMS and lab systems (e.g., LabX, Omnis).\r\nWorkflow creation for execution systems is manual and time-consuming.\r\nLargely non-automated test execution (old methods, no NIR).\r\nHigh system complexity for testing, lack of overview.\r\nMany different logins needed, consuming time.\r\nProblematic data transfer between lab systems.\r\nGeneral:\r\nNo data connection, no manual data transfer (for Connected Systems - QC19 / USE CASE 16).\r\nReagent and stock management done manually per lab, not based on planned needs (for Automated Storage - QC17 / USE CASE 17).\r\nManual creation of quality events and manual data transfer to GoTrack. (QC15 / USE CASE 18)\r\nGoTrack UI not user-friendly. (QC15 / USE CASE 18)\r\nEvent data incomplete or with failures (audit findings). (QC15 / USE CASE 18)\r\nReal-time creation of events is often an issue. (QC15 / USE CASE 18)\r\nHigh effort in transferring information from suppliers. (QC18 / USE CASE 19)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 45,
        "bi_id": "PS-QC-006",
        "name": "06 | QC DATA ANALYSIS AND TRENDING",
        "area_id": 6,
        "step_description": "**Purpose:**\r\nTo transform data into process insights through a user-centric framework that allows continuous and automated QC data analysis, supported by AI to identify patterns across the analytical panel.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Automated Data Linkage:** Automatically link analytical data to predefined trending scenarios, reducing manual steps (e.g., mapping) and serving as a prerequisite for predictive analytics.\r\n-   **Predictive Analytics & AI-Powered Trending:** Employ AI for correlating analytical results within or across batches, identifying trends, patterns, and shifts for health checks of methods/equipment/labs, supporting real-time trending and automated report generation (CPV, PQR, MQR).\r\n-   **Root Cause Prediction:** Utilize AI to cluster OOS events by shift, equipment, or analyst, identifying patterns for root cause analysis and proactive prevention.\r\n-   **Non-Analytical Data Trending:** Automate the trending and evaluation of available lab data (e.g., discrepancies, equipment availability) using AI, providing timely notifications if patterns arise.\r\n-   **Comprehensive Quality Assessment:** Automatically assess products (SCRA), suppliers (Purchasing Assessments, RQA), and other quality events using non-analytical data, implementing a unified trending approach.\r\n\r\n**Value:**\r\nTransforms raw data into actionable insights, enabling proactive identification and prevention of quality issues before they occur. It eliminates manual trending efforts, reduces complexity, provides a holistic picture of quality events, and supports data-driven decision-making for process improvement, compliance, and supplier risk management.",
        "raw_content": null,
        "summary": null,
        "vision_statement": "Our user-centric framework allows continuous & automated QC data analysis, supported by AI to identify patterns across the analytical panel",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "Result Generation, Evaluation & Release (QC05): For sourcing QC analytical data.\r\nLIMS/LES/ERP (SAP QM): Primary sources for analytical and operational QC data.\r\nQuality Event Systems (e.g., GoTrack, SCRA, RQA): For non-analytical data like deviations, supplier assessments. (QC26)\r\nManufacturing Systems (MES): For process parameters that might be correlated with QC trends.\r\nEquipment Management Systems (QC07): For equipment availability and maintenance data. (QC26)\r\nManagement Reporting Systems / BI Platforms: For disseminating trend reports and dashboards. (QC25)\r\nQuality Assurance (QA): For insights into product quality, process stability, and CAPA effectiveness.",
        "what_is_actually_done": "Automatically link analytical data to predefined trending scenarios. Reduce manual steps currently performed in systems like GDTS (e.g., mapping). Serve as a prerequisite for predictive analytics (QC24 / USE CASE 27). Use predictive analytics to identify potential quality issues before they occur (proactive measures). Employ AI for correlating analytical results within a batch or across multiple batches of a product. Utilize AI for identifying trends, patterns, shifts, and for health checks of methods/equipment/labs. Support real-time trending based on actual data. Enable AI-assisted automated trending, report generation (CPV, PQR, MQR), and self-service analytics on GxP validated QC data pools (QC25 / USE CASE 26). Automate the trending and evaluation of available lab data (e.g., discrepancies, equipment availability) using AI. Provide timely notifications if patterns arise. Automatically assess products (SCRA), suppliers (Purchasing Assessments, RQA), etc., using this non-analytical data. Implement a unified trending approach for all quality events, including report generation (QC26 / USE CASE 28).",
        "pain_points": "No clear vision for trending; scattered approaches are used.\r\nAll trending activities involve many manual steps.\r\nNo connection of all equipment to systems; still relying on logbooks and several disparate systems.\r\nIt's not clear what should be shown with trending.\r\nTrending is done in multiple systems with a lot of manual steps.\r\nSystems are not user-friendly for data analysis.\r\nGetting data easily is not possible; a lot of manual work is involved.\r\nSix to seven different trending reports that still don't provide a holistic picture.\r\nNo connection/interface to equipment to have data ready for monitoring/long-term overview.\r\nOnly partial integration of equipment into a \"data lake.\"\r\nKPIs are measured but not used; no common QC KPIs.\r\nCMO data: Client responsibility, not all data governed by BI.\r\nManual data trending, no central governance, or overarching guidance.\r\nEven for critical attributes, global solutions are not available in a user-friendly way.\r\nManual steps in GDTS (e.g., mapping) for linking data to trending scenarios. (USE CASE 27)",
        "targets_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 46,
        "bi_id": "PM-01",
        "name": "01 | Breaking down goals and setting targets",
        "area_id": 8,
        "step_description": "**Purpose:**\r\nTo systematically translate high-level strategic company goals into actionable, measurable, and unit-specific targets, ensuring clear organizational alignment and commitment.\r\n\r\n**Key Tasks:**\r\n\r\n-   **Goal Cascade & Frameworks:** Implementing structured approaches like Balanced Scorecard, OKRs, or Hoshin Kanri to break down strategic objectives into unit-specific targets.\r\n-   **Interdependency Management:** Identifying, prioritizing, and managing the complex co-dependencies between various organizational goals to ensure alignment and prevent conflicts.\r\n-   **Cross-functional Commitment:** Securing commitment and buy-in from all involved parties across different departments and business units.\r\n-   **Standardized Prioritization:** Defining clear criteria for prioritizing goals and targets to maintain focus and avoid overcommitment.\r\n-   **Baseline Review:** Regularly reviewing and adjusting KPI baselines and targets to ensure they remain appropriate and dynamic.\r\n\r\n**Value:**\r\nEnsures that strategic objectives are effectively cascaded throughout the organization, driving clear alignment, measurable impact, and scalable performance management. This fosters commitment, reduces conflicting priorities, and enables systematic progress towards overall company goals.",
        "raw_content": null,
        "summary": "Based on given strategic company goals, relevant and binding unit-specific targets are broken down and set.",
        "vision_statement": "Strategic goals are translated and broken down into team targets through standardized principles and system-driven insights. This enables clear alignment, measurable impact, and scalable performance management.",
        "in_scope": null,
        "out_of_scope": null,
        "interfaces_text": "test",
        "what_is_actually_done": "The first core process step addresses how pharmaceutical manufacturers typically translate high-level strategic company goals into actionable, unit-specific targets. This foundational element of performance management faces several significant challenges, including securing commitment from all involved parties, the absence of standardized approaches for goal breakdown, lack of focus due to too many competing priorities, and the complex co-dependencies that exist between various organizational goals.\r\n\r\nThe research framework identifies the need to understand common methodologies and structured approaches employed for goal breakdown and target setting, specifically mentioning frameworks such as Balanced Scorecard, Objectives and Key Results (OKRs), and Hoshin Kanri/Policy Deployment. These established methodologies provide pharmaceutical companies with systematic approaches to ensure that strategic objectives are effectively cascaded throughout the organization while maintaining alignment and avoiding conflicts between different departmental or functional goals.\r\n\r\nCross-functional commitment and buy-in represent critical success factors in this process, requiring pharmaceutical companies to develop sophisticated approaches for securing engagement across different departments and business units. The research emphasizes understanding how organizations typically identify, prioritize, and manage the interdependencies between various goals to ensure alignment and avoid conflicts that could undermine overall performance.",
        "pain_points": "Commitment of all involved parties\r\nNo standarized approach in breaking down goals\r\nMore focus (not too many of the highest priority)\r\nCo-dependencies of goals",
        "targets_text": "Commitment and Engagement of All Stakeholders\r\nPrioritization is based on clearly defined criteria\r\nprocess is scalable and applicable across the organization\r\nTransparent mapping of goal linkages and dependencies",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      }
    ],
    "use_cases": [
      {
        "id": 6,
        "bi_id": "SCM21",
        "name": "Enabler for MD harmonization",
        "process_step_id": 12,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": null,
        "effort_level": "high",
        "status": "high",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Based on desired level of automation describe pre-requisites from data, process, system view. Define planning relevant parameters and rules for structure of planning relevant data objects/fields. Classify which data requirements are needed to support which planning aspect/process. Create tools to identify gaps easily and give guidance for adjustments. Integrated network wide, harmonized data model. Global governance for manufacturing master data (production versions, recipes, resources) to enable aggregation and global transparency.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "...",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:04:55.172241+00:00"
      },
      {
        "id": 9,
        "bi_id": "PM-UC-19",
        "name": "Action Tracker & PDCA Guidance",
        "process_step_id": 41,
        "priority": null,
        "raw_content": null,
        "summary": "Tool to track actions including alerting and reminding system. Integrated tracking system for action follow-up. Time assignment. Possibility to link actions to KPIs. System support for monitoring the PDCA-Cycle, especially check. Interactive PDCA cycle, digital with access to real-time KPIs. System supported determination of actions incl. description, priority, responsible person and due date. No separate tool, but part of system that indicates deviating KPI and actions. Tool automatically shows resolution status and timeline / overdue actions. Possibility to review time to resolution grouped by topic",
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "Actions are not always consequently followed up and action owner does not sufficiently describe activities and result of problem solving",
        "target_solution_description": "Tool to track actions including alerting and reminding system. Integrated tracking system for action follow-up. Time assignment. Possibility to link actions to KPIs. System support for monitoring the PDCA-Cycle, especially check. Interactive PDCA cycle, digital with access to real-time KPIs. System supported determination of actions incl. description, priority, responsible person and due date. No separate tool, but part of system that indicates deviating KPI and actions. Tool automatically shows resolution status and timeline / overdue actions. Possibility to review time to resolution grouped by topic",
        "technologies_text": "ServiceNow could be a technology. Global task tracking tool, e.g. Service Now",
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Integrated tracking system for action follow-up. Time assignment. Possibility to link actions to KPIs. Tool to track actions including alerting and reminding system. Actions are not always consequently followed up and action owner does not sufficiently describe activities and result of problem solving",
        "further_ideas": "System support for monitoring the PDCA-Cycle, especially check. Interactive PDCA cycle, digital with access to real-time KPIs. System supported determination of actions incl. description, priority, responsible person and due date. Tool to track actions including notification and reminding system. No separate tool, but part of system that indicates deviating KPI and actions. Tool automatically shows resolution status and timeline / overdue actions. Possibility to review time to resolution grouped by topic. ServiceNow could be a technology. Global task tracking tool, e.g. Service Now. Higher acceptance of actions due to less recurrence of actions",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "Initial evaluation: Medium. REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": "OPEX contact? Service Now SME",
        "related_projects_text": "Service Now SME",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:28:05.450737+00:00"
      },
      {
        "id": 17,
        "bi_id": "PM-UC-24",
        "name": "APOLLO Interface access for all digital solutions",
        "process_step_id": 30,
        "priority": null,
        "raw_content": null,
        "summary": "Native APOLLO interface to ANY digital solution. APOLLO Interface access for all digital solutions. Future connection to AI models is needed to be ready for future use-cases. Maximizing performance by giving the means to do deeper analysis",
        "inspiration": null,
        "wave": null,
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "Many of our current applications have no native connection to AI. Working manually with large amounts of data or finding patterns in data not feasible. Non-data-driven approach creates local maxima in performance instead of global",
        "target_solution_description": "Native APOLLO interface to ANY digital solution. APOLLO Interface access for all digital solutions. Future connection to AI models is needed to be ready for future use-cases. Maximizing performance by giving the means to do deeper analysis",
        "technologies_text": "APOLLO. Various LLM's",
        "requirements": "Easy and scalable way to get APOLLO integration in individual use cases. Continuously high improvement rate of AI models. Data interfaces/ KPI/ data lake. For maximum benefit: model at least partially trained on BI data",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Native APOLLO interface to ANY digital solution. Many of our current applications have no native connection to AI. Working manually with large amounts of data or finding patterns in data not feasible. Non-data-driven approach creates local maxima in performance instead of global",
        "further_ideas": "Future connection to AI models is needed to be ready for future use-cases. Maximizing performance by giving the means to do deeper analysis. Easy and scalable way to get APOLLO integration in individual use cases. Continuously high improvement rate of AI models. Data interfaces/ KPI/ data lake. For maximum benefit: model at least partially trained on BI data. APOLLO. Various LLM's",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:29:46.472030+00:00"
      },
      {
        "id": 13,
        "bi_id": "PM-UC-32",
        "name": "Upskilling & Training for Performance with AI bot trainer",
        "process_step_id": 42,
        "priority": null,
        "raw_content": null,
        "summary": "Offer hard skill trainings for tech / innovation topics. Using BI University to support education regarding use of digitalized tools and dashboards. Fancy trainings to educate employees (customized according to their role) in performance management. Virtual learning environments. Individualized trainings with an AI bot educating colleagues on the training gaps. Individual AI empowered agent development to boost performance. Training with AI bot / coach on individual and role based needs. KPI Interactive training. Focused development plans",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "High human errors rate. Slow reaction to problems. Scattered responsibility. Boring training methods. Low / delayed LOS training. Confirm training completeness while not truly trained",
        "target_solution_description": "Offer hard skill trainings for tech / innovation topics. Using BI University to support education regarding use of digitalized tools and dashboards. Fancy trainings to educate employees (customized according to their role) in performance management. Virtual learning environments. Individualized trainings with an AI bot educating colleagues on the training gaps. Individual AI empowered agent development to boost performance. Training with AI bot / coach on individual and role based needs. KPI Interactive training. Focused development plans",
        "technologies_text": "BI University Training 2.0. LLM/Apollo. Self trained model",
        "requirements": "Alignment on training requirements. Sufficient training materials. Infrastructure to support knowledge management. Approval for common trainings",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Offer hard skill trainings for tech / innovation topics. Using BI University to support education regarding use of digitalized tools and dashboards. Fancy trainings to educate employees (customized according to their role) in performance management. Interactive training. High human errors rate. Slow reaction to problems. Scattered responsibility. Boring training methods. Low / delayed LOS training",
        "further_ideas": "Virtual learning environments. Individualized trainings with an AI bot educating colleagues on the training gaps. Individual AI empowered agent development to boost performance. Training with AI bot / coach on individual and role based needs. KPI Interactive training. Focused development plans. Alignment on training requirements. Sufficient training materials. Infrastructure to support knowledge management. Approval for common trainings. LOS. BI University Training 2.0. LLM/Apollo. Self trained model. RFT improvement. Faster decision making and task completion",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "Initial evaluation: High. REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): RFT improvement, Faster decision making and task completion",
        "dependencies_text": null,
        "contact_persons_text": "Sue Townsend",
        "related_projects_text": "Sue Townsend",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:31:23.631409+00:00"
      },
      {
        "id": 19,
        "bi_id": "QC17",
        "name": "Automated storage and inventory management",
        "process_step_id": 44,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Waiting list",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "Reagent and stock management done manually per lab and not based on planned needs",
        "target_solution_description": "*   Description: Implement automated systems for the storage and management of compounds, linked to order management processes.\n*   Key Features: Automated labeling and storage of compounds. Inventory management for compound supplies. Real-time tracking of storage conditions and order management.\n*   Automatical ordering process based on stock and needs. Automated handling in the system.",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Automated storage and inventory management\n*   storage system for compounds(e.g. chemicals, columns, etc.)\n*   Digital tool to manage reagents with harmonized master data\n*   Description: Implement automated systems for the storage and management of compounds, linked to order management processes. Key Features: Automated labeling and storage of compounds. Inventory management for compound supplies. Real-time tracking of storage conditions and order management.\n*   Reagent and stock management done manually per lab and not based on planned needs\n*   Linked to use case in process step 1 (Order management)\n*   Automatical ordering process based on stock and needs. Automated handling in the system.",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "Linked to use case in process step 1 (Order management); Lab4u",
        "contact_persons_text": "Process: Gerlinde Pl\u00f6ger",
        "related_projects_text": "Lab4u",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 20,
        "bi_id": "QC15",
        "name": "Automated quality events documentation",
        "process_step_id": 44,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   manual creation of quality events and manual transfer of data from source systems into GoTrack\n*   GoTrack user interface not user friendly\n*   data are not complete oor with failure (audit findings)\n*   realtime creation of events often an issue",
        "target_solution_description": "*   automatic creation of GoTrack events out of source systems\n*   feedback event number from GoTrack to source system for transparency\n*   cross check in GoTrack for existing events and trending",
        "technologies_text": "*   GoTrack\n*   Dataland\n*   all lab systems (20-30 cross all businesses)\n*   GBS",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   No more manual entering of data in the deviation system since this is automatically generated during the process step in QC\n*   Description: Use AI to process QC data, including automated triggering of OOS (Out of Specification) and discrepancies.\n*   Key Features: AI-driven data analysis. Automated OOS and discrepancy detection. Real-time alerts for QC issues.\n*   Automated quality events documentation (incl. Intelligent OOS and Discrepancy Management)\n*   manual creation of quality events and manual transfer of data from source systems into GoTrack\n*   GoTrack user interface not user friendly\n*   data are not complete oor with failure (audit findings)\n*   realtime creation of events often an issue\n*   Deviation tool connected to lims and other systems.\n*   automatic creation of GoTrack events out of source systems\n*   feedback event number from GoTrack to source system for transparency\n*   cross check in GoTrack for existing events and trending\n*   Once created. It links the deviation information/ report to the batch / lab documentation\n*   zero touch documentation\n*   No manual scanning of e.g. consumables (like shopping)\n*   Automated triggering of discrepancies/ OOS\n*   Automated start/creation of OOX procedures or discrepancy/deviation process in GoTrack --> autmated comparison of limits and specifications\n*   Qualitative Benefits: easier handling for user in lab (do they need GoTrack?)\n*   High potential for less GoTrack user (~400 user just for Ingelheim)\n*   less loops and steps in event creation, review and management",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "High; High potential for less GoTrack user (~400 user just for Ingelheim); less loops and steps in event creation, review and management",
        "dependencies_text": "IT/GBS",
        "contact_persons_text": "Process / Quality System requirements: Sascha Klein, Tatjana Popara, Christina Faul",
        "related_projects_text": "*   GoTrack trending tool and cross check tool in development\n*   IDA BIX project to use AI for Complaint creation",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 21,
        "bi_id": "QC16",
        "name": "In-line testing to reduce IPCs",
        "process_step_id": 44,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "Babtec, Inmation",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   In-line testing to reduce IPCs\n*   Which IPC's do we really need?\n*   use process data to get rid of IPC's\n*   Leverage on data of production to reduce IPCs\n*   Increase in-line testing to reducre IPCs (actual drawing of samples)\n*   Linked to Manufacturing\n*   Babtec, Inmation",
        "further_ideas": "n.a.",
        "effort_quantification": "Hard",
        "potential_quantification": "High",
        "dependencies_text": "Linked to Manufacturing; link to manufacturing use case (in line testing)",
        "contact_persons_text": "n.a.",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 23,
        "bi_id": "PM-UC-06",
        "name": "Automized target and KPI baseline review tool",
        "process_step_id": 46,
        "priority": null,
        "raw_content": null,
        "summary": "Automized yearly review of KPI baseline if it is still appropriate including targets. Regular KPI check process by ensuring all metrics are relevant. Dynamic KPI targets",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Need for regular review of KPI baselines to ensure they remain appropriate. Ensuring all metrics are relevant and up-to-date",
        "target_solution_description": "Automized yearly review of KPI baseline if it is still appropriate including targets. Regular KPI check process by ensuring all metrics are relevant. Dynamic KPI targets",
        "technologies_text": "There is no global solution needed because it can be considered in dashboarding",
        "requirements": "Breaking down goals and setting targets. KPI tree",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Automized yearly review of KPI baseline if it is still appropriate including targets. Regular KPI check process by ensuring all metrics are relevant",
        "further_ideas": "KPI tree",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null. Initial evaluation: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:20:12.844737+00:00"
      },
      {
        "id": 72,
        "bi_id": "M18",
        "name": "Automated creation of audit documentary",
        "process_step_id": 27,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "Medium/Low",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Automatic audit preparation with production/quality data\n*   Reduction of Audit preparation time",
        "further_ideas": "*   Innovation idea available? (Oliver Gluth)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   \u00c4hlich zu 21, aber unterschiedl. Use Cases. Austausch n\u00f6tig bei Ausarbeitung (Similar to 21, but different Use Cases. Exchange necessary during elaboration)\n*   Schnittstelle zu Quality (Interface to Quality)",
        "contact_persons_text": "*   Hans-Joachim Ploss (Head of Corp. Quality Audits & Inspection)\n*   GBS: Dorothea Kappesser (ME) for system audit presentation\n*   Oliver Gluth (for Innovation Idea)\n*   Chemie/Quality: Markus Wheeldon",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 26,
        "bi_id": "PM-UC-12",
        "name": "Proactive Trending & Alerting System",
        "process_step_id": 40,
        "priority": null,
        "raw_content": null,
        "summary": "Escalation/Alerting System. Identification of trends, deviations (gaps vs. targets), risks & opportunities. Early warning system for proactive problem prevention incl. e.g. data from one unit might negatively impact another unit. Data driven KPI monitor predicts which target will likely be reached or missed by the end of a certain reporting period. Forecasting of KPIs/target achievements (forward looking KPIs). Automated escalation notification. Data-driven, automated identification of risks and opportunities. Correlation/dependencies monitoring. Dynamic and real time performance path calculation. Forward looking analysis and discussions",
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": "No prewarning that targets/KPIs will not be reached. No warning system regarding upcoming issues. No automated alerts are triggered by predefined thresholds to notify stakeholders when targets are at risk. Lack of early warning system for proactive problem prevention",
        "target_solution_description": "Escalation/Alerting System. Identification of trends, deviations (gaps vs. targets), risks & opportunities. Early warning system for proactive problem prevention incl. e.g. data from one unit might negatively impact another unit. Data driven KPI monitor predicts which target will likely be reached or missed by the end of a certain reporting period. Forecasting of KPIs/target achievements (forward looking KPIs). Automated escalation notification. Data-driven, automated identification of risks and opportunities. Correlation/dependencies monitoring. Dynamic and real time performance path calculation. Forward looking analysis and discussions",
        "technologies_text": "KPI trending limits / alarm limits defined to initiate (preventive) continuous improvement actions. IT Tool for identification of trends, deviations (gaps vs. targets), risks & opportunities. Use AI to identify trends and create early alerts. KPI Thresholds/limits defined and transparent to trigger mitigation actions. Data driven KPI monitor that predicts target achievement",
        "requirements": "In CSI we already have two clearly defined thresholds for process parameters: Alarm Limit - Watch KPI trend more closely, Action Limit - Now you have to take action. KPI Thresholds/limits defined and transparent to trigger mitigation actions. Integration with existing monitoring systems. Real-time data connectivity",
        "relevants_text": "All areas with KPI monitoring requirements. CSI (Continuous System Improvement)",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Escalation/Alerting System. Identification of trends, deviations (gaps vs. targets), risks & opportunities. In CSI we already have two clearly defined thresholds for process parameters: Alarm Limit - Watch KPI trend more closely, Action Limit - Now you have to take action. Early warning system for proactive problem prevention incl. e.g. data from one unit might negatively impact another unit. KPI trending limits / alarm limits defined to initiate (preventive) continuous improvement actions. Data driven KPI monitor predicts which target will likely be reached or missed by the end of a certain reporting period. Forecasting of KPIs/target achievements (forward looking KPIs). Automated escalation notification. No prewarning that targets/KPIs will not be reached. No warning system regarding upcoming issues. No automated alerts are triggered by predefined thresholds to notify stakeholders when targets are at risk. Data-driven, automated identification of risks and opportunities. Correlation/dependencies monitoring. Dynamic and real time performance path calculation. Forward looking analysis and discussions. KPI Thresholds/limits defined and transparent to trigger mitigation actions. Data driven KPI monitor predicts which target will likely be reached or missed by the end of a certain reporting period. Use AI to identify trends and create early alerts. IT Tool for identification of trends, deviations (gaps vs. targets), risks & opportunities",
        "further_ideas": null,
        "effort_quantification": "Operating cost (Opex): Software as a service cost. Invest (Capex): Cost for IT implementation. Implementation time: null. Initial evaluation: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:25:37.387386+00:00"
      },
      {
        "id": 24,
        "bi_id": "PM-UC-17",
        "name": "Countermeasure impact and effectiveness tracker",
        "process_step_id": 41,
        "priority": null,
        "raw_content": null,
        "summary": "AI support to allocate the corresponding KPI out of the BI KPI landscape or even propose additional KPIs if needed - considering the level of aggregation (smart&consistent cascading). System supported translation of targets into concrete figures and KPIs for each individual area. KPI must be directly linked to a specific (strategic / tactical) goal and its action its quantitative upper/lower limit must be standardized across departments/units. Limitation of number of targets per organizational level (the higher the less). ONE system for KPIs that limits maximum number of KPI's (e.g. 20) must include human outside the system. Quality gate (check) to ensure purpose of a KPI. Linkage of KPIs to targets and of targets to goals",
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "No standardized tool to measure effectiveness of countermeasures/actions. Action \"effectiveness check\" incl. timeline defined and linked to respective KPI/goal. Automated assessment of effectiveness in regards to time to resolution, reoccurrence, sustainable improvement of respective KPI or Business Goal",
        "target_solution_description": "AI support to allocate the corresponding KPI out of the BI KPI landscape or even propose additional KPIs if needed - considering the level of aggregation (smart&consistent cascading). System supported translation of targets into concrete figures and KPIs for each individual area. KPI must be directly linked to a specific (strategic / tactical) goal and its action its quantitative upper/lower limit must be standardized across departments/units. Limitation of number of targets per organizational level (the higher the less). ONE system for KPIs that limits maximum number of KPI's (e.g. 20) must include human outside the system. Quality gate (check) to ensure purpose of a KPI. Linkage of KPIs to targets and of targets to goals",
        "technologies_text": "System support to find the right KPI which supports reaching the according target. KPI automated guide for connecting KPIs to Goals. Link KPI's to relevant strategic targets to make focus and potential conflicts transparent",
        "requirements": "KPI Definition & Cascading. Accept that a quantitative KPI can't always reflect complexity of qualitative goals/strategy",
        "relevants_text": null,
        "reduction_time_transfer": "Setting in time countermeasures without delays in transfer timeline",
        "reduction_time_launches": "Setting in time countermeasures without delays in launch timeline",
        "reduction_costs_supply": "Impact if contradicting goals exist",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "System support to find the right KPI which supports reaching the according target. KPI automated guide for connecting KPIs to Goals. Link KPI's to relevant strategic targets to make focus and potential conflicts transparent. Accept that a quantitative KPI can't always reflect complexity of qualitative goals/strategy. Tool to measure efficiency of measures with regard to gap closing. AI-based robustness check of actions. AI-based check of CAPA effectiveness. Continuous evaluation of countermeasures effectiveness",
        "further_ideas": "One target system (see picture). Countermeasures and effectiveness must be in the same system/module. Service Now? Trackwise similar to MAG Tool in Successfactor. Efficient performance steering process. Robustness increase. Reduction of costs (e.g. functional costs)",
        "effort_quantification": "Operating cost (Opex): Depends on system, licenses cost may arise. Invest (Capex): No Capex, but initial IT Budget. Implementation time: null. Initial evaluation: Medium",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: Setting in time countermeasures without delays in transfer timeline. REDUCTION OF TIME FOR PRODUCT LAUNCH: Setting in time countermeasures without delays in launch timeline. REDUCTION OF TOTAL COSTS OF SUPPLY: No delay in production plan => reduced risk for idle costs. QUALITY (RFT): No additional costs due to insufficient actions implemented. Initial evaluation: High",
        "dependencies_text": "Countermeasures need to be in same tool as the effectiveness tracker",
        "contact_persons_text": "Neves,Filipe Oliveira. Business: Lyse Wotschke, Britta Lifka. GBS MDM (Martin Treder).",
        "related_projects_text": "COPE replacement - PACE Workstream. COPE - Rene Kluiber ext. Version Stream. Bernhard Poll. Britta Lifka. Martin Treder MDM. BIPRISMA Replacement. MDG: Sabine Germeyer / Boris Klockow.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:28:01.713974+00:00"
      },
      {
        "id": 29,
        "bi_id": "QC20",
        "name": "Review and release by exception",
        "process_step_id": 23,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Wave 1",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": "Manual checks, multiple review and approval steps",
        "target_solution_description": "*   Analytical results and executed steps is available in the system, and automatically compared to limits and execution of the analytical procedures\n*   Review / manual approvals only required in case of exceptions\n*   Description: Automate the review process by the compliance team to ensure QC data integrity and regulatory adherence.\n*   Key Features: Automated compliance checks for QC data. Real-time review notifications. Integration with compliance management systems.",
        "technologies_text": "*   SAP / Lab4U MyLIMS/AMES BRC\n*   ERP / Method Execution layer BRC",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Review and release by exception\n*   review by exception\n*   Review by exception. Only apporval or review of data/audit trail if something is out of the ordinary\n*   Manual checks, multiple review and approval steps\n*   Review by exception\n*   Review only when limits/specs are violated or patterns identified. (e.g. AI based analyzation of results)\n*   result evaluation and automated documentation within limit and spec - review by exception\n*   Analytical results and executed steps is available in the system, and automatically compared to limits and execution of the analytical procedures\n*   Review / manual approvals only required in case of exceptions\n*   AI based batch simulation to reduce number of quality tests to a minumum\n*   Description: Automate the review process by the compliance team to ensure QC data integrity and regulatory adherence. Key Features: Automated compliance checks for QC data. Real-time review notifications. Integration with compliance management systems.\n*   SAP / Lab4U MyLIMS/AMES BRC\n*   ERP / Method Execution layer BRC",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium, Hard",
        "potential_quantification": "High",
        "dependencies_text": "LES is prerequisite; Lab4U; DI: Andrew Riederer",
        "contact_persons_text": "n.a.",
        "related_projects_text": "*   link to RTRT Project (Andreas Oefner)\n*   SAP QM / MyLIMS ( Viriginia Cedeno / Jennifer Seefeldt, Christopher Stratil )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 45,
        "bi_id": "QC27",
        "name": "Unified Equipment Management System",
        "process_step_id": 24,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   Equipment information is not available in a harmonized, transparent system.\n*   This information is critical/pre-requisite for many systems in the QC Digitalization roadmap and a critical enabler\n*   Information is required for various planning of Lab activities, maintenance and other processes which is currently time consuming to obtain",
        "target_solution_description": "*   Develop a comprehensive system to manage all equipment data, ensuring consistent controls and streamlined processes.\n*   may SAP PM",
        "technologies_text": null,
        "requirements": "*   Centralized Database: Store all equipment data including qualifications, calibrations, daily checks, and maintenance data.\n*   Traffic Light System: Show the current status of equipment (ready/not ready for use).\n*   Resource Optimization: Identify needed/unneeded resources based on production output.\n*   Metadata Enrichment: Enrich metadata of equipment in SAP/PM to support further harmonization.\n*   Global Platform: Include critical lab equipment data for systematization across the architecture.\n*   U\n*   Usage Blocking: System blocks usage if equipment is not ready for use.\n*   Availability Tracking: Provide information on equipment availability (free, next available time slot).\n*   Maintenance Data: Database for critical lab maintenance data, repair data, etc.\n*   Scheduled Maintenance Optimization: AI-based optimization of scheduled maintenance.\n*   Global Maintenance Approach: Standardize maintenance approach globally (similar to calibration).",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Description: Maintain a comprehensive digital database and logbook for equipment data, history, maintenance, and calibration records. Key Features: Centralized equipment data repository. Historical records of equipment usage and maintenance. Digital logbook accessible via mobile devices. Automated maintenance scheduling and calibration tracking. Real-time updates and notifications.\n*   Unified Equipment Management System\n*   Equipment information is not available in a harmonized, transparent system.\n*   This information is critical/pre-requisite for many systems in the QC Digitalization roadmap and a critical enabler\n*   Information is required for various planning of Lab activities, maintenance and other processes which is currently time consuming to obtain\n*   Database to store all equipment data like qualifications, calibrations, daily checks, ... And traffic light to show the current status\n*   needed/unneeded ressources identified based on production forecast\n*   enrich metadata of equipment in SAP/PM to support further harmonization (equipment class for lab equipment or information needed in AMET)\n*   Global platform to include critical lab equipment data that is interfaced to different systems across the architecture where the data is required.\n*   Develop a comprehensive system to manage all equipment data, ensuring consistent controls and streamlined processes.\n*   Create Database in AAS -> EQ & Capabilities as well as status.\n*   System blocks usage if equipment is not ready for use\n*   may SAP PM\n*   status overview (blocked, free, calibration status, functional testing, etc.)\n*   Optimization of maintanance activities based on use cycles/historical maintainance data (e.g. AI based)\n*   global maintenance approach (same duration, same functional test parameter etc.)\n*   One data base for all equipments that provides all needed information (e.g., block or free, next calibration, maintenance activities)\n*   database for equipment incl. maintenance data, repair data, etc. (handover from suppliers)\n*   Centralized Database: Store all equipment data including qualifications, calibrations, daily checks, and maintenance data.\n*   Traffic Light System: Show the current status of equipment (ready/not ready for use).\n*   Resource Optimization: Identify needed/unneeded resources based on production output.\n*   Metadata Enrichment: Enrich metadata of equipment in SAP/PM to support further harmonization.\n*   Global Platform: Include critical lab equipment data for systematization across the architecture. U\n*   Usage Blocking: System blocks usage if equipment is not ready for use.\n*   Availability Tracking: Provide information on equipment availability (free, next available time slot).\n*   Maintenance Data: Database for critical lab maintenance data, repair data, etc.\n*   Scheduled Maintenance Optimization: AI-based optimization of scheduled maintenance.\n*   Global Maintenance Approach: Standardize maintenance approach globally (similar to calibration).",
        "further_ideas": "Idea",
        "effort_quantification": "Medium",
        "potential_quantification": "High",
        "dependencies_text": "n.a.",
        "contact_persons_text": "Claudia Schneider",
        "related_projects_text": "DigiLab Program -> DigiEngine-> Equipment Standardization Stream ( Jennifer Seefeldt / Heike Gottschalg)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 35,
        "bi_id": "QC22",
        "name": "Automated Result Generation and Reporting",
        "process_step_id": 23,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Wave 2",
        "effort_level": null,
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Description: Automate the generation of QC results with standardized reports and notifications.\n*   Key Features: Standardized QC result reports. Automated notifications for result availability. Integration with QC data systems.",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Automated Result Generation and Reporting\n*   automated result generation (data processing)\n*   Automated result generation and evaluation against predefined limits\n*   automated data calculation and processing through the different layers\n*   Raw data are processes automatically\n*   Evaluation considering whole analytical panel of product\n*   Description: Automate the generation of QC results with standardized reports and notifications. Key Features: Standardized QC result reports. Automated notifications for result availability. Integration with QC data systems.\n*   Evaluation of patterns\n*   automated result transfer from source system into LIMS\n*   AI, machine learning",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "Process/system owner for the respective Software",
        "contact_persons_text": "Carolin Becker, Andreas Oefner",
        "related_projects_text": "*   Project: Lab4U Evolution Phase 2 (67334)\n*   SAP QM / MyLIMS ( Viriginia Cedeno / Jennifer Seefeldt, Christopher Stratil )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 54,
        "bi_id": "QA18",
        "name": "Modular deviation & CAPA list generation",
        "process_step_id": 18,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   one click generation of deviation / CAPA lists with adaptable content\n*   Many informations are available from gotrack\n*   Simplify retrieval of audit lists\n*   easy creation of lists (e.g. for audits) is possible",
        "further_ideas": "n/a",
        "effort_quantification": "Easy; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Low/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:53:56.697638+00:00"
      },
      {
        "id": 37,
        "bi_id": "QA12",
        "name": "Multi-site data comparison and proactive trend detection",
        "process_step_id": 31,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   enable comparison of APQRs for multi site products based on data generated ==> understand if potential issues are site or product related\n*   trending across systems supported by AI",
        "further_ideas": "n/a",
        "effort_quantification": "Medium/Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:51:53.776887+00:00"
      },
      {
        "id": 38,
        "bi_id": "QC25",
        "name": "Predictive Analytics and AI-Powered Trending",
        "process_step_id": 45,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Wave 2",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Description: Leverage predictive analytics and AI to forecast quality trends and uncover deeper insights in both analytical and non-analytical data.\n*   Key Features: Predictive modeling for future quality trends. AI-driven identification of OOT and OOS scenarios. Automated linkage of data to trending scenarios. Enhanced AI insights with root cause analysis. Comprehensive evaluation of non-analytical data trends. Monitoring and tracking sample sample progression.",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Predictive Analytics: Use predictive analytics to identify potential quality issues before they occur, allowing for proactive measures.\n*   AI based correlation of analytical results from one batch or correlation across multiple produced batches from one product\n*   AI based analyzation an trending of results. Identification of patterns, shifts. establish/re-calculate limits\n*   Predictive Analytics and AI-Powered Trending\n*   AI based identification of trends and patterns\n*   AI guided health check for methods/equipment/Labs\n*   automated trending/data analysis for all analytical methods and results\n*   \"real time\" trending based on actual data\n*   Description: Leverage predictive analytics and AI to forecast quality trends and uncover deeper insights in both analytical and non-analytical data. Key Features: Predictive modeling for future quality trends. AI-driven identification of OOT and OOS scenarios. Automated linkage of data to trending scenarios. Enhanced AI insights with root cause analysis. Comprehensive evaluation of non-analytical data trends. Monitoring and tracking sample sample progression.\n*   AI supported trending set-up, evaluation and reporting (validated)\n*   Self service trending and analytics based on GxP validated QC data pool\n*   Automated Trendings /Monitoring (QC / CPV / PQR etc.)\n*   AI assissted automated trending and report generation for routine trendings/monitorings (CPV, PQR, MQR)",
        "further_ideas": "n.a.",
        "effort_quantification": "Hard",
        "potential_quantification": "High",
        "dependencies_text": "n.a.",
        "contact_persons_text": "*   Carolin Becker, Andreas Oefner\n*   Ingo Albert\n*   Marc Schuwerack",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 39,
        "bi_id": "QC29",
        "name": "Automated Periodic Review",
        "process_step_id": 24,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3",
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "lets start semi automated",
        "requirements": "*   must consider all data like events, devations, changes, SLC doc .....\n*   should evaluate on negative trends",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Description: Automate the periodic review of compliance systems and reporting, including methods validation.\n*   Key Features: Automated compliance review processes. Regular reporting and validation checks. Integration with quality management systems.\n*   semi-automated is a fist step\n*   Automated Periodic Review\n*   automated periodic review for computer systems and equipment\n*   also methods, validation, excel files\n*   must consider all data like events, devations, changes, SLC doc .....\n*   lets start semi automated\n*   should evaluate on negative trends",
        "further_ideas": "Idea",
        "effort_quantification": "Medium",
        "potential_quantification": "High",
        "dependencies_text": "n.a.",
        "contact_persons_text": "*   Caroline Becker\n*   Jens Lueers",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 44,
        "bi_id": "QC18",
        "name": "Supplier data integration",
        "process_step_id": 44,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Waiting list",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "SAP/QM",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Supplier data integration\n*   data transfer from supplier e.g. CoA\n*   e.g. xml import files\n*   High effort of transferring information from supplier to the systems\n*   e.g. scan with text recognition\n*   SAP/QM",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium, Hard",
        "potential_quantification": "High, Medium",
        "dependencies_text": "n.a.",
        "contact_persons_text": "*   Raw Materials Supplier Management: Manuel Gierth, Verena St\u00e4hler\n*   Lab: Patrick Scheu, Carina Mayer, Nora Liebscher",
        "related_projects_text": "*   3PM Supply Chain Insight (Uli Kies)\n*   there was a BIX project for Dortmund",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 40,
        "bi_id": "QA23",
        "name": "Transparent incident monitoring connected to batch data",
        "process_step_id": 33,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   automated review of affected batches in case of microbiological events\n*   If an event (for an equipment or a facility) occurs automated summary of affected batches will be provided",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:55:13.171470+00:00"
      },
      {
        "id": 42,
        "bi_id": "QA27",
        "name": "Global digital transparency of equipment (incl. lab equip.) [Enabler]",
        "process_step_id": 34,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "*   Equipments available on sites are not connected to a global electronic solution that indicates the associated status for further processing",
        "target_solution_description": "*   One global database for manufacturing and analytical equipment\n*   Transferability of equipment life cycle documents to be enabled",
        "technologies_text": "*   Adequate and user-friendly database...",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   global overview of equipment and equipment status over the sites (relevant for transfer planing)\n*   E.g. enabling Lab4U",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): \u20ac500k - \u20ac1mio; Implementation time: <1 year",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   Facility heads\n*   Alex Andretter???\n*   T. hrebicek",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:56:36.816610+00:00"
      },
      {
        "id": 41,
        "bi_id": "QA26",
        "name": "Digital cleaning documentation for rooms",
        "process_step_id": 34,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   Not sufficient transpaency of clean room status",
        "target_solution_description": "*   Establish electronic logbook framework and tracking solution that provides the current status directly at the room.",
        "technologies_text": null,
        "requirements": "*   Access requirements to e-solution to be given for all users (incl. external)",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Digitize documentation of Cleaning & Desinfections of Rooms\n*   minimum: Digital log book\n*   Compare to \"digital log book\" use case in Manufacturing",
        "further_ideas": "n/a",
        "effort_quantification": "Easy; Operating cost (Opex): <\u20ac200k; Invest (Capex): \u20ac500k - \u20ac1mio; Implementation time: 1-3 years",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": "See Manufacturing Workshop. \"Room status\"",
        "contact_persons_text": "tbd - DMSO / GMSPO Facilities?",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:56:34.198468+00:00"
      },
      {
        "id": 48,
        "bi_id": "QC30",
        "name": "Continuous optimization of maintenance schedule",
        "process_step_id": 24,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3",
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "incl. optimization of maintenance schedule based on usage of equipment",
        "technologies_text": null,
        "requirements": "Prerequisite: \"Digital Maintenance for QC Equipment\"",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Continuous optimization of maintenance schedule\n*   Prerequitite: Equipment Connectivity: Use IoT (Internet of Things) to connect various pieces of equipment. This connectivity allows for real-time monitoring and data collection, ensuring that equipment is functioning optimally and any issues are quickly identified\n*   Architectural Connectivity Layer. EQs and Solutions are from a VUKA World -> Flexibility to connect EQ and solutions in a standardized way\n*   predictive maintenance\n*   incl. optimization of maintenance schedule based on usage of equipment\n*   AI supported predictive maintenance based on available data.\n*   AI can also predict equipment failures before they happen, allowing for proactive maintenance\n*   Prerequisite: \"Digital Maintenance for QC Equipment\"",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium, Low",
        "dependencies_text": "Prerequisite: \"Digital Maintenance for QC Equipment\"",
        "contact_persons_text": "Mirko Schlief",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 52,
        "bi_id": "QA16",
        "name": "Assisted creation of eQMS records",
        "process_step_id": 18,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   Current e-QMS records are partially inconsistent and incomplete.",
        "target_solution_description": "*   AI connected to e-QMS too provide in-system proposal for creating adequate content and/or verification of exisitng content of the record steps",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   assissted creation / investigation / summarizing of deviations\n*   Assisted creation of multiple topics (change controls, events, discrepancy records, ...)\n*   minimal requirements during investigation / deviation / CAPA are checked after saving.",
        "further_ideas": "n/a",
        "effort_quantification": "Easy/Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): \u20ac500k - \u20ac1mio; Implementation time: 1-3 years",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": "To be considered for new e-QMS solution (See Use Case 21)",
        "contact_persons_text": "*   GOTrack GBS Representative (Yaeli Valdez) / Abdullah",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:53:53.314589+00:00"
      },
      {
        "id": 51,
        "bi_id": "QA15",
        "name": "Automated observation follow-up",
        "process_step_id": 19,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Supplier Audit observations: integration of external and assignment of CAPA to external party (==> KPI / contract)\n*   External partner is required to fill out the system",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:52:36.978085+00:00"
      },
      {
        "id": 47,
        "bi_id": "QA31",
        "name": "Integrated artwork management tool",
        "process_step_id": 22,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   manual work for correlating issues related to Medicine & OPS ==> AMT process needs to be reduced by offering a joint digital solution\n*   AWM+EL: E2E SCM Lifecycle System with seamless handover of Labeling Data (incl. label changes)",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:57:37.874508+00:00"
      },
      {
        "id": 53,
        "bi_id": "QA17",
        "name": "Fit for purpose non-conformance and event management tool",
        "process_step_id": 18,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   fit for purpose GOTrack for CMO Managment (mandatory fields / process steps etc)\n*   AI used to generate Executive summary for Investigation reports of CMOs",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:53:54.964164+00:00"
      },
      {
        "id": 59,
        "bi_id": "M22",
        "name": "Real-time translation",
        "process_step_id": 39,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Copilot premium f\u00fcr alle MA ausgerollt",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   real-time, overarching translation for all manufacturing information\n*   Sprache (Language)\n*   z.B. Integration von z.B. Deepl in interne systeme (e.g., Integration of e.g., Deepl into internal systems)\n*   GMP relevante \u00dcbersetzung?!? (GMP relevant translation?!?)\n*   sollte direkt voreingestellt werden gem\u00e4\u00df des MA, der sich anmeldet (should be directly preset according to the employee logging in)",
        "further_ideas": "*   integration in GxP applications (PAS-X, united)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Da gibt es kein laufendes Projekt, kann man aber ggf. mit Copilot realisieren (Transcription)?. (Oliver Gluth) (There is no ongoing project, but it could possibly be realized with Copilot (Transcription)?)",
        "contact_persons_text": "*   Chemie/Quality: Markus Wheeldon\n*   Oliver Gluth (for Copilot info)\n*   GBS: n/a or only for BI-MES / united",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 60,
        "bi_id": "QC24",
        "name": "Automated linkage of analytical data to trending scenarios",
        "process_step_id": 45,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Wave 2",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Automated linkage of analytical data to trending scenarios\n*   Automated linkage of analytical data to trending scenarios\n*   Manual steps in GDTS (e.g. mapping)\n*   prerequitite use case for \"predictive analytics\"",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium, Hard",
        "potential_quantification": "Medium",
        "dependencies_text": "prerequitite use case for \"predictive analytics\"",
        "contact_persons_text": "*   Bettina Neufurth\n*   Carolin Becker, Andreas Oefner\n*   Harshvardhan,Harshvardhan",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 58,
        "bi_id": "QA22",
        "name": "Digital tool for CCS & CSS life cycle management",
        "process_step_id": 33,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   The main problem to be solved is the inefficiency and risk associated with manual and paper-based processes. By digitizing the life cycle management of CSS and CCS, the system can streamline processes, improve efficiency, and ensure better risk management.\n*   Furthermore, in case of also externally manufactured multi-site products, the integration of the CMO related CSS-part currently is managed via a complex and manual process",
        "target_solution_description": "*   Full Digital Life Cycle Management: Complete digitization of the life cycle management of CSS and CCS, including risk management.\n*   Connection/Interface Process: Interface process for CSS generation for multi-site products, including external manufacturing sites (CMOs)....\n*   Assisted Risk Assessment: AI-assisted risk assessment based on development data and consequently creation of control strategy.",
        "technologies_text": "*   AI Algorithms: For assisted risk assessment and automated document creation....\n*   Interface Processes: Connection/interface processes for multi-site products, including external manufacturing sites....",
        "requirements": "*   Harmonize processes over sites / Divisions\n*   reduce inefficienies\n*   Full Digital Life Cycle Management: Complete digitization of the life cycle management of CSS and CCS, including risk management.",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Full ditgital Life cycle mgt of CSS and CCS and its Risk Mgt.\n*   provision of system support for CSS/CCS\n*   fully integrated control strategy summary allows for direct assessment in case of deviation\n*   control strategy summary is a mere generic document, creation can be automated out of data pools\n*   connection / interface process for CSS generation for multi-site products incl. external ManSites (CMOs)\n*   Control Strategy completely on paper\n*   assissted risk assessment based on development data and consequently creation of control strategy",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): \u20ac500k - \u20ac1mio; Implementation time: 1-3 years",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   Jelena Laube (Contamination Control Strategy)\n*   Holger von der Heydt (Control Strategy)\n*   Anke Timm (3PQM) SME",
        "related_projects_text": "*   P360: 67589 Annex 1 for CCS Monitoring Tool\n*   P360: 63413 GDTS for Future as consumer of data",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:55:09.673045+00:00"
      },
      {
        "id": 114,
        "bi_id": "SCM33",
        "name": "TOOR",
        "process_step_id": 29,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": "high",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "E2E TOOR (TOCS) process in place across functions & sites: enable decision on batch release at decoupling points and for final release to market.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "...",
        "contact_persons_text": "E. Neumann. C. Dechow.",
        "related_projects_text": "TOCS C. Dechow.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:11:06.838896+00:00"
      },
      {
        "id": 63,
        "bi_id": "M17",
        "name": "Self service data platform",
        "process_step_id": 27,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\r\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "low (weeks)",
        "reduction_costs_supply": "Medium/Low",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Data Self Service Plattforms verbunden mit Dataland damit die Einheiten selbst einfache bis mittelkomplexe Auswertungen machen k\u00f6nnen (Data Self Service Platforms connected to Dataland so that the units themselves can perform simple to medium-complex evaluations)\r\n*   Includes training, change, ...\r\n*   \"GDTS for future\" for Pharma\r\n*   We have transparency on all relevant data for process, equipment, and product data and know the owner, creator, maintainer\r\n*   mit Access f\u00fcr das Business! (with Access for the business!)",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   IT EDP for DL\r\n*   Data Strategy & Science Team Representative A.Oefner ?\r\n*   Dependency/Relation to: Dataland (mentioned in ideation)\r\n*   Dependency/Relation to: \"GDTS for future\" (mentioned in ideation)",
        "contact_persons_text": "*   IT EDP for DL (Dept/Group?)\r\n*   Data Strategy & Science Team Representative A.Oefner ?\r\n*   GBS: n/a or only for global system onboarding\r\n*   Ansprechpartner Dortmund: Marco Vennewald (Head of Local Business Intelligence) - Kontakt \u00fcber Markus Kirchner\r\n*   Chemie/Engineering: Matthias Siefert",
        "related_projects_text": "*   \"GDTS for future\" for Pharma (Contact from UC18: Karin Morch, Michaela Koppers)\r\n*   Dataland (Contact from UC06: Andreas Oefner)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 64,
        "bi_id": "M13",
        "name": "Live status of change over progress",
        "process_step_id": 37,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\r\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "low (weeks)",
        "reduction_costs_supply": "low/medium",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Live status of change over progress\r\n*   Statusanzeige/-\u00fcbersicht \u00fcber den Fortschritt und evtl. St\u00f6rungen f\u00fcr die Mitarbeiter, aber auch f\u00fcr Coach/TL/BL (Status display/overview of progress and potential disruptions for employees, but also for Coach/TL/BL)\r\n*   Digital info board to announce changeover and status",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to: change over as part of Manufacturing Process in MES (ESP, eLogbooks)",
        "contact_persons_text": "*   Chemie/Produktion: Cord Tomforde/J\u00f6rg Braun\r\n*   GBS: Kerstin Trenz (ME)\r\n*   IT O&L MANUFACTURING (Sven)",
        "related_projects_text": "*   change over as part of Manufacturing Process in MES (ESP, eLogbooks, K. Trenz)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 65,
        "bi_id": "M10",
        "name": "Continuous changeover optimization tool",
        "process_step_id": 37,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\r\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "low/medium (weeks)",
        "reduction_costs_supply": "low/medium",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Auswertung von historischen Daten zu Change over um \u00fcber Simulation/Optimierung den Prozess stetig zu verbessern. (Evaluation of historical changeover data to continuously improve the process via simulation/optimization.)\r\n*   Operator Guidance and Process recording including settings/configurations (AI supported) comprising Setup, Maintenance & Calibration\r\n*   \"Digital Twin\" der Anlage erstellen um Optimierungen im Change over Prozess simulieren zu k\u00f6nnen. (Create \"Digital Twin\" of the plant to simulate optimizations in the changeover process.)\r\n*   Digital Twin: Virtuelle Modelle von Produktionsanlagen helfen, den Umr\u00fcstprozess zu simulieren und zu optimieren, bevor er tats\u00e4chlich durchgef\u00fchrt wird (Digital Twin: Virtual models of production facilities help to simulate and optimize the changeover process before it is actually carried out)\r\n*   Etablierung einer Standard-Software, mit denen bereichs\u00fcbergreifend optimale R\u00fcstabl\u00e4ufe visualisiert, geplant und via AI-Audio-Support trainiert werden k\u00f6nnen. (\"Change Over Process Mirror\") Routinem\u00e4\u00dfiger Abgleich mit der Realit\u00e4t und Verbesserung. Monitoring der Soll vs. Ist-Zeiten. (Establishment of standard software with which optimal setup sequences can be visualized, planned across areas and trained via AI audio support. (\"Change Over Process Mirror\") Routine comparison with reality and improvement. Monitoring of target vs. actual times.)\r\n*   Virtual twin to simulate and optimize changeovers (e.g. reduce number of parts to be changed)\r\n*   optimized product sequence to reduce change over activites reflecting individual working steps\r\n*   Digital Twin zur Simulation und Optimierung von R\u00fcstvorg\u00e4ngen (Digital Twin for simulation and optimization of setup processes)",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to: IT GFS SCM\r\n*   Dependency/Relation to: IT O&L Manufacturing/ GFE\r\n*   Dependency/Relation to: MWB\r\n*   Dependency/Relation to: MES ESP\r\n*   Dependency/Relation to: Basic Workshop-Methodology for SMED (changeover-optimisation)",
        "contact_persons_text": "*   GBS: Kerstin Trenz (ME)\r\n*   IT GFS SCM: Bernd Ohse\r\n*   IT O&L Manufacturing/ GFE: Axel K. & Sven\r\n*   Chemie/Produktion: Cord Tomforde/J\u00f6rg Braun\r\n*   MWB contacts: Timm Lahman, Irfan Murcic\r\n*   MES ESP contact: Kerstin Trenz\r\n*   SMED Workshop contact: BPE Solids, Dr. Karin Winter",
        "related_projects_text": "*   MWB (Timm Lahman, Irfan Murcic)\r\n*   MES ESP (Kerstin Trenz)\r\n*   Basic Workshop-Methodology for SMED (changeover-optimisation) -Workshops as basic principle for future software solution --> BPE Solids, Dr.Karin Winter",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 66,
        "bi_id": "QC31",
        "name": "Digital Maintenance for QC Equipment",
        "process_step_id": 24,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Description: Use predictive models to forecast maintenance needs for QC equipment.\n*   Key Features: AI-driven predictive maintenance algorithms. Integration of equipment data into predictive models. Proactive maintenance scheduling.",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Digital Maintenance for QC Equipment\n*   Digital equipment logbook interfaced with other systems like LIMS, trackwise, ...\n*   Digitalize the paper checklist used for maintenance of lab equipment\n*   All system related tasks and status visible in and checked by elektronic systems --> no stickers except ID on equipment\n*   paperless documentation and logbook entries for maintainance activities. systems are connected\n*   Description: Use predictive models to forecast maintenance needs for QC equipment.\n*   Key Features: AI-driven predictive maintenance algorithms. Integration of equipment data into predictive models. Proactive maintenance scheduling.\n*   mobile maintenance",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "n.a.",
        "contact_persons_text": "n.a.",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 67,
        "bi_id": "M04",
        "name": "Digitally supported MBR & Master recipe creation",
        "process_step_id": 25,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\r\nBUSINESS PROBLEM SOLVED:\r\n*   Harmonized MBR Libary available for Process Archetypes (Tablets, Capsules, Chem, Bio)\r\n*   Transfers and Launches supported by Libary and AI generated MBRs\r\n*   Guidlines & Best Practice established\r\n*   Multi-language support available (no translation outside the system)",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   Harmonized MBR Libary available for Process Archetypes (Tablets, Capsules, Chem, Bio)\r\n*   Transfers and Launches supported by Libary and AI generated MBRs\r\n*   Guidlines & Best Practice established\r\n*   Multi-language support available (no translation outside the system)",
        "target_solution_description": "*   Standardization of MBRs & automatically creation of them to accelerate transfer times. Harmonization of existing transfer activities into the commercial Ops and between the sites to reduce variation. Implement automation tools and software systems to automatically generate MBRs based on predefined templates, reducing manual effort and potential errors.\r\n*   2 Subprojekte: - digitales Tool (AI-based) - Organizational Structure (global support)",
        "technologies_text": "*   Werum Pas X\r\n*   evt. Emerson Syncade\r\n*   Idea (placeholder?)",
        "requirements": "*   Electronic Batch record implemented\r\n*   Review-necessities\r\n*   Chemie/Betrieb: Stephan Weyand\r\n*   IT/ GBS.PPM & Business resources",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "medium-high (month)",
        "reduction_time_launches": "medium-high (month)",
        "reduction_costs_supply": "medium (2-3 FTE)",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Establish clear guidelines and specifications for MBR creation, ensuring consistent format and content across all products and processes.\r\n*   seamless integration of planning master data with master recipes\r\n*   Automatically generated MBRs on basis of defined process description\r\n*   Standardization of MBRs & automatically creation of them to accelerate transfer times. Harmonization of existing transfer activities into the commercial Ops and between the sites to reduce variation. Implement automation tools and software systems to automatically generate MBRs based on predefined templates, reducing manual effort and potential errors. (Repeated from target/solution)\r\n*   \"MBR validator\"\r\n*   automatisierte Erstellung eines MBR, Rezept und QC Daten (automated creation of an MBR, recipe and QC data)\r\n*   MBR Library\r\n*   Laufende Projekte/Tools: Innerspace, Amber (Ongoing projects/tools: Innerspace, Amber)\r\n*   ggf. 2 Use Cases (possibly 2 Use Cases)",
        "further_ideas": "*   Quicker MBR Creation\r\n*   central MBR designer Factory evaluation AI connected\r\n*   Quicker MBR Creation (repeated)\r\n*   Decreased review effort\r\n*   Increased MBR design maturity",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): 300.000 \u20ac\r\n*   Implementation time: Value not specified",
        "potential_quantification": "*   REDUCTION OF TIME FOR PRODUCT TRANSFER: (Quantified as medium-high (month))\r\n*   REDUCTION OF TIME FOR PRODUCT LAUNCH: (Quantified as medium-high (month))\r\n*   REDUCTION OF TOTAL COSTS OF SUPPLY: (Quantified as medium (2-3 FTE))\r\n*   QUALITY (RFT): (Quantified as Medium)",
        "dependencies_text": "*   Please cross-check use case 5 \"MBR-configurator\"\r\n*   Please verify existing tool \"MBR-Validator\"\r\n*   Cross-site MBR Standardisation via BI-MES Program (Kerstin Trenz)\r\n*   BI-MES Program: Template and master data (Kerstin Trenz)\r\n*   GBS united (Felipe Gonzaga/Kerstin Trenz)\r\n*   BI-MES Key-User Community Support for Pharma Supply",
        "contact_persons_text": "*   LEAD: Kersin Trenz & Benno Knopf\r\n*   IT O&L MFG (Sven)\r\n*   Philipp Louis(Head of Projects, Processes, Innovation) Kontakt: Benno Knopf\r\n*   Alexander Krauland (AMBER contact)\r\n*   Kerstin Trenz (BI-MES contact)\r\n*   Felipe Gonzaga (GBS united contact)\r\n*   GBS: Kerstin Trenz (BI-MES)\r\n*   BI MES Vertreter (BI MES Representatives)\r\n*   MES DTM (Markus Kirchner)\r\n*   Stephan Weyand (Chemie/Betrieb Requirement contact)",
        "related_projects_text": "*   AMBER (Alexander Krauland)\r\n*   BI-MES Program (Kerstin Trenz)\r\n*   GBS united (Felipe Gonzaga/Kerstin Trenz)\r\n*   Possibly Innerspace (mentioned in ideation)\r\n*   Possibly MBR-Validator (mentioned in dependencies)\r\n*   Possibly MBR-configurator (mentioned in dependencies)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 68,
        "bi_id": "M05",
        "name": "Seamless drug product knowledge",
        "process_step_id": 25,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\r\nBUSINESS PROBLEM SOLVED:\r\n*   reduce manual effort in launches and transfers\r\n*   right first time\r\n*   improve robustness of new products and transfers\r\n*   Feedback loop from production to IU/Dev for 2nd gen. etc.\r\n*   faster launches and transfers",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   reduce manual effort in launches and transfers\r\n*   right first time\r\n*   improve robustness of new products and transfers\r\n*   Feedback loop from production to IU/Dev for 2nd gen. etc.\r\n*   faster launches and transfers",
        "target_solution_description": "*   one data source used by IU Dev and Operations\r\n*   App for DoE\r\n*   Use data from IU and Operations to simulate DoE\r\n*   App for FMEA\r\n*   Aligned standards for control strategy and product & process robustness monitoring\r\n*   Tool and data harmonization\r\n*   Interfaces to IU Dev and Ops Systems (see screenshot Data Hub)",
        "technologies_text": "*   Dataland use case\r\n*   Interfaces to IU Dev and Ops Systems (see screenshot Data Hub)",
        "requirements": "*   harmonised datasets\r\n*   data governance\r\n*   Dataland datalake\r\n*   app development\r\n*   data scientist\r\n*   definde common standards with IU/Dev and Ops\r\n*   Interfaces to IU Dev and Ops Systems (see screenshot Data Hub)",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "medium (weeks)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   NCE-Daten aus Biberach verwenden, um DoE in Ingelheim zu planen f\u00fcr die ersten Transferchargen. Ergebnisdaten zur\u00fcckspielen an IU Dev (Use NCE data from Biberach to plan DoE in Ingelheim for the first transfer batches. Feed back result data to IU Dev)\r\n*   \"Digital Drug Product Knowledge & Performance Solution OneHP\": One digital platform to assess process risks, define control strategy and monitor product & process robustnes development from Development over Launch to Lifecycle.\r\n*   FMEA --> CSS --> PPQ --> CPV (Equipment-data + IPC-data & QC-data)\r\n*   batch/process comparison between all factorys/sites\r\n*   automatisierte Risikobewertung/FEMA auf Basis fundiertem Know-how (aseptische Prozesse) bereits beim Prozessdesign Vorteil: automatisierte Textbausteine f\u00fcr SOP, MBR und Trainingsmaterialen (Traceability) System: Frame-by-Frame risk analysis (Innerspace) (automated risk assessment/FMEA based on well-founded know-how (aseptic processes) already during process design Advantage: automated text modules for SOP, MBR and training materials (Traceability) System: Frame-by-Frame risk analysis (Innerspace))\r\n*   Laufendes Projekt, Launch Data Hub (Ongoing project, Launch Data Hub)\r\n*   Automated linkage between real-time data and comparison to CSS & FMEA.",
        "further_ideas": "*   Direct data feedback loop from process data to FMEA & CSS\r\n*   time to market (also listed as Qualitative Benefit in image)\r\n*   accelerate launch (also listed as Qualitative Benefit in image)\r\n*   effort reduction in IU Dev and Ops (also listed as Qualitative Benefit in image)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): 1mio\u20ac per anno\r\n*   Implementation time: 3 years",
        "potential_quantification": "*   reduction of transfer time due to better data and experience and simulation\r\n*   reduce cycle times for new product in facility to a minumim (right first time) (higher benefit in Pharma compared to Bio)\r\n*   no savings in Supply Chain or logistics, however faster time to market\r\n*   reduce cycle times by 50%",
        "dependencies_text": "*   Dataland is already existing, maybe licenses for a new tool which is not yet implemented (w.g. Uhlmann Tool)\r\n*   Dependency/Relation to: Launch Data Hub and Dataland\r\n*   Dependency/Relation to: Bio DMSO CSS\r\n*   Dependency/Relation to: \"CSS Digitalizsation\" Project\r\n*   Dependency/Relation to: GDTS4Future Project\r\n*   Dependency/Relation to: Manufacturing and Plant Gap Assessment for Platform Processes in der Bio\r\n*   Dependency/Relation to: Frame-by-Frame risk analysis (Innerspace) (mentioned in ideation)",
        "contact_persons_text": "*   LEAD: Andreas \u00d6fner (Info \u00fcber Sven W.)\r\n*   Chemie/PEC: Oliver Br\u00fccher\r\n*   GBS: Kerstin Trenz (ME)\r\n*   LIL-representative: Nicole K\u00f6hler?\r\n*   Jochen Gerlach (Head of Launch&Lifecycle Center Inject.) - Info \u00fcber Viola\r\n*   Andreas \u00d6fner/Data Strategy & Science (Launch Data Hub contact)\r\n*   Sven Weber/PNIH\r\n*   CPT SOl-representative: Ask Shoaib Rana for nomination (e.g. Nancy Manthey)\r\n*   Markus Braum\u00fcller (QS BioPharma, CSS Digitalization contact)\r\n*   Karin Morch (GDTS4Future Project, GBS)\r\n*   Erik Arrango (IU, Manufacturing/Plant Gap Assessment contact)\r\n*   Nicole K\u00f6hler (Innerspace contact, from previous use case)",
        "related_projects_text": "*   Launch Data Hub and Dataland (Andreas Oefner)\r\n*   Bio DMSO CSS\r\n*   \"CSS Digitalizsation\" Project (Markus Braum\u00fcller)\r\n*   GDTS4Future Project (Karin Morch, GBS)\r\n*   Manufacturing and Plant Gap Assessment for Platform Processes in der Bio (Erik Arrango - IU)\r\n*   Frame-by-Frame risk analysis (Innerspace) (mentioned in ideation)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 69,
        "bi_id": "M06",
        "name": "Data collection and transfer to/from equipment & IPC-devices",
        "process_step_id": 25,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\r\nBUSINESS PROBLEM SOLVED:\r\n*   Manual data transfer is reduced\r\n*   Double-check is not needed anymore\r\n*   No system breaks --> step for data availability",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   Manual data transfer is reduced\r\n*   Double-check is not needed anymore\r\n*   No system breaks --> step for data availability",
        "target_solution_description": "*   Fully vertical implemntation of all Equipments and IPC devices --> quality review\r\n*   Harmonized process definition (draw, sampling, analyzing, etc.)\r\n*   IPC fully connected to production step --> horizontal connection between LIMS and MES\r\n*   All relevant data is provided for further use cases",
        "technologies_text": "*   MES, ERP, LIMS, DCS",
        "requirements": "*   Clear data strategy: What is needed --> basis for integration plan of devices and equipment\r\n*   Integration of equipments according to strategy\r\n*   Easy and traceable integration\r\n*   State of the art equipment",
        "relevants_text": "Bio, Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   automated breakdown of order to shop floor\r\n*   bidirectional connected factory\r\n*   Define for Pharma IPC-Equipment-a Data Collection & Provision Strategy. Enable a global IT-system to collect systematically IPC-data and provide flexible interface to multiple IPC-equipment-suppliers.\r\n*   IPC connected\r\n*   Equipments and their connection for the data exchange\r\n*   Interface definition should harmonized - source & target (data structure)\r\n*   (Management process/system owner of recipes)\r\n*   fully vertical implemntation of all Equipments\r\n*   Harmonization of the processes - Definition of draw & sample, analyze procedure, etc.",
        "further_ideas": "*   Enabler for 04\r\n*   Enabler for 07",
        "effort_quantification": "*   High when all IPC devices/production equipments have to be upgraded to tech standard\r\n*   Software updates for integration is slow\r\n*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: High when looking on lifecycle of devices/equipments",
        "potential_quantification": null,
        "dependencies_text": "*   Local solution ING: Babtec. No global solution available.\r\n*   Dependency/Relation to: SDC: IPC intergration with MES\r\n*   Dependency/Relation to: Inmation\r\n*   Dependency/Relation to: Henosis\r\n*   Dependency/Relation to: Vertical Integration (ISAA L3-L2) per Product Type: direct, Flexlink, Inmation",
        "contact_persons_text": "*   LEAD: Erik Straub/ Sven L.\r\n*   Bastian Knabe (Head of Engineering Assembly DTM) - Kontakt \u00fcber Markus Kirchner\r\n*   GBS: Kerstin Trenz (ME)\r\n*   GFE Andreas Kleiner (SDC IPC integration contact)\r\n*   Portella Montse (IT Operations & Laboratories Automation Integration/ Manufacturing)\r\n*   Sonny Slobota (Inmation contact)\r\n*   DAvid Ludwig (Henosis contact)\r\n*   Bj\u00f6rn Schubert (Vertical Integration contact)\r\n*   Kerstin Trenz (Vertical Integration contact)\r\n*   Chemie/Engineering: Matthias Siefert\r\n*   SOL: Felix Antemann",
        "related_projects_text": "*   Babtec (Local solution ING)\r\n*   SDC: IPC intergration with MES (Andreas Kleiner, K. Trenz)\r\n*   Inmation (Sonny Slobota)\r\n*   Henosis (DAvid Ludwig)\r\n*   Vertical Integration (ISAA L3-L2) per Product Type: direct, Flexlink, Inmation (Bj\u00f6rn Schubert, K. Trenz)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 70,
        "bi_id": "M12",
        "name": "Automated loading of recipes and settings",
        "process_step_id": 37,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\r\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Focus on automated setting of equipment",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "low/medium",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Autom. Laden von Rezepten und Maschineneinstellungen (Autom. loading of recipes and machine settings)\r\n*   Set points for equipment settings\r\n*   Cleaning per eMCR (ESP)\r\n*   Maschinen passen sich dann automatisch an (Machines then adapt automatically)\r\n*   Ulmann hat da eine L\u00f6sung (Verpackung) (Uhlmann has a solution there (Packaging))",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   GFE Automation\r\n*   GBS: Kerstin Trenz (MES integration)\r\n*   IT O&L Integration\r\n*   Montse & Sven for MES\r\n*   Dependency to use case 02\r\n*   Dependency/Relation to: MES-Automatization integration (combined VII + BI-MES)\r\n*   Dependency/Relation to: inmation, Flexlink, SDC",
        "contact_persons_text": "*   GFE Automation (Department/Group, no specific name)\r\n*   GBS: Kerstin Trenz (MES integration)\r\n*   IT O&L Integration: Montse\r\n*   IT O&L Integration: Sven (for MES)\r\n*   MES-Automatization integration contacts: Bj\u00f6rn Schubert, K.Trenz",
        "related_projects_text": "*   MES-Automatization integration (combined VII + BI-MES, Bj\u00f6rn Schubert, K.Trenz)\r\n*   inmation (related technology/project, contact from previous UCs: Sonny Slobota)\r\n*   Flexlink (related technology/project, contact from previous UCs: Bj\u00f6rn Schubert, K. Trenz)\r\n*   SDC (related project, contact from previous UCs: Andreas Kleiner, K. Trenz)\r\n*   Uhlmann solution (mentioned in ideation)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 71,
        "bi_id": "M14",
        "name": "Transparency on location and status of equipment & parts",
        "process_step_id": 26,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2\r\nBUSINESS PROBLEM SOLVED:\r\n*   Eliminated searching effort for movable equipments.\r\n*   Ad-hoc usability status (clean/not clean,calibrated) available",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   Eliminated searching effort for movable equipments.\r\n*   Ad-hoc usability status (clean/not clean,calibrated) available",
        "target_solution_description": "*   Geo-localisation of movable equipment in the same or another building.\r\n*   + Online-Equipment-Dashboard",
        "technologies_text": "*   Asset Tracker wireless triangulation via WiFi\r\n*   GPS (if extra-factory relevant, like container)\r\n*   Tablet",
        "requirements": "*   Electronic status of equipment available\r\n*   WiFi-Access Points installed",
        "relevants_text": "Bio, Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "low (days)",
        "reduction_time_launches": "low (weeks)",
        "reduction_costs_supply": "low/medium (site specific)",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   loc. tracking\r\n*   Lokalisierung von Equipment \u00fcber Tracker/etc. im Geb\u00e4ude (Localization of equipment via tracker/etc. in the building)\r\n*   automated tracebility for form parts\r\n*   Autom. Erkennnug von korrektem Equipment via NFC, um Doppelkontrollen abzuschaffen (Autom. recognition of correct equipment via NFC to abolish double checks)\r\n*   eindeutige Zuordnung der ben\u00f6tigten Formatteile, automatisierte Dokumentation, welche Formatteile eingebaut worden sind (clear assignment of required format parts, automated documentation of which format parts have been installed)\r\n*   RFID-unterst\u00fctztes Formatteil-Management etablieren. (Was ist wo in welchem Status, gereinigt, ungereinigt. Ist das korrekte Teil eingebaut? (Establish RFID-supported format part management. (What is where in which status, cleaned, uncleaned. Is the correct part installed?)))\r\n*   automated recognition of mounted parts incl. alignment with recipe/MBR\r\n*   tracability & automatic cross-check of changed parts/tools\r\n*   automated (NFC / RFID) identification and check of parts\r\n*   Statusanzeige und Warnmeldungen f\u00fcr gereinigtes und sterilisiertes Equipment (Status display and warning messages for cleaned and sterilized equipment)\r\n*   Live Equipment Status (log book) in various ways available",
        "further_ideas": "*   Incl. 09 (Seems to indicate inclusion or relation to Use Case 09, possibly related to format parts mentioned in ideation)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: 2 years tbd per site",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to: IT O&L GFE (Axel Keul) for PM &Calibr.\r\n*   Dependency/Relation to: Sven for MES Equip. hygiene Status\r\n*   Dependency/Relation to: Pharma: Solids-Factory, IBC-Bulk-Container Localisation Project with RFC-Tags (very old, stopped)\r\n*   Dependency/Relation to: BIgLOC Equipment \"Lokalisierungstool\"\r\n*   Dependency/Relation to: smartPanel (SOL Pilot)\r\n*   Dependency/Relation to: BIgCal\r\n*   Dependency/Relation to: Indicamp idea",
        "contact_persons_text": "*   IT O&L GFE: Axel Keul (for PM & Calibr.)\r\n*   Sven (for MES Equip. hygiene Status)\r\n*   Pharma Solids-Factory Localisation Project: Engineering Solids: Rainer Dietz\r\n*   BIgLOC contact: Paul Hart\r\n*   smartPanel contacts (SOL Pilot): Christoph Dechow, Martin D\u00f6hms\r\n*   Paul Hart (IT Infrastructure); Kontakt: Benno Knopf\r\n*   BIgCal contact: Enric Pallares\r\n*   GBS: Kerstin Trenz (ME)\r\n*   Chemie/ServiceCenter: Thomas Peters\r\n*   Indicamp idea contact: Oliver Gluth\r\n*   Chemie/Engineering: Matthias Siefert",
        "related_projects_text": "*   Pharma: Solids-Factory, IBC-Bulk-Container Localisation Project with RFC-Tags (very old, stopped) Contact: Engineering Solids: Rainer Dietz\r\n*   BIgLOC Equipment \"Lokalisierungstool\" derzeit in Evaluierung/Testung in Wien (currently under evaluation/testing in Vienna) Ansprechpartner Paul Hart\r\n*   smartPanel (SOL Pilot: Christoph Dechow, Martin D\u00f6hms)\r\n*   BIgCal: Enric Pallares\r\n*   Indicamp idea (Oliver Gluth)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 73,
        "bi_id": "QA24",
        "name": "Automated generation of SLC & product life cycle document drafts",
        "process_step_id": 20,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   The main problem to be solved is the inefficiency and inconsistency of manual document creation processes. By automating the generation of document drafts, the system can streamline processes, improve efficiency, ensure better accuracy, and enhance traceability.\n*   1st wave: CSV LC document drafts.\n*   2nd wave: extension of developed solution to product related LC documents...\n*   Data Integrity Risk Assessments",
        "target_solution_description": "*   The goal is to create a system that automates the generation of SLC document drafts and product life cycle document drafts, ensuring consistency, accuracy, and improved traceability....",
        "technologies_text": "*   AI Algorithms: For automated document creation, template integration, and risk-based approach logic....\n*   Data Integration: Seamless integration of data pools for populating document drafts.\n*   Template Management: Customizable templates for various document types.\n*   Traceability Tools: Tools and features that enhance traceability and allow for easy tracking and auditing.",
        "requirements": "*   AI-supported Creation of SLC Documentation: AI should support the creation of SLC documentation, ensuring accuracy and consistency.\n*   Automatic Creation of Qualification & Validation Documentation: AI should automate the creation of qualification and validation documentation.\n*   Risk-Based Approach: Derive a logic from historic data to support a risk-based approach to validation.\n*   Automated Authoring and Execution of Functional Testing: AI should automate the authoring and execution of functional testing, considering a risk-based approach.\n*   Reuse of Qualification & Validation Documentation: Enable the reuse of qualification and validation documentation based on user requirements.\n*   Protocol Proposals: Automatically generate protocol proposals, including statistical approaches in transfers/process validation (matrixing/bracketing), sampling plans, etc., after providing some key information and considering benchmark/authority trends.\n*   Transfer Plan/Validation Plan Proposal: Based on development data, create a transfer plan/validation plan proposal.\n*   AI-assisted Creation of Reports: AI should assist in the creation of reports (transfer, validation).\n*   Improved Traceability: Ensure that all document drafts and processes are traceable, allowing for easy tracking and auditing.",
        "relevants_text": "Bio, Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   AI supported creation of SLC documentation\n*   Automatic creation of Qualif&Vali documentation\n*   Derive a logic from historic data to support Risk Based approach valid.\n*   Automated authoring and execution of functional testing considering a risk based approach\n*   Reuse of Qualif&Valid documentation\n*   Based on user requirements\n*   Protocol proposals incl. statistical approaches in transfers / PV (matrixing / bracketing), sampling plans etc are automatically generated after providing some key information taking into consideration benchmark / authority trends\n*   based on development data creation of a transfer plan / validation plan proposal\n*   AI assissted creation of reports (transfer, validation)",
        "further_ideas": "n/a",
        "effort_quantification": "Easy/Medium; Operating cost (Opex): > \u20ac500k; Invest (Capex): <\u20ac500k; Implementation time: 1-3 years",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket; Connected to similar use Case in Manufacturing and QC",
        "dependencies_text": null,
        "contact_persons_text": "*   Abdullah Kural (GBS)\n*   Ivan de Anda (GMSO CSV)\n*   Gemma Ferrer-Ponce (Data Integrity)\n*   Karin Herzog (Medical Devices)",
        "related_projects_text": "*   66470 - Polarion - DLM Device Lifecycle Management (Project Manager: alexander.haas@boehringer-ingelheim.com, Business PM: heinz.scherz@boehringer-ingelheim.com)\n*   64536 - DiVal - Interface enablement\n*   62116 - DiVal - Implementation Wave1\n*   67014 - DiVal Further Rollout - Wave 1\n*   66957 - Data Integrity Governance Life Cycle",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:55:38.237469+00:00"
      },
      {
        "id": 74,
        "bi_id": "QA25",
        "name": "Documents digitally integrated over the Lifecycle",
        "process_step_id": 20,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Simple traceability between SLC documents throughout Lifecycle\n*   Automatic tracebility for CSV documentation\n*   Currently already projects ongoing",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:55:41.690599+00:00"
      },
      {
        "id": 76,
        "bi_id": "PM-UC-11",
        "name": "One Performance Monitoring Tool / Dashboard concept across BI",
        "process_step_id": 40,
        "priority": null,
        "raw_content": null,
        "summary": "ONE Performance Monitoring Tool/System instead of silo solutions. Only one harmonized KPI Monitoring system applied in OneOps. One standard system for Performance Dialogue on each level with automated data available. Connected dashboards with the required information for each target group (e.g. senior management, site managers,...). One user-friendly and standardized dashboard with customized views (e.g. for OneOps Leadership, Network, Factory etc.). Frequencies and scope of each hierarchy is aligned (cascade & interlinked). ONE system as base for all dashboards & reports (instead of silo solutions) creating overall transparency",
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Missing linkage between different dashboard levels - management view vs. detail view. Individual not connected Dashboards for the different levels. Inconsistent reporting, limited visibility, misaligned metrics, and communication gaps. No comprehensive view of performance across the organization due to fragmented systems. Varied methods or tools for reporting, resulting in inconsistent formats and interpretations. Organization uses multiple performance management dashboards/tool using different software that does not allow structured automated integration of data and lacks transparency/connection. There is not ONE Business Case / Savings tracker across OneOps",
        "target_solution_description": "ONE Performance Monitoring Tool/System instead of silo solutions. Only one harmonized KPI Monitoring system applied in OneOps. One standard system for Performance Dialogue on each level with automated data available. Connected dashboards with the required information for each target group (e.g. senior management, site managers,...). One user-friendly and standardized dashboard with customized views (e.g. for OneOps Leadership, Network, Factory etc.). Frequencies and scope of each hierarchy is aligned (cascade & interlinked). ONE system as base for all dashboards & reports (instead of silo solutions) creating overall transparency",
        "technologies_text": "Open-minded visualization solution \"dashboard\". Standardized dashboards and data model across the organization. Data driven KPI monitor that predicts which target will likely be reached or missed by the end of a certain reporting period. DATALAND as Data integration Platform for a harmonized data foundation. Service Now?",
        "requirements": "Ensure standardized deployment in all functions of OneOps (or even beyond). Data from all relevant sources is seamlessly connected through standardized systems and available in real time enabling smooth flexible analysis and decision-making across all levels. ONE system as base for all dashboards & reports. Automated data generation & connection between levels",
        "relevants_text": "All OneOps functions and levels. Senior management, site managers, OneOps Leadership, Network, Factory etc.",
        "reduction_time_transfer": "Not quantified (Alignment of targets and issue solving will support all target achievements, i.e. ensures faster transfers)",
        "reduction_time_launches": "Not quantified (Alignment of targets and issue solving will support faster launches)",
        "reduction_costs_supply": "Not quantified (Alignment of targets and issue solving will support seamless supply)",
        "quality_improvement_quant": "High",
        "ideation_notes": "Missing linkage between different dashboard levels - management view vs. detail view. Only one harmonized KPI Monitoring system applied in OneOps. ONE Performance Monitoring Tool/System instead of silo solutions. One standard system for Performance Dialogue on each level with automated data available. Frequencies and scope of each hierarchy is aligned (cascade & interlinked). ONE system as base for all dashboards & reports (instead of silo solutions) creating overall transparency. There is not ONE Business Case / Savings tracker across OneOps. Organization uses multiple performance management dashboards/tool using different software that does not allow structured automated integration of data and lacks transparency/connection. Individual not connected Dashboards for the different levels. Inconsistent reporting, limited visibility, misaligned metrics, and communication gaps. No comprehensive view of performance across the organization due to fragmented systems. Varied methods or tools for reporting, resulting in inconsistent formats and interpretations. Open-minded visualization solution \"dashboard\". Only one harmonized KPI Monitoring system applied in OneOps that ensures automated data generation & connection between levels. Connected dashboards with the required information for each target group (e.g. senior management, site managers,...). One user-friendly and standardized dashboard with customized views (e.g. for OneOps Leadership, Network, Factory etc.). Ensure standardized deployment in all functions of OneOps (or even beyond). Data from all relevant sources is seamlessly connected through standardized systems and available in real time enabling smooth flexible analysis and decision-making across all levels. e.g. DATALAND as Data integration Platform for a harmonized data foundation. Service Now?",
        "further_ideas": "Standardized dashboards and data model across the organization. Data driven KPI monitor predicts which target will likely be reached or missed by the end of a certain reporting period",
        "effort_quantification": "Operating cost (Opex): Software as a service cost, Running cost via key user, personnel cost for performance dialogues. Invest (Capex): Cost for IT implementation. Implementation time: e.g. via Opex Prime roll-out (2 - 3 years?), depending on priority. Initial evaluation: Medium",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: Alignment of targets and issue solving will support all target achievements, i.e. ensures faster transfers. REDUCTION OF TIME FOR PRODUCT LAUNCH: Alignment of targets and issue solving will support faster launches. REDUCTION OF TOTAL COSTS OF SUPPLY: Alignment of targets and issue solving will support seamless supply. QUALITY (RFT): Performance management KPIs will be defined to support the achievement of these targets. Initial evaluation: High",
        "dependencies_text": "Alignment of targets and issue solving will support all target achievements, i.e. ensures faster transfers, launches & seamless supply",
        "contact_persons_text": "Marinie",
        "related_projects_text": "OPEX Prime",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:24:49.001003+00:00"
      },
      {
        "id": 79,
        "bi_id": "QC04",
        "name": "Centralized Specification Management System",
        "process_step_id": 43,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Globally used system to manage Specifications.\n*   The system is end to end integrated with all data sources, and automatically feeding other systems within QC landscape\n*   Description: Develop a comprehensive system to manage all specifications in one place, ensuring centralized control and streamlined processes.\n*   Key Features: Centralized repository for all specifications, Version control and change tracking, User access controls and permissions, Integration with other enterprise systems, Real-time collaboration and updates\n*   Create and maintain specifications and analytical procedures in a global system, ensuring consistent controls and streamlined processes.",
        "technologies_text": "*   GESPEC ?\n*   XML structured documends",
        "requirements": "*   Use of a global system for the creation and all maintenance activities for testing specifications\n*   Method setup: cross-site, cross-product harmonized procedures and limits\n*   Global standards are in English (prerequisite)\n*   Strong governance and clear responsibilities (prerequisite)\n*   Safe way to update P&SMs through automated Versioning / management (guided Workflow)\n*   References to local adaptions of global standard\n*   Incl. CMO topic (Bio)\n*   Procedures and methods harmonized, and created in a formatting that can be consumed / interfaced digitally by the system\n*   Interfaces to sources systems, and subsequent systems that use the Specifications",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   One system to create and maintain specifications / analytical procedures\n*   global system for specification management and handling including interfaces to lab execution system\n*   build a global system for specification management providing interfaces to relevant sytems\n*   Create and maintain specifications and analytical procedures in a global system, ensuring consistent controls and streamlined processes.\n*   Globally used system to manage Specifications.\n*   The system is end to end integrated with all data sources, and automatically feeding other systems within QC landscape\n*   Safe way to update P&SMs through automated Versioning /- management (guided Workflow)\n*   Description: Develop a comprehensive system to manage all specifications in one place, ensuring centralized control and streamlined processes. Key Features: Centralized repository for all specifications, Version control and change tracking, User access controls and permissions, Integration with other enterprise systems, Real-time collaboration and updates\n*   References to local adaptions of global standard\n*   Incl. CMO topic (Bio)\n*   method set up: cross site check to ensure hormonized procedures and limits\n*   Safe way to prevent useing outdated P&SMs through workflows connected to database\n*   Counter \"How often, when and why (Where) used\"\n*   Global standards are in English Prerequisite\n*   strong governance and clear responsibilities Prerequisite\n*   Safe way to update P&SMs through automated versioning (updated workflow)\n*   Global system for specification management and handling, including interfaces to lab execution systems\n*   References to local adaptations of global standards\n*   Safe way to prevent wrong transportations through connected databases\n*   Inclusion of CMO topics (Bio)\n*   Procedures and methods harmonized, and created in a formatting that can be consumed / interfaced digitally by the system\n*   Interfaces to sources systems, and subsequent systems that use the Specifications\n*   Use of a global system for the creation and all maintenance activities for testing specifications\n*   Method setup: cross-site, cross-product harmonized procedures and limits\n*   Global standards are in English (prerequisite)\n*   Strong governance and clear responsibilities (prerequisite)\n*   Hard due to change management activities and organizational discussions\n*   GESPEC ? XML structured documends\n*   Qualitative Benefits: Harmonization, One source of truth for LES, foundation for Lab digitalization\n*   Description (AI part - seems related but perhaps a separate idea): Leverage AI to create precise and efficient analytical procedures, enhancing the accuracy and speed of lab operations. Key Features: AI-based procedure generation and optimization, Integration with lab equipment and data sources, Real-time validation and error checking, Historical data analysis for procedure refinement, User-friendly interface for procedure customization",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Hard due to change management activities and organizational discussions",
        "potential_quantification": "High",
        "dependencies_text": "Data management",
        "contact_persons_text": "*   Klaudius Dragon\n*   Alex Haas\n*   Tobias Elsenheimer + Benjamin Walker\n*   Adelina Reichert",
        "related_projects_text": "*   Benjamin Walker + Tobias Elsenheimer\n*   Project: GSpecS - EditorUpgrade (66466) Background: Application is still hybrid cloud Authors need to switch between Workspace and Editor (Add-in of MS Word) which runs on Terminal Servers and is accessible via Citrix Apps Workspace and Editor are 2 different Citrix Apps Internal 7 Terminal Servers (incl. 1 load balancer) and 6 Citrix Apps (40k\u20ac per year) Save IT INF resources for maintenance and support of citrix environment and servers Objectives:",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 80,
        "bi_id": "QA03",
        "name": "Integrated data interface between sponsor and ext. partners",
        "process_step_id": 17,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   eliminination of non-value-adding copy-paste activities (+ 4eye principle) to incorporate information from partner..\n*   reduction of associated data integrity risks\n*   real-time information available .\n*   The main problem to be solved is inefficiency and data integrity risks due to manual processes. By integrating external partners into BI systems, efficiency is increased and data integrity is ensured",
        "target_solution_description": "*   The goal is seamless and secure data* transfer between BI and external partners, regardless of whether BI is acting as a CMO or sponsor....\n*   *data in scope includes: production data, analytical results, discrepancy related information, investigation reports, change requests, CAPA related information and completion dates..",
        "technologies_text": "*   Vault RIM / OMP: Direct integration into BI IT applications.\n*   SNCP Platform: Use of the platform for data* transfer",
        "requirements": "*   Rights Management: Access to BI systems must be regulated.\n*   Interface Integration: Seamless data transfer between BI and external partners.\n*   Efficiency Improvement: Avoid manual copy-paste processes....",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   connection of external partners with restricted access to BI IT applications either directly (Vault RIM / OMP) or via SNCP platform to eliminate copy-paste into BI tools (efficiency gain, capacity reduction) and reduce DI risks\n*   seamlessly regardless if BI is CMO or sponsor\n*   integrate interfaces for every external partner to ensure seamless data transfer\n*   minimum: right-management for access to BI systems",
        "further_ideas": "n/a",
        "effort_quantification": "Medium/Hard; Operating cost (Opex): \u20ac200k - \u20ac500k; Invest (Capex): <\u20ac500k; Implementation time: 1-3 years",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   Pedro Recarte-Pelz (GMSO External - Supplier Qualification)\n*   Andreas Oefner\n*   Nadine Jahn (DMSO External Mngmt)\n*   Tania Plaskasoviti (Supplier Audits)?",
        "related_projects_text": "*   P360: 67576 GOTrack - Interface Supplier Network collaboration Platform (Thomas Hedwig)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:49:06.393680+00:00"
      },
      {
        "id": 83,
        "bi_id": "QA29",
        "name": "Advanced Global Batch Traceability",
        "process_step_id": 22,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Establish a comprehensive global batch traceability system that includes CMOs. This system should provide real-time tracking of batches from production to distribution, ensuring transparency and compliance. Utilize blockchain technology to enhance the security and integrity of batch traceability data.\n*   Extension of GBT (Global Batch Traceability) to externally manufactured products\n*   Global Batch and Unit traceability for traceability AND supply chain security\n*   traceability down to unit-level END-TO-END down to customer",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:57:20.515064+00:00"
      },
      {
        "id": 81,
        "bi_id": "QA04",
        "name": "Automated handling for external GMP documents",
        "process_step_id": 17,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   higher degree / fully automated archiving of GMP documents (elimination of redundant manual process steps => efficiency gain, capacity reduction)\n*   Get external GMP Documents to eDMS",
        "further_ideas": "n/a",
        "effort_quantification": "Easy; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Low/Medium; ca. 1,5 FTE; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:49:18.983611+00:00"
      },
      {
        "id": 86,
        "bi_id": "QC07",
        "name": "AI-Powered Document Translation System",
        "process_step_id": 43,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   Current translation is not of high Quality first time, with effort for revision\n*   Time consuming, variable quality, expensive.\n*   Translation as an activity/step is delay factor for new projects/systems roll-out to sites",
        "target_solution_description": "*   mainly in VQD build\n*   Automated Translation: Use AI to translate documents while maintaining the original layout and formatting.\n*   Real-Time Translation: Provide instant translation for documents uploaded to the system.\n*   Multi-Language Support: Support for multiple languages to cater to a global audience.\n*   Glossary Integration: Use glossaries to ensure context-specific terminology is accurately translated\n*   Integration with Existing Systems: Seamless integration with existing document management and enterprise sy",
        "technologies_text": "*   First step create a Agent for specific documents for translation",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Description: Utilize advanced AI technology to automatically translate documents, making the process faster and more cost-effective.\n*   Key Features: Multi-language support, Context-aware translation algorithms, Real-time translation previews, Integration with document management systems, Continuous learning and improvement of translation models\n*   AI-Powered Document Translation System\n*   Current translation is not of high Quality first time, with effort for revision\n*   Time consuming, variable quality, expensive.\n*   Translation as an activity/step is delay factor for new projects/systems roll-out to sites\n*   Translations if needed are automatically prepared by AI and updated accordingly\n*   Englisch as required language of specification - automated translation if country specific regulations require provided by AI\n*   The default for all global master data should primarily be English. However, there should be the option to translate it into the local language.(AI)\n*   mainly in VQD build\n*   First step create a Agent for specific documents for translation\n*   Automated Translation: Use AI to translate documents while maintaining the original layout and formatting.\n*   Real-Time Translation: Provide instant translation for documents uploaded to the system.\n*   Multi-Language Support: Support for multiple languages to cater to a global audience.\n*   Glossary Integration: Use glossaries to ensure context-specific terminology is accurately translated\n*   Integration with Existing Systems: Seamless integration with existing document management and enterprise sy",
        "further_ideas": "Idea (Purple sticker)",
        "effort_quantification": "Easy",
        "potential_quantification": "High",
        "dependencies_text": "n.a.",
        "contact_persons_text": "*   Caroline Becker, Colin Lischik",
        "related_projects_text": "EngageAI",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 87,
        "bi_id": "QC06",
        "name": "Global Inspection Plan for one product",
        "process_step_id": 43,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Master data setup per site. SAP structure currently only per plant-station (Werk). Possible compliance risk since plans might differ after some time. Change management needed for every site separately.",
        "target_solution_description": "Only one Global master data set up. Standardized and harmonized plans and data structure. Clear responsibilites for master data. One plan available to all sites.",
        "technologies_text": "LIMS / LES",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Global Inspection Plan for one product\n*   global inspection plan for a product\n*   Inspection plans are currently on plant level\n*   Hard due to change management activities and organizational discussions\n*   Master data setup per site. SAP structure currently only per plant-station (Werk). Possible compliance risk since plans might differ after some time. Change management needed for every site separately.\n*   Only one Global master data set up. Standardized and harmonized plans and data structure. Clear responsibilites for master data. One plan available to all sites.\n*   Global Inspection Plan for One Product\n    *   Single Global Master Data Setup: Ensures consistency and standardization.\n    *   Standardized Plans and Data Structure: Reduces discrepancies.\n    *   Clear Responsibilities: Enhances accountability and efficiency.\n    *   One Plan for All Sites: Uniform implementation and monitoring.\n*   Current Setup and Challenges\n    *   Master Data per Site: Leads to inconsistencies.\n    *   SAP Structure: Organized per plant, posing compliance risks.\n    *   Compliance Risks: Diverging plans may lead to non-compliance\n*   Currently not possible in GBS United. No global inspection plan module\n*   There should be only one plan in the system\n*   LIMS / LES",
        "further_ideas": "Info (Yellow sticker with detailed description)",
        "effort_quantification": "Medium; Hard due to change management activities and organizational discussions",
        "potential_quantification": "High",
        "dependencies_text": "GBS",
        "contact_persons_text": "Tobias Elsenheimer, Philipp Hattemer und Julia Ilgen, Virginia Hau",
        "related_projects_text": "Jennifer Seefeldt (MyLIMS)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 85,
        "bi_id": "SCM29",
        "name": "Smart (warehouse) ressource, capacity & transportation planning",
        "process_step_id": 29,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 2",
        "effort_level": "Medium/High",
        "status": "medium",
        "business_problem_solved": "Manual planning in Excel with data from BIX@ and EWM (short term).",
        "target_solution_description": "Single source system (e.g. EWM System), link to prodction planning/schedule.",
        "technologies_text": "as part of EWM. pilot in power BI.",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Automated transport load building. Smart digital handling of transport capacity utilization. freight consolidation - cost saving vs.speed. Machine learning supported demand forecasting to shift incoming and outgoing goods as well as inventory management, reducing overstock and stockouts. implement pool of employes to shift from all teams where needed (GR, GI, buffer warehouse, commisssioning).",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: 6m if power BI.",
        "potential_quantification": "Optimized consolidation. Efficient workforce allocation.",
        "dependencies_text": "check if combination possible or leave as single digital twin use case. Link to 23: AI driven simulation capability for logistics. Accurate Data e.g. Inbound of deliveries. Master Data Definition / Ownership / Quality.",
        "contact_persons_text": "Guido Sabelleck for POPU logistics.",
        "related_projects_text": "RCV PowerBI Solution.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:10:38.034930+00:00"
      },
      {
        "id": 84,
        "bi_id": "SCM11",
        "name": "Unified data model for global capactiy transparency",
        "process_step_id": 35,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": null,
        "effort_level": "High",
        "status": "high",
        "business_problem_solved": "Unified data model allows to transparently check global available and utilized capacity. Enables global capacity and allocation planning to internal and external network. Allows planning of pre-Launch materials to reserve capcaity and calculate material needs. Allows for simulation and scenario planning. Allows efficient and compliant manufacturing execution.",
        "target_solution_description": "Integration and alignment with SKU concept, attributes and units of measure. Consistent definition and implementation off/on. How capacities, equipments and labor are modeled (e.g. train vs. equipments). Hierarchies and aggregation rules for capacities. Technology definitions. Clear concpet how to implement the concept in SAP. Definiton of SAP ERP resources including classification. Definition of SAP ERP production versions, recipes and BOMs including concept forlong term planning, tactical & operational planning as well as execution and integration with MES and other shop floor systems. Governance structure incl RACI and potential data domain for manufacturing master data.",
        "technologies_text": "SAP ERP, SAP IBP. K\u00f6rber / MESetc.",
        "requirements": "Consistent model across networks and systems. Allowing strategic planning incl. financial integration. financial calculation. tactical and opertaionl planning. Execution. shop floow integration. Aligned with COPE process requirements.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Application of SKU data model unified across all sites and enriched with missing attributes. (e.g. product stage not used consistently). Define network-wide and domain integrative data model for products and processes -> provide basis for further automation of decision making, reduce organisational drag, increase decision speed. Increase planning consistency over the planning horizon. Making sure of consistency in Operative/ tactical and strategic planning by using one source of truth (i.e. use of the identical Bom, planning parameter). Global governance for manufacturing master data (production versions, recipes, resources) to enable aggregation and global transparency. establish versatile capacity model and integrate external partner's data. Harmonization of product-relevant master data across sites by implementing a unified governance concept. This ensures consistent data management and integrity, reducing discrepancies and improving overall operational efficiency. (along with defining iand implementing network wide data model)... Master Data Agent keeps our SCM data room clean. Continously trained based on actual transactional data compares with master data settings, proposes adjustment and executes master data changes. Set-up initiative for harmonisation and standardisation of data across the network incl. Governance concept to \"get clean and stay clean\".",
        "further_ideas": "FURTHER INPUT: Consolidated forecasting. Not to be merged but case \"Unified data model for capacity\" is another critical element for master data. Also case 18 has many elements from case \"unified data model\". We need to make sure that comes out!",
        "effort_quantification": "Project cost: Medium, after concept definition master data majorly in GBS UnITed to be updated / adjusted. Run costs (p.a.): Once implemented higher efficiecny in processes overcompensates additional for governance. Time for implementation: 3-5 years.",
        "potential_quantification": "Unified model allows for global steering,planning and transparency.",
        "dependencies_text": "Dependencies: Manufacturing. Scenario Planning. Tactical Supply Planning. Production Planning & Scheduling. COPE.",
        "contact_persons_text": "Laufersweiler,Joern. Gardt,Thomas.",
        "related_projects_text": "Cope: Architecture & Master Data workstream. Britta Lifka. Mark Singh. Dylan Maxwell.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:02:55.657100+00:00"
      },
      {
        "id": 90,
        "bi_id": "QA06",
        "name": "AI supported MBR review",
        "process_step_id": 17,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   Master manufacturing documents are to be manually aligned with dossier documents\n*   Context transition and understanding is time -onsuming",
        "target_solution_description": "*   Well-trained AI solution that is able to undertstand context to perform adherance of master document to assocated dossier",
        "technologies_text": "*   Interface of AI to RIM and MES necessary",
        "requirements": "*   Well trained AI that understands transitions into master documents",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   AI support in review & approval of master documents (MBR, TS) - to be aligned with submission documentation / CCs / basis reports (eg PV)\n*   internal and external",
        "further_ideas": "n/a",
        "effort_quantification": "Easy; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: 1-3 years",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   GMSO for Batch disposition: Sebastien Blang\n*   DMSO for Batch disposition: Matina Jugl",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:49:47.212026+00:00"
      },
      {
        "id": 92,
        "bi_id": "QA08",
        "name": "Automated quality reporting",
        "process_step_id": 17,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Quality management Review process Every site compiles data tediously and individually (70 ppt slides template to be filled out currently)\n*   Automated assignment of of role-based curricula to associated roles\n*   Quality dashboard\n*   Data for external oversight\n*   Define Data sources forKPI calculation\n*   Implement a data quality management system that ensures high data quality, connectivity, and accessibility. Additionally, develop a data connectivity tool that integrates various data sources for KPI calculation and metrics generation, providing a comprehensive and accurate view of performance metrics.\n*   adaption of IT applications to include needed additional fields etc to allow automated KPI calculation & reporting\n*   incl. standardized (guided) reporting instructions",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:50:30.821813+00:00"
      },
      {
        "id": 91,
        "bi_id": "QA07",
        "name": "Guided workflow following SOPs",
        "process_step_id": 17,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   breakthrough :-): perhaps SOP can be subsituted by direct explanations at time of usage (e.g. \"dear system please help me cleaning the equipment xxx)\n*   transport validation is pretty generic and could be executed more or less by a system (what routes will be used, what shipping material, which conditions)\n*   People are guided from a system/ bot/ ... while operating along a SOP",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:50:05.166668+00:00"
      },
      {
        "id": 94,
        "bi_id": "SCM13",
        "name": "Cost Model",
        "process_step_id": 35,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 3",
        "effort_level": "High",
        "status": "high",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Develop a total-cost-of-supply concept, fed by variable data and Master Data. Develop into calculation tool for operational, tactical, and strategic purposes.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "e.g. Partners, suppliers, stakeholders ...",
        "contact_persons_text": "Langlouis,Dr.,Gabriele.",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:03:01.922300+00:00"
      },
      {
        "id": 93,
        "bi_id": "SCM18",
        "name": "Automation of parametrization (SC Digital Twin)",
        "process_step_id": 11,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Include / combine with content from demand P360 67306 / 67614 (Dtwin). # GBS & IT Budget Process 2026 - VP_SC Digital Twin 2026.pptx",
        "wave": "Wave 2",
        "effort_level": "Low",
        "status": "medium",
        "business_problem_solved": "Major SC parameters (safety stocks, lot sizes, etc.) arecalculated/proposed by the system considering actual data. Proposals for operational parameters like yield, takt, etc. for tactical/strategical planning. Alerting for paremeters and need for change. Support for segmentation, e.g. launch vs. mature.",
        "target_solution_description": "Defined parametrization Run for planning relevant master data to ensure updated and correct data. Released parameters are automatically populated to the relevant systems. Defined ownership of all parameters including governance model / raci.",
        "technologies_text": "SAP.",
        "requirements": "Easy to use, frequent SC parameter update. Alerting.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "Medium",
        "reduction_time_launches": "Medium",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "(AI enabled) automatization of parametrization supporting all lifecycle stages and segmentation concepts.",
        "further_ideas": null,
        "effort_quantification": "Project cost: Med for implementation project. Run costs (p.a.): once implemented reduced Operating cost due to higher accuracy of master data leading to less re-planning actvities. Time for implementation: 1-2 years.",
        "potential_quantification": null,
        "dependencies_text": "Digital SC Twin HP (P360 67306 / 67614). Performance mgmt. in manufacturing.",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:04:20.826446+00:00"
      },
      {
        "id": 95,
        "bi_id": "SCM20",
        "name": "Clinical Trial Supply Integration",
        "process_step_id": 11,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": "low",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "...",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "-",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:04:33.366275+00:00"
      },
      {
        "id": 11,
        "bi_id": "SCM34",
        "name": "E2E Dangerous Goods",
        "process_step_id": 32,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "Dangerous Goods.pptx",
        "wave": null,
        "effort_level": "Low",
        "status": "low",
        "business_problem_solved": "System supported completion checks and monitoring. Currently no E2E visibility for Boehringer products in place.",
        "target_solution_description": "ww traceability of BI products (eg via Serialization) until patient level.",
        "technologies_text": "coding technology in place. cloud solution for storage of codes in place. customer read out tbd (simliar to scanning @ pharmacy, app on mobile).",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "E2E TOOR (TOCS) process in place across functions & sites: enable decision on batch release at decoupling points and for final release to market.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ~ 3 years for ww.",
        "potential_quantification": "use beyond ACF topcis (T&T). avoid counterfeits, reputational issues. be proactive instead of reactive. avoid destruction cost.",
        "dependencies_text": "...",
        "contact_persons_text": "Sabelleck,Guido.",
        "related_projects_text": "Dangerous Goods.pptx.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:08:36.552327+00:00"
      },
      {
        "id": 101,
        "bi_id": "SCM06",
        "name": "Data Interface to SC-Partners",
        "process_step_id": 38,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "-",
        "requirements": "-",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "Medium",
        "reduction_time_launches": "Medium",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Establish process and system to exchange data (Q,Manuf, SCM, Finance) with external partners (CMO, 3PL, Excipient-, Material Suppliers. --> integrate internal and external facilities and partners into OneOps data space , enable wholistic decision making. Integrate CMOs into PLM to increase automation and compliance.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ~0,5 mio\u20ac for digital twin foundation. built of interfaces from source systems . ingestion of data from source systems. Run costs (p.a.): transfer of data from existing systems in LLM. Time for implementation: 1 year learning timeline including training. availability of training data sets.",
        "potential_quantification": null,
        "dependencies_text": "-",
        "contact_persons_text": "Neves,Filipe Oliveira. Uwe Kr\u00e4mer-> 3PL. U. Kies. inc. Supplier & 3PL. Timm Hofrichter -> Supplier.",
        "related_projects_text": "-",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:01:07.489458+00:00"
      },
      {
        "id": 5,
        "bi_id": "SCM08",
        "name": "Scenario Planning & Simulation",
        "process_step_id": 35,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 2",
        "effort_level": "High",
        "status": "high",
        "business_problem_solved": "Scenario planning, simulation and optimization of global int/ext capacities including financial integration.",
        "target_solution_description": "Capacity vizualization of internal and extenal production sites for FG to starting materials based on harmonized data model allowing aggregation and dis-aggregation covering time horizon 0-10y for all product lifecycle stages. system support for product review. integration of demand scenarios. all decisions are driven by fiancial impact assessement.",
        "technologies_text": "SAP.",
        "requirements": "user friendly process which can be run quarterly. data model alinged with financial planning. fully integrated solution (process and system).",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Integrated system streamlines strategic planning with automated demand-capacity integration and pipeline management. To provide robust reconciliation options for various demand scenarios, ensuring more accurate and efficient decision-making. Implement financial integrated long range capacity planning solution (SPICE). LRCP is considering financial implications (i.e. TPA-05 volume allocation to G800 will lead to increased CoGS). use total cost of supply to steer product allocation / life cycle measures => system support for calculation. Scenario planning, simulation and optimization of global int/ext capacities for LRCP. scenario planning also using path specific details (sustainability, price/CoGs, finance, risk management data). Capacity vizualization of internal and extenal production sites for FG to starting materials based on harmonized data model allowing aggregation and dis-aggregation covering time horizon 0-10y for all product lifecycle stages. Scenario Planning. What-If Analysis: Conduct scenario planning to evaluate the impact of various strategic decisions on the supply chain (e. g. changes in demand, supply disruptions, etc.). Scenario Planning. Risk Mitigation: Development of contingency plans for potential suppy disruptions by simulating different risk scenarios. AI driven digital Supply Chain Twin for simulation, evaluation and strategic decision-making (i.e. supply chain design options; capacity simulation; invest decisions). Visualize Supply Chain based on configuration for better oversight and presentation. Enable demand scenarios (incl. likelyhood of success) to access impact on supply network. forecast for launch products (as needed for Operations, i.e. high volume product / new technology with sufficient lead time. aggregation level tbd). To ensure investment planning. Advanced Analytics: Use machine learning and data analytics to identify trends.",
        "further_ideas": null,
        "effort_quantification": "Project cost: project cost to finalize exisiting IT platform. Run costs (p.a.): medium driven by potential run cost of IT solution. Time for implementation: approx 1 year.",
        "potential_quantification": "Integrated planning across all functions. Collaboration across the company.",
        "dependencies_text": "-",
        "contact_persons_text": "Langlouis,Dr.,Gabriele.",
        "related_projects_text": "SAP IBP S&OP for tactical and strategic network planning.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:02:48.086184+00:00"
      },
      {
        "id": 97,
        "bi_id": "SCM02",
        "name": "Data Model \u2013 SKU",
        "process_step_id": 38,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "re-design SKU master data / hierarchy: GTIN as global identifier (int&ext), CoGs independent of production site. allocation one level below => get rid of cumbersome planning on local SKU (user/BOPU oriented). One harmonized data model for E2E PLM planning and execution. Implement best fitting SKU concept considering Mulitsourcing, Versioning, Financial, Regulatory and Quality aspects. Change supplier specific SKU concept of Boehringer Ingelheim to enable standardized planning solutions.",
        "wave": null,
        "effort_level": "High",
        "status": "high",
        "business_problem_solved": "process blocks due to missing data along SC, only reactive.",
        "target_solution_description": "Defined and implemented corporate procedure for data model. Consistent material attributes across all levels supporting all local and global processes. Implement best fitting SKU concept considering Mulitsourcing, Versioning, Financial, Regulatory and Quality aspects.",
        "technologies_text": "SAP ERP, MDM, IBP, ...",
        "requirements": "Consistent model allowing Global SC Planning and Steering. Efficient local execution. Efficent financial planning. Data governance concept for HP and AH ensuring sustainable usage and adherence.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "re-design SKU master data / hierarchy: GTIN as global identifier (int&ext), CoGs independent of production site. allocation one level below => get rid of cumbersome planning on local SKU (user/BOPU oriented). One harmonized data model for E2E PLM planning and execution. Implement best fitting SKU concept considering Mulitsourcing, Versioning, Financial, Regulatory and Quality aspects. Change supplier specific SKU concept of Boehringer Ingelheim to enable standardized planning solutions.",
        "further_ideas": "FURTHER IDEAS / INPUT: wave 1) from BOPU to POPU (BIX@) proactive info on master data issues. wave 2) enlarge scope to all interface systems (eg material supply to POPU, EWM). test AH solution for HP (viability) quick&dirty solution.",
        "effort_quantification": "Project cost: Low to medium for consistent model creationHigh expected cost to adjust impeacted processes in operations and finances. Run costs (p.a.): low, once implemented no additional cost conmpared to todays concept. Time for implementation: 3-5 years.",
        "potential_quantification": "Reduction of complexity. Global transparency.",
        "dependencies_text": "Data model needs to be aligend with AH. Implementation of SKU model might imply adjustments of other processes in finance,manufacturing, order 2 cash, etc. e.g. Partners, suppliers, stakeholders ...",
        "contact_persons_text": "Lersch,Thomas.",
        "related_projects_text": "COPE.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:00:59.457352+00:00"
      },
      {
        "id": 98,
        "bi_id": "SCM03",
        "name": "Dedicated Pre-Launch Process before approval",
        "process_step_id": 38,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": "low",
        "business_problem_solved": "Early Finance Planning. Early volume planning.",
        "target_solution_description": null,
        "technologies_text": "Demand and Capacitily Simulation Tool (DaCS). BIPRISMA.",
        "requirements": "-",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "design/build \"launch at risk process\" in systems. current: time/ressource consuming, frequent Q blocks. Early SKU/Dummy concept for pipepline products (ensure reflection in ERP/planning tools). Improvement of Launch Planning & Readiness. Pain: Late go live planning of Launch SKUs. resulting in manual planning of DS/ DP & FP capacities/ materials. ToDo: Launch SKUs are planned created & properly planned in the 36 months horizon.",
        "further_ideas": null,
        "effort_quantification": "Project cost: -. Run costs (p.a.): -. Time for implementation: -.",
        "potential_quantification": null,
        "dependencies_text": "Input into Strategic Network Planning - Scenario Planning (UC 7). BIPRISMA replacement. LTF-Process.",
        "contact_persons_text": "Neves,Filipe Oliveira.",
        "related_projects_text": "COPE.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:01:01.477443+00:00"
      },
      {
        "id": 99,
        "bi_id": "SCM04",
        "name": "Master Data Monitor",
        "process_step_id": 38,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "Dashboard, Report",
        "wave": null,
        "effort_level": "Low",
        "status": "low",
        "business_problem_solved": "process blocks due to missing data along SC, only reactive.",
        "target_solution_description": "wave 1) from BOPU to POPU (BIX@) proactive info on master data issues. wave 2) enlarge scope to all interface systems (eg material supply to POPU, EWM). A traffic light system for all required master data is in place. user group: BOPU local SCM for daily business, global SCM as prep for Launch.",
        "technologies_text": "dashboard, eg SAC. across systems.",
        "requirements": "-",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "Medium",
        "reduction_time_launches": "Medium",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Masterdata Monitor to remove obstacles (missing PIR, temperature data etc) along the supply chain proactively instead reactively.",
        "further_ideas": "FURTHER IDEAS / INPUT: wave 1) from BOPU to POPU (BIX@) proactive info on master data issues. wave 2) enlarge scope to all interface systems (eg material supply to POPU, EWM). test AH solution for HP (viability) quick&dirty solution.",
        "effort_quantification": "Project cost: no CAPEX needed. Run costs (p.a.): 50-100k EUR. Time for implementation: Use available technologies. Source systems: united, BIX@, EWM. Easier to achieve with seperate reports in source systems. For identification of relevant materials evaluate use of Central Mapping Engine on united (->reach out to J\u00f6rn Laufersweiler).",
        "potential_quantification": "avoid late supply. avoid incompliance (missing Q data). reduce high communication effort / be efficient. also true for run / daily work.",
        "dependencies_text": "Master data quality use cases. Master data flow. Defintion of R&R for Master Data.",
        "contact_persons_text": "Hendrik Lindmeyer.",
        "related_projects_text": "Comperable product \"manually\" (Madaris) AH.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:01:03.701375+00:00"
      },
      {
        "id": 103,
        "bi_id": "SCM14",
        "name": "Segmentation based planning",
        "process_step_id": 28,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting List",
        "effort_level": "low",
        "status": "low",
        "business_problem_solved": "Joint understanding of lifecycle phases. Tailoring existing demand plans to different lifecycle phases will improve forecasst accuracy by adressing market dynamics at each stage. A segmented approach will provide more detailed insights, allowing for more precise planning and decision-making.",
        "target_solution_description": "PLM-Tool: A tool that segments demand plans based on predefined product lifecycle phases (Launch, Growth, Decline and LOE) to adress unique market dynamics at each stage. Integrated Business Planning Approach - ideally supported by system. Integrated Planning Platform: Integrate data from various sources to provide a comprehensive view. extraction of data resulting in supplier reconsiliation.",
        "technologies_text": "Forecasting simulation tool. to be defined according to user requirements.",
        "requirements": "Clear definition of lifecycle phases on brand-level and country-level. Integration with existing data sources and systems. Manual enrichment features for adjusting forecasts/segmentation based on expert insights. User friendly interface for easy navigation and collaboration. Ability to segment demand plans based on product lifecycle phases. For optimal effect this UC requires a top down decision towards same targets (Finance, Demand, Supply).",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Lifecycle Phase Segmentation: Demand plans tailored to different lifecycle phases (launch, established products, LOE) to address market dynamics at each stage. Segmented approach, leveraging automated statistics where possible and manual enrichment where needed.",
        "further_ideas": null,
        "effort_quantification": "Project cost: Implementation of SAP IBP Demand Planning 4-5 Mio \u20ac invest plus licensing. Run costs (p.a.): ... Time for implementation: conflicting targets between finance, supply and demand side.",
        "potential_quantification": "collaborate with purpose. fast decision making.",
        "dependencies_text": "UC 15. Finance. Demand side (Global X-Ta Forecasting).",
        "contact_persons_text": "Dr.Ries,Britta. Sebastian Zenobi (X-TA Global Forecasting). Kate Foster, xTA FC ARC.",
        "related_projects_text": "Next Gen Sales Forecasting - Sebastian Zenobi (X-TA Global Forecasting). Kate Foster, xTA FC ARC.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 107,
        "bi_id": "SCM30",
        "name": "Connected exchange of data with external",
        "process_step_id": 29,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": "Manual planning in Excel with data from BIX@ and EWM (short term).",
        "target_solution_description": "Single source system (e.g. EWM System), link to prodction planning/schedule.",
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "\"Establishing an EDI link with supplier\". Smart digital handling of (time-critical) non-standard transport issues. cmo, 3PL customers... shared database instead of paper or mail.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "...",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:10:42.980714+00:00"
      },
      {
        "id": 105,
        "bi_id": "SCM17",
        "name": "Integration of demand planning to supply planning",
        "process_step_id": 28,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting List",
        "effort_level": "Medium",
        "status": "low",
        "business_problem_solved": "Transparent integration of unconstrained consensus demand plans with option to reflect critical short term adjustments on demand as exception. We can handle allocations and constrained plans to centrally define best overallscenario for the company.",
        "target_solution_description": "Clear transformation of data level from demand planning level (Item / Country) to supply planning level (SKU / SAP Location) defined and implemented. Unconstrained demand plan is integrated to supply planning following amonthly cycle and allows for ad-hoc integration. Constrained allocations lead to constrained demand-plans which can beintegrated from supply planning to demand plannig for transparency reasons.",
        "technologies_text": "SAP IBP Demand.",
        "requirements": "Integrated process supported by SAP IBP to display uncontrained and contrained FC to enable fast alignment and decision making.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Availability of latest sales forecast figures in SCM planning system on demand / ad hoc (not just once a month).",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "...",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:03:50.606973+00:00"
      },
      {
        "id": 108,
        "bi_id": "SCM31",
        "name": "Logistics enabled customer experience",
        "process_step_id": 29,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "overarching use case to enhance customer experience: GPaS (one Boehringer Global Patient Support Capability = platform for patient interaction based on QR code on pack).",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": "...",
        "dependencies_text": "...",
        "contact_persons_text": "Kai Hintze but project lead from HCA&PE. Sonny Zolota.",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:10:44.562529+00:00"
      },
      {
        "id": 106,
        "bi_id": "SCM19",
        "name": "e2e Orchestration of SCM (e.g. deviation & exceptions)",
        "process_step_id": 11,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting list",
        "effort_level": "Medium/High",
        "status": "high",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "E2E Supply Chain Orchestration: Integrated systems to coordinate activities across the entire supply chain- from planning SKUs to active SKUs. Transparent inventory management of TMA inventories across the whole value chain (internal and external).",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "COPE.",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:04:31.401522+00:00"
      },
      {
        "id": 111,
        "bi_id": "SCM25",
        "name": "Business intelligence process for upcoming regulations",
        "process_step_id": 32,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": "high",
        "business_problem_solved": "No overview about upcoming changes and requirements globally. Current: risk of incompliance with impact on patient supply, financials, market authorisation.",
        "target_solution_description": "Business intelligence process in place to detect, assess, implement upcoming regulations (EHS, S&A, resilience, sustainability, GxP). Should be supported by a multi-user system with interface to externally sourced information.",
        "technologies_text": "current RIN / PIN process could be used, but should be system/ tool supported: provide oversight per country / topic. business intelligence mgmt tools should be available on the market.",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Business intelligence process in place to detect, assess, implement upcoming regulations (EHS, S&A, resilience, sustainability, GxP). Should be supported by a multi-user system with interface to externally sourced information. Current: risk of incompliance with impact on patient supply, financials, markez authorisation.",
        "further_ideas": null,
        "effort_quantification": "Project cost: tbd after market check for tools. Run costs (p.a.): ... Time for implementation: manual: 6m. system ~ 1y.",
        "potential_quantification": "Compliance wrt GxP, Tax, Customs, EHS, sustainability, serialization.",
        "dependencies_text": "RIN / PIN process (manual). R&R need to be defined for global/local level for each area. process needs to be developed in parallel how to detect, interpret, implement requirements. should also/mainly be in SEOS Quality!",
        "contact_persons_text": "Albrecht Jacobi. Crossfunctional(EHS, GxP, Q, GMSO RIN/PIN). should also/mainly be in SEOS Quality!",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:09:11.512253+00:00"
      },
      {
        "id": 113,
        "bi_id": "SCM32",
        "name": "E2E paperless Logistics",
        "process_step_id": 29,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": null,
        "effort_level": "Medium",
        "status": "high",
        "business_problem_solved": "Documentation on paper => Risk: \"Non GxP-compliant documentation\".",
        "target_solution_description": "End-to-end digitalization from Inbound order to shipping documents incl. final customer. The system guides employees through documentation, prompting only for required data.",
        "technologies_text": "Mobile Scanner supported process. Integration to EWM. electronic documentation of tasks / system (Libary).",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Paperless logistics end to end. wareneingang, - ausgang, transportdokumente, checklisten... End-to-end digitalization and automation from Inbound order to shipping documents incl FC. FURTHER INPUT: tools on the market eg at 3PL (outbound checklist, customized) incl e-signature / 4 eyes principle.",
        "further_ideas": "tools on the market eg at 3PL (outbound checklist, customized) incl e-signature / 4 eyes principle.",
        "effort_quantification": "Project cost: ... Run costs (p.a.): 150-250k EUR. assumption scope of 5 processes. Time for implementation: <1year.",
        "potential_quantification": "Improved security and compliance: Easier safeguarding and tracking of documents. Increased efficiency and productivity: Faster, more accurate processes with fewer errors. Lower paper consumption and reduced archiving costs. Sustainability: Reduction of CO\u2082 emissions.",
        "dependencies_text": "EWM Template. Master Data Definition / Ownership / Quality.",
        "contact_persons_text": "...",
        "related_projects_text": "Concept: Digital Checklist Inbound (C. Koch). Digitaler Transportauftrag (Wien), Edgar Giese.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:11:05.738623+00:00"
      },
      {
        "id": 110,
        "bi_id": "SCM24",
        "name": "AI driven simulation capability for logistics",
        "process_step_id": 32,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "# GBS & IT Budget Process 2026 - Simulation tool for material flows for Survodutide.pptx",
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": "high",
        "business_problem_solved": "Decisions along the supply chain are not considering the E2E picture (silo decisions in logistics, production, demand planning etc.).",
        "target_solution_description": "Decisions along supply chains consider trade-offs across multiple aspects (e.g. cost of transportation, warehouse costs at BOPU, Customer service level, safety stock levels). mid-term: scenario planning for invest decision (eg make or buy local/3PL WH, hub, cool strage concept) with (digital twin) (Link to UC 28).",
        "technologies_text": "HP Digital Twin project. COPE Replacement project. Finance. Stock. Distribution.",
        "requirements": "Good level of understanding of international logistics and transportation and tread-offs / the \"big picture\" along the supply chain. Keep transportation costs efficient and balanced among the supply chain setting and contribute/ support global inventory policies. Adjust / Set Target setting in Logistics to a realistic ambition for P-OPUs and B-OPUs (Air-share, Utilization etc.).",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "AI driven digital Supply Chain Twin for optimization, simulation and decision-making (i.e. Logistics design for new products/capabilities). Smart capacity planning for warehouse operations (translation of volume in pallets necessary). capability to plan WH capacity (int/ext/hub) and transport based/linked to planning systems (simulation tool). Implementing warehouse capacity planning solution. Connect Production planning to warehouse capacity planning ensuring that there is sufficient capacity available throughout the horizon. Warehouse capacity reflected in systems as planning constrained (e.g. for survodutide).",
        "further_ideas": null,
        "effort_quantification": "Project cost: no CAPEX. Run costs (p.a.): 500-1000k/year for 2-3 use cases with additional data ingestions. Time for implementation: n years - Continous build of use cases on growing data basis.",
        "potential_quantification": "Faster & educated decision making. Decision support in crisis mode. Avoid Capacity (WH/transport) bottelnecks.",
        "dependencies_text": "link to 28!! check if combination possible or leave as singel digital twin use case. Master Data Definition / Ownership / Quality.",
        "contact_persons_text": "Florian Kache. Christian Petri. Sebastian Nebel. Sonja M\u00fcller.",
        "related_projects_text": "HP digital twin project (ADAGO).",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:09:05.375366+00:00"
      },
      {
        "id": 112,
        "bi_id": "SCM26",
        "name": "Automated Logistics",
        "process_step_id": 29,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": "medium",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "...",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Exploiting automation potential: AGV systems, UV disinfection, automated palletizing, etc. Increase camera use for visual inspection at GR finalize the initative to have a automized double check. Automized unloading without people directly into high bay warehouse using camera checks. weighing process for GI will be developed in EWM can be copied from ING to other sites. Clear envision by ASN from supplier to see when and how much is expected to come in the next days and which deliveries have priority. As little manual data entry in SAP booking as possible. Goal: Stable flow of goods without too many peaks and idl times on shopfloor. SSCC Usage for Goods receipt processing. Increase digitalization in GBS ILOL processes: Paperless reduce and challenge checklists. Integrated palettizing concept. Equipments for palettization follow system integration requirements and rules for Handling unit labelling.",
        "further_ideas": null,
        "effort_quantification": "Project cost: tbd after market check for tools. Run costs (p.a.): ... Time for implementation: manual: 6m. system ~ 1y.",
        "potential_quantification": "Optimized consolidation. Efficient workforce allocation.",
        "dependencies_text": "...",
        "contact_persons_text": "...",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:10:58.058758+00:00"
      },
      {
        "id": 117,
        "bi_id": "QC11",
        "name": "Automated sample storage systems",
        "process_step_id": 21,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Automated sample storage systems\n*   Automated Storage Systems: Use automated storage systems to manage large volumes of samples efficiently.\n*   Intelligent storage of samples with temperatur and humidity control. Storage is locked and can only be accessed with digital authorization (e.g. card reader)",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "n.a.",
        "contact_persons_text": "Oliver Gluth (InnDiCamp), Wien",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 118,
        "bi_id": "QC02",
        "name": "Digital Performance Dashboard",
        "process_step_id": 2,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Real-time performance metrics\r\n*   Alerts for performance deviations\r\n*   Historical data analysis and trend identification",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Digital Performance Dashboard\r\n*   Collaboration Tools: Communication Platform: Built-in messaging and notification systems to keep all team members informed.\r\n*   Description: Create a digital dashboard to display real-time performance metrics and historical data analysis.\r\n*   Key Features: Real-time performance metrics, Alerts for performance deviations, Historical data analysis and trend identification\r\n*   Will be fed out of the planning system\r\n*   KPIs/Metrics: OEE (Overall Equipment Effectiveness), Deviations, Events (e.g., equipment failure)",
        "further_ideas": "n/a",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "Will be fed out of the planning system",
        "contact_persons_text": "n.a.",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 119,
        "bi_id": "QC10",
        "name": "Electronic Sampling Documentation",
        "process_step_id": 21,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 3",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "*   sampling documentation paper based\n*   data is manually transfered from paper to system\n*   access for sample takers to SAP/QM not given\n*   data integrity / digital data availability due to system breaks",
        "target_solution_description": "*   integration SAP/QM in MES systems\n*   sample drawing procedure in SAP/QM --> interface to MES",
        "technologies_text": "*   SAP/QM\n*   BIMES\n*   Syncade\n*   MYLIMS\n*   Scanner technology",
        "requirements": "*   sample tracking \"chain of custody\" high inspection focus",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Description: Implement electronic documentation for all sampling events to ensure accurate and accessible records.\n*   Key Features: Digital logging of sampling events, Integration with existing documentation systems, Real-time data entry and validation, Secure storage and easy retrieval of sampling records\n*   Electronic Sampling Documentation\n*   sampling documentation paper based\n*   data is manually transfered from paper to system\n*   access for sample takers to SAP/QM not given\n*   data integrity / digital data availability due to system breaks\n*   electronic documentation of sampling (paperless)\n*   integration SAP/QM in MES systems\n*   sample drawing procedure in SAP/QM --> interface to MES\n*   digital documentation and evaluation of handling and storage\n*   Every information how a sample is handled is documented\n*   Temperature (control) and other live data-logging.\n*   sample tracking \"chain of custody\" high inspection focus\n*   Qualitative Benefits: no paper archival needed, sampling documented DI compliant",
        "further_ideas": "linked to manufacturing",
        "effort_quantification": "Easy; Operating cost (Opex): Invest (Capex): Implementation time: 1 year",
        "potential_quantification": "High; archiving, avoidance manual data transfer",
        "dependencies_text": "harmonization of hardware devices; IT, GBS; Hardware (Scanner, printer, PC)",
        "contact_persons_text": "*   SAP/QM (Virginia Hau)\n*   MES Kerstin Trentz\n*   BIMES Bernd Lehle\n*   Syncade Dieter Jansen\n*   MES CSI Iris Mensch\n*   IT Sven Leibenath\n*   Jennifer Seefeldt",
        "related_projects_text": "SAP QM / MyLIMS ( Virginia Cedeno / Jennifer Seefeldt Christpher Stratil, )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 115,
        "bi_id": "SCM35",
        "name": "SC - Master Data",
        "process_step_id": 14,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": "high",
        "business_problem_solved": "SC data quality often falls short of needs resulting in lengthy, error-prone, & labor-intensive execution. Transparency: Clear reference data systems (one source of truth). MDG/FRED/etc. Eliminating data silos by creating harmonized data model across Finance and Supply Chain Management, GRA, Quality, Trademark and Patents, POPUs, BOPUs. Clarifying data ownership responsibilites to improve accountability and data governance. Digitalization and integration of STMLs. Transparency on recycling part in primary and secondary packaging as per EU legislative. Easy conversion of data e.g. production and logistics.",
        "target_solution_description": "Transform the SC into a data-driven one via three levers (1) Create data transparency to set actionable data quality targets; (2) Setup SCM data orchestration structures, improving data quality and availability of existing data assets via secured personnel capacities in SCM&S; and (3) establish a SC. data culture lived by every employee. Full-fledged SCM data orchestration structures in place ensuring the needed data quality. \u201cData quality fit-gap assessment\u201d conducted for ALL SC planning / execution / lifecycle systems & processes. Regular data quality audits in SCM ensure data quality targets are being met (linked to MAG). Data quality awareness trainings are regular part of learning curricula, ensuring data quality is our norm & part of our SCM culture. Successful data quality transformation with data culture in place and actively lived: Master data is in a state to run our core processes efficiently in our systems. Data quality targets in place for each employee in MAG \u201cI am accountable for data quality in my area -and I take care\u201d. Ai supported doublicate removal / cleaning (prevent entry). unique identification for all master data sets (via ISPOC or user guided process). data governance model for all data E2E. Integrated network wide, harmonized data model.",
        "technologies_text": "MDG as Master Data Management Tool. RIM system (OMP). PLM-Tool. PLM GPT (AI support). Augmented Data Management.",
        "requirements": "Master Data governance and execution needs to be business oriented e.g. Launch SKU creation and planning 36 months. Consoilidated E2E MD. One data set used by Finance and SCM to ensure that Sales and Production volumes are always alinged. Easy connectivity needed.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Every liquid product has the conversion factor in the master data e.g. KG, G in L and ML. no transparency on recycling part in primary and secondary packaging. ALCOA++. Improvement of Launch Planning & Readiness. Pain:Late go live planning of Launch SKUs. resulting in manual planning of DS/ DP & FP capacities/ materials. ToDo: Launch SKUs are planned created & properly planned in the 36 months horizon. Global governance for manufacturing master data (production versions, recipes, resources) to enable aggregation and global transparency. establish one integrated data model from forecasting to execution (SKU, batches, ...) (fin, SCM, QA, RA). Single source of truth for data & clear ownership (eg EHS/DG, sustainability, environmental conditions, tax, customs, legal, all other logistics master data), interfaced into execution systems to ensure compliance and reduce manual effort for crosschecks. Could be AI supported. One data set used by Finance and SCM to ensure that Sales and Production volumes are always alinged. Create unique identifer solution for supplier and materials to enable easy supplier performance mgmt and consolidated forecasting. Based on desired level of automation describe pre-requisites from data, process, system view. Define planning relevant parameters and rules for structure of planning relevant data objects/fields. Classify which data requirements are needed to support which planning aspect/process. Create tools to identify gaps easily and give guidance for adjustments. Integrated network wide, harmonized data model. Establish network wide integrative data model. Unique identifier for a vendor/supplier. One common concept for interchangability to reduce efforts (i.e. unique idendifer?). Vendor Management: Develop maintenance rules to prevent duplicates, gaps, errors, and inconsistencies. (Implementation of algorithms and external verification, but also incentivisation of proper behaviour). Centralized master data maintenance and reduce system complexity while increasing processing speed to increase data integrity, reduce TCO, and to shorten the currently long-lasting data consolidation process in Futurcast(between the 15th- 23rd day of a month). Global governance for manufacturing master data (production versions, recipes, resources) to enable aggregation and global transparency. Planning tool is considering contracualobligations (i.e. min/max volume, lot size, campaign size, ...).",
        "further_ideas": "FURTHER INPUT: Consolidated forecasting. Not to be merged but case \"Unified data model for capacity\" is another critical element for master data. Also case 18 has many elements from case \"unified data model\". We need to make sure that comes out!",
        "effort_quantification": "Project cost: low, internal FTEs. Run costs (p.a.): Data Community in Operations. Time for implementation: To be aligned with COPE 5 years max go live 2030.",
        "potential_quantification": "!!!unbelievable high!!! Increased data integrity, accuracy. ALCOA++.",
        "dependencies_text": "Interchangability part of COPE needs to be decided. OneOps topic rather than SCM. GBS MDM and PPM project (Garcia_Ruiz,Carlos (GBS MDM) BIG-DE-I). SKU Transfer Master List Cockpit 2026 - 67716 (Project planned for 2026).",
        "contact_persons_text": "This is a global oneOPS topic - proposal: to be driven via Digital Office (Viola Meisterling). OneOPS Data Strategy: Andreas \u00d6ffner. SCM Data Domain Owner: Isil D\u00f6nmez Seyhan. Governance project GBS: Garcia_Ruiz,Carlos (GBS MDM) BIG-DE-I. Nadine Becker GBS MDM. Martin Treder MDM. COPE Workstream Data Architecture: Britta Lifka, Dylan Maxwell, Mark Singh. Not to be merged but case \"Unified data model for capacity\" is another critical element for master data. Also case 18 has many elements from case \"unified data model\". We need to make sure that comes out!",
        "related_projects_text": "Cope: Architecture & Master Data workstream. Britta Lifka. Mark Singh. Dylan Maxwell.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:11:40.580506+00:00"
      },
      {
        "id": 120,
        "bi_id": "M01",
        "name": "Integrated production planning and scheduling",
        "process_step_id": 36,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\r\nWAVE: 1\r\nBUSINESS PROBLEM SOLVED:\r\n*   Scenario planning / simulation has to be done in multiple decentralized excels\r\n*   Replanning after changes in production are slow and inefficient\r\n*   Decision making is slow on checking possible scenarios\r\n*   Check of maintenance plan, production plan, and material availability done seperately and require manual cross checks",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   Scenario planning / simulation has to be done in multiple decentralized excels\r\n*   Replanning after changes in production are slow and inefficient\r\n*   Decision making is slow on checking possible scenarios\r\n*   Check of maintenance plan, production plan, and material availability done seperately and require manual cross checks",
        "target_solution_description": "*   Scenario planning / simulation including material & equipment availability in one tool\r\n*   Tool to support scheduling to include checks for capacity & required time\r\n*   Maintenance, production and material planning in one tool.",
        "technologies_text": "*   Advanced production planning solution\r\n*   Pharma uses GRP 3.0 (SAP APO)\r\n*   Chemie uses MWB OR-Soft\r\n*   AH uses Orsoft MWB\r\n*   Biopharma OR-Soft-roll out ongoing",
        "requirements": "*   IT, GBS resources\r\n*   Input by local SCM experts from different areas needed.\r\n*   SCM workshop with local SCM-experts?",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   Production planning & scheduling closely integrated with replenishment planning in one tool.\r\n*   support of version planning.\r\n*   Centralized planning in one planning tool\r\n*   Global SCM info about productionplan, facility specific planning connected with working plans and capacity planning in one tool --> different productionsystems can be entered in one tool\r\n*   One Planning Tool for all disciplines (SCM, Manufacturing, Engineering, CPT, Cleaning Validation) to organize all Factory activities\r\n*   Requirement: common manufacturing lead time tool, categorized by type of production/technology, including BOM (bill of material) and lead times for specific end product.\r\n*   the model could propose best production slots for given products based on raw material availabilty, change over time, etc.\r\n*   intergrated and standardized planning process in GBS (Volumes, capacities, maintenance, calibration, validation etc.)\r\n*   Re-Scheduling (short-term, contigency induced)\r\n*   Requirement: Simulation environment for all planning tools w. import / export\r\n*   Equipment / System availability\r\n*   Equipment und Materialplanung automatisiert am Produktionsplan orientiert. (Equipment and Material planning automated based on production plan)\r\n*   R\u00fcstoptimierte Productionsplanung (Setup-optimized production planning)\r\n*   eliminate Excel usage (brain drain)\r\n*   Nutzung von KI um zuk\u00fcnftige Nachfrageprognosen zu erstellen, um die Produktion und Lagerhaltung besser zu planen (Use of AI to create future demand forecasts to better plan production and warehousing)\r\n*   Historical analysis of production times to predict planning\r\n*   eSCPE/MWB = globales Produktionsplanungstool mit hinterlegtem Produktionsequipment (MWB). Sp\u00e4ter soll auch eine Personal Kapazit\u00e4tsplanung dazu kommen. (eSCPE/MWB = global production planning tool with stored production equipment (MWB). Personnel capacity planning should be added later.)",
        "further_ideas": "*   Algorithms support the planner in creating optimized schedules automatically\r\n*   Alerting\r\n*   SAP IBP\r\n*   SAP ePP/DS or MWB und SAP PP (S/4)",
        "effort_quantification": "*   IT Licence cost\r\n*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: 4-12 months depending on site complexity",
        "potential_quantification": "*   REDUCTION OF TIME FOR PRODUCT TRANSFER: (Quantified as Low (days))\r\n*   REDUCTION OF TIME FOR PRODUCT LAUNCH: (Quantified as Low (weeks))\r\n*   REDUCTION OF TOTAL COSTS OF SUPPLY: (Quantified as Medium)\r\n*   QUALITY (RFT): (Quantified as Low)",
        "dependencies_text": "*   Alignment with SCM Stream recommended\r\n*   Dependency/Relation to: MRP Highway (SCM Project)\r\n*   Dependency/Relation to: IT GFS SCM\r\n*   Dependency/Relation to: eSCPE BIO\r\n*   Dependency/Relation to: Spice, Cope (SCM Projects)\r\n*   Dependency/Relation to: OPEX Prime\r\n*   Dependency/Relation to: SCM-Chemie",
        "contact_persons_text": "*   Florian Kache (Head of Supply Chain Excell. & Digital.)\r\n*   GBS: Jonas Ritzer (named by K.Trenz)\r\n*   Judith Kirchner (Head of Production Planning & Scheduling DTM)\r\n*   Bernd Ohse (IT GFS SCM contact)\r\n*   Marinie Voutsina (OPEX Prime contact)\r\n*   Torsten Heinz (SCM-Chemie contact)\r\n*   Local SCM-Heads-Pharma need to nominate participants (e.g., ING: Goran Evdjic or KOR: Georgios Filinis)\r\n*   Irfan Mujkic / Tim Lahmann (for eSCPE/MWB)",
        "related_projects_text": "*   MRP Highway (SCM Project, Florian Kache)\r\n*   IT GFS SCM (Bernd Ohse)\r\n*   eSCPE BIO (Jonas Ritzer)\r\n*   Spice, Cope (SCM, Florian Kache)\r\n*   Biopharma OR-Soft-roll out ongoing (Technology)\r\n*   OPEX Prime (Marinie Voutsina)\r\n*   eSCPE/MWB (Global production planning tool, Irfan Mujkic/Tim Lahmann)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 121,
        "bi_id": "M02",
        "name": "Plant modelling tool",
        "process_step_id": 36,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2\r\nBUSINESS PROBLEM SOLVED:\r\n*   beschleunigte und optimierte Planung neuer Geb\u00e4ude und Anlagen und deren Auslastung (accelerated and optimized planning of new buildings and facilities and their utilization)\r\n*   IU Dev kann besser auf die Ops Anlagen reinmodellieren und planen (IU Dev can better remodel and plan for Ops facilities)\r\n*   das Produkt kommt reifer auf die Anlage (the product arrives more mature at the facility)\r\n*   reduction of high manual risik analysis for aseptic facilities and long lead time",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   beschleunigte und optimierte Planung neuer Geb\u00e4ude und Anlagen und deren Auslastung (accelerated and optimized planning of new buildings and facilities and their utilization)\r\n*   IU Dev kann besser auf die Ops Anlagen reinmodellieren und planen (IU Dev can better remodel and plan for Ops facilities)\r\n*   das Produkt kommt reifer auf die Anlage (the product arrives more mature at the facility)\r\n*   reduction of high manual risik analysis for aseptic facilities and long lead time",
        "target_solution_description": "*   digital twin to simulate a new plant with best utilization",
        "technologies_text": "*   Inosim like simulation tool\r\n*   AR/VR solution",
        "requirements": "*   Digital twin of factory\r\n*   Digital twin of production equipment\r\n*   IT\r\n*   GFE\r\n*   Equipment Supplier",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "medium (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Plant Modelling tool (Inosim) bisher nur f\u00fcr Drug Substance (Bio) auch f\u00fcr Drug Product einsetzen zur Simulation von Betriebsabl\u00e4ufen, Planung, Allokation,... (Use Plant Modelling tool (Inosim), previously only for Drug Substance (Bio), also for Drug Product for simulation of operations, planning, allocation,...)\r\n*   provide digital twin w/ attributes for simulation\r\n*   Vendor co-innovation\r\n*   Simulationsplanung um die Auslastung des Geb\u00e4udes zu berechnen (Simulation planning to calculate building utilization)\r\n*   Transfer and scale up tool for process implementation --> all relevant info like process parameter, equipment data, timeline, plant capacity, waster water, etc. as input\r\n*   Automated suggestion how process runs most efficiently with which equipment; simulation of different process scenarios possible --> output is process suggestion with capacity and raw material planning",
        "further_ideas": "*   small solution Inosim (quick Win) till large vision of digital twin for semi automated transfers (more complex)\r\n*   risk reduction/avoidance (also listed as Qualitative Benefit in image)\r\n*   Aufwand f\u00fcr den risk based approach aseptic (Effort for the risk-based approach aseptic)\r\n*   durch Simulation weniger Try and Error (less trial and error through simulation)\r\n*   Frame-by-Frame risk profiling f\u00fcr das Design von aseptischen Prozessen von Fa. Innerspace: Nicole K\u00f6hler",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): <100K\u20ac for Insosim tool; 1mio\u20ac f\u00fcr die Erstellung der Digital Twin (1mio\u20ac for creating the digital twin); ~500K\u20ac License costs for tools like Inosim for all sites\r\n*   Implementation time: 3 years",
        "potential_quantification": "*   reduction of transfer time due to better data and experience and simulation\r\n*   reduce cycle times for new product in facility to a minumim (right first time) (higher benefit in Pharma compared to Bio)\r\n*   no savings in Supply Chain or logistics, however faster time to market\r\n*   reduce cycle times by 50%",
        "dependencies_text": "*   Same Database as 01. Tools need to be interlinked\r\n*   Dependency/Relation to: ModelX (GFE project)\r\n*   Dependency/Relation to: COMOS (GFE tool/project)\r\n*   Dependency/Relation to: Innerspace (Frame-by-Frame risk profiling)\r\n*   Dependency/Relation to: PharmaPlant-Simulation Tool \"SOL-Ramp-Up-Giotrif\"",
        "contact_persons_text": "*   Chemie/PEC: Pascal Naumann\r\n*   LIL-representative\r\n*   SOL-representative\r\n*   GBS: Enric Pallares (PM)\r\n*   (Thomas Wucherpfenning, Erik Hasenfu\u00df)\r\n*   Plant Modelling Tool Inosim contacts: Stefan Krahulec, Joachim Baer, Thomas Wucherpfennig, Nicole K\u00f6hler\r\n*   ModelX contact: Thorsten von Goessel (GFE)\r\n*   COMOS contacts: Heiko Reitzer, Paul Messenger (GFE)\r\n*   Thomas Wucherpfenning (Global Development CMC Biologicals); Kontakt: Benno Knopf\r\n*   Innerspace contact: Nicole K\u00f6hler\r\n*   PharmaPlant-Simulation Tool contacts: Dr. Karin Winter, Christian Vesper",
        "related_projects_text": "*   Plant Modelling Tool Inosim (Stefan Krahulec, Joachim Baer, Thomas Wucherpfennig, Nicole K\u00f6hler)\r\n*   ModelX (GFE, Thorsten von Goessel)\r\n*   COMOS (Heiko Reitzer, Paul Messenger GFE)\r\n*   Frame-by-Frame risk profiling (Fa. Innerspace: Nicole K\u00f6hler)\r\n*   PharmaPlant-Simulation Tool \"SOL-Ramp-Up-Giotrif\" (Dr.Karin Winter, Christian Vesper)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 122,
        "bi_id": "M03",
        "name": "Real-time process monitoring",
        "process_step_id": 25,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2\r\nBUSINESS PROBLEM SOLVED:\r\n*   early reaction and correction possible in case of negative trends\r\n*   avoid deviations\r\n*   avoid long waiting times in production to clarify issues\r\n*   reduce time and cost consuming analytics by inline testing and monitoring",
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   early reaction and correction possible in case of negative trends\r\n*   avoid deviations\r\n*   avoid long waiting times in production to clarify issues\r\n*   reduce time and cost consuming analytics by inline testing and monitoring",
        "target_solution_description": "*   inline measurements\r\n*   dashboard with parameters relevant for contineous process monitoring\r\n*   alert functionality in case of negative trends",
        "technologies_text": "*   plus10\r\n*   inmation\r\n*   Dataland? for Dashboards?\r\n*   inline measurements and sensors\r\n*   interfacce to PCS (Prozessleitsystem)\r\n*   historian",
        "requirements": "*   inline measurement equipments/sensors\r\n*   Zulassungs\u00e4nderung f\u00fcr Bestandsprodukte wenn ich das ohne QC nutze (Regulatory change for existing products if used without QC)\r\n*   IU Dev\r\n*   GFE\r\n*   QA and QC\r\n*   IT\r\n*   Automatisierer GFE\r\n*   Inmation",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "low (weeks)",
        "reduction_costs_supply": "medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Real-time process monitoring tool that suggests possible waiting positions for extra work due to problems\r\n*   Verkn\u00fcpfung mit Planning und Scheduling (Linkage with Planning and Scheduling)",
        "further_ideas": "*   keine Reagenzien f\u00fcr Analysen (no reagents for analysis)\r\n*   Weniger FTE in QC und IPC (Fewer FTEs in QC and IPC)\r\n*   Reduced reaction time and improved algorithms (more data available)",
        "effort_quantification": "*   Licenses (e.g. SEEQ)\r\n*   IT development\r\n*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): 1m\u20ac invest; 1m\u20ac for sensors\r\n*   Implementation time: 2-5years for all",
        "potential_quantification": null,
        "dependencies_text": "*   n.a.\r\n*   Dependency/Relation to: Lab Integration\r\n*   Dependency/Relation to: Inmation\r\n*   Dependency/Relation to: PAT \"Process Analytic Technology\"\r\n*   Dependency/Relation to: SEEQ\r\n*   Dependency/Relation to: CPM (Continuous process monitoring)\r\n*   Dependency/Relation to: Alfred \"Automatic Long-term Forecasting REsteering Device\"",
        "contact_persons_text": "*   LEAD: Bernhard & Sven W.\r\n*   IT O&L Automation & Integration\r\n*   Chemie/Engineering: Matthias Siefert\r\n*   IT O&L Automation & Integation: Montse\r\n*   Pharma: CPT Solids Factory Ask Joachim Schlosser for participation of Alexander Kron\r\n*   L&I: SOL-representative: Engineering: Erik Straub?\r\n*   CPT SOL: Dietmar Keutel/Felix Antemann\r\n*   GBS: n/a\r\n*   Markus Kirchner (Head of Manufactruing DCO)\r\n*   Sonny Slobota (Inmation contact)\r\n*   Jochen M\u00fcller (PAT SOL contact)\r\n*   Bernhard Pfeuffer (SEEQ contact)\r\n*   Montse (CPM contact)\r\n*   Felix Antemann (Alfred SOL contact)",
        "related_projects_text": "*   Lab Integration\r\n*   Inmation (Sonny Slobota)\r\n*   PAT \"Process Analytical Technology\" (SOL: Jochen M\u00fcller)\r\n*   SEEQ (Bernhard Pfeuffer)\r\n*   CPM (Continuous process monitoring) - Montse\r\n*   Alfred \"Automatic Long-term Forecasting REsteering Device\" (SOL Felix Antemann)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 123,
        "bi_id": "M08",
        "name": "Real-time anomaly monitoring",
        "process_step_id": 25,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Potentielle Prozessprobleme \u00fcber Datensimulation (w\u00e4hrend Produktion) erkennen (Identify potential process problems via data simulation (during production))\n*   Simulation von Prozessschritten zur Verringerung der Laufzeiten (Simulation of process steps to reduce run times)\n*   Anomaly Detection for rapid incident tackling/troubleshooting\n*   Firma Plus10: Erzeugung von dynamisch Events mit techn. Kontext, also konkret gesagt wo in der Schrittkette der Automatisierungstechnik hat sich etwas auff\u00e4llig verhalten bevor es in den Stopp/St\u00f6rung der Anlage ging --> autom. L\u00f6sungssuche aus verschiedenen Wissensquellen (Company Plus10: Generation of dynamic events with tech. context, specifically where in the automation technology step chain something behaved conspicuously before the plant stoppage/malfunction --> autom. solution search from various knowledge sources)\n*   Prozessrobustheit: Datensammlung ISS starten. WSG-Daten kontinuierlich sammeln um Porzess tiefer zu monitoren Abweichungen in der Granulierung zu begegnen. (Process robustness: Start ISS data collection. Continuously collect WSG data to monitor the process more deeply [and] address deviations in granulation.)\n*   AI based process surveillance\n*   automatisierte inline testing (automated inline testing)\n*   Use machine learning and AI algorithms to analyze the collected data and identify patterns or anomalies\n*   Bei Fehlern in der Produktion werden alle relevanten Infos zusammengestellt und den Operatoren/Supervisorn zur Verf\u00fcgung gestellt, um Entscheidungen zu treffen (In case of production errors, all relevant info is compiled and made available to operators/supervisors to make decisions)",
        "further_ideas": "*   Enabled durch 04 (Enabled by 04)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to Use Case 04\n*   Dependency/Relation to ARGUS",
        "contact_persons_text": "*   Bastian Knabe (Head of Engineering Assembly DTM) - Kontakt \u00fcber Markus Kirchner\n*   Thomas Oppolzer (Head of Head of E&T Germany) Kontakt \u00fcber Benno Knopf\n*   ARGUS - Kontakt B. Pfeuffer\n*   IT O&L (Montse & Thorsten)\n*   IT EDP Moritz Schneider\n*   Chemie/Engineering: Bernhard Pfeuffer\n*   GBS: n/a\n*   L&I Data Science: Ogsen Gabrielyan",
        "related_projects_text": "*   ARGUS - Kontakt B. Pfeuffer",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 124,
        "bi_id": "M20",
        "name": "Multi-site comparison for continuous process verification & optimiz.",
        "process_step_id": 27,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\r\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "*   Product-specific work packages across different sites are often the same and can be copied\r\n*   Best-practice sharing between sites for process robustness, performance, changes in process, trending, equipment performance, etc.",
        "target_solution_description": "*   Product and Process specific exchange of data\r\n*   Platform for exchange available\r\n*   Data is easily accessible and can be used from other sites for troubleshooting, data science use cases, performance increase, etc.",
        "technologies_text": null,
        "requirements": "*   Data strategy for access\r\n*   Harmonized structure of data for same products so that data can be used without limitations\r\n*   Governance structure for exchange",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   DP-specific Multi-Site Comparison of IPC & Lab-Data for internal sites & CMO (Multi-Site-CPV)\r\n*   Daten \u00fcber die Netzwerke hinweg nutzen und daraus lernen (contineous improvement across networks) (Use data across networks and learn from it)\r\n*   Process Data Contextualization for Data Science UCs, Troubleshooting & Investigations (Root-Cause-Analysis)\r\n*   Batch comparison, (process improvement Factroy internal and Network)\r\n*   using equipment and production related data to improve performance and quality continously (AI supported)\r\n*   Physico-Chemical-Biological Process Optimization through Data Science (and PAT)\r\n*   data are the foundation for AI improvement opportunities\r\n*   Produktionsdaten Geb\u00e4ude/Standort\u00fcbergreifend zur Verf\u00fcgung stellen um bei Trouble Shooting oder Prozessoptimierung mehr Information zu haben (Make production data available across buildings/sites to have more information for troubleshooting or process optimization)\r\n*   Status Prozes sund Betrieb --> Verf\u00fcgbarkeit aller relevanten Prozess und auch Betriebsdaten (R\u00e4ume, Medien, Geb\u00e4ude,...) in einer \u00dcbersicht (Status process and operation --> Availability of all relevant process and also operational data (rooms, media, buildings,...) in one overview)\r\n*   Alle relevanten Prozess und Maschinendaten inkl. IPC sind in einem System verf\u00fcgbar und k\u00f6nnen nach Bedarf auf versch. Art und Weise ausgewertet werden (All relevant process and machine data incl. IPC are available in one system and can be evaluated in various ways as needed)\r\n*   continous AI supported monitoring of current production data, e.g. rejected material, OP/OEE, output, inline IPC, trends...\r\n*   Increas output through OEE by the use of Eqipment event data augmented by operater input (Damage code)\r\n*   Reduction of destructions/ rejected with the use of detailed mail function event data\r\n*   \"Manuelle eingaben maschinenlesbar standardisieren\" (Standardize manual entries to be machine-readable)",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Use case 04 improves outcome of use case 18. Not necceseralry dependant\r\n*   Dependency/Relation to: Batch Context Egine\r\n*   Dependency/Relation to: Multi-Site-CPV-Comparison-Dashboards (Tableau based on GTDS-data)\r\n*   Dependency/Relation to: GDTS4Future - Multi-Site-CPV-Comparsion Module\r\n*   Dependency/Relation to: Statistical visualisation & usage of Babtec-IPC-data (CPT-Solids)\r\n*   Dependency/Relation to: Global GDTS-Roll-Out\r\n*   Dependency/Relation to: GDTS und GDTS4Future\r\n*   Dependency/Relation to: BI-MES Program: data collection and handover to GDTS\r\n*   Dependency/Relation to: MES PDA: generate Data availability\r\n*   Dependency/Relation to: SMART (Modeling Platform for more yield - Bio)",
        "contact_persons_text": "*   Markus Kirchner (Head of Manufacturing DCO)\r\n*   GBS: Michael Rommerskirchen (GDTS)\r\n*   GBS: Kerstin Trenz (ME / BI-MES)\r\n*   Chemie/Engineering: Matthias Siefert\r\n*   Batch Context Egine contact: Florian H\u00e4rle\r\n*   Multi-Site-CPV-Comparison-Dashboards contacts: Thomas Reischl, Stefan Floercks\r\n*   GDTS4Future contacts: Karin Morch (PL GBS), Michaela Koppers (Customer Perspective)\r\n*   Customers for CPV/GDTS4Future: Local PPT-units worldwide, Global Pharma Network Innovation & Harmonisation (G.Radtke/S.Weber)\r\n*   Statistical visualisation & usage of Babtec-IPC-data contact: Alexander Kron (CPT-Solids)\r\n*   Global GDTS-Roll-Out contact: M.Rommerskirchen\r\n*   Heiko Rengel (HP BioP Execution Excel. & Standard.), Kontakt: Birgit W\u00e4rner\r\n*   Data Stratgy & Science contacts: Andreas \u00d6fner/Michaela Koppers?\r\n*   3PM Representative: Ulrich Kies?\r\n*   GDTS und GDTS4Future contacts: Andreas Oefner, Caroline Becker\r\n*   Sven Weber (Pharma Network Innovation & Harmonisation)\r\n*   Montse for Automation & Integration (Opex Prime)\r\n*   SMART (Modeling Platform for more yield) (Alexander Grauland - Bio)",
        "related_projects_text": "*   Batch Context Egine (Florian H\u00e4rle)\r\n*   Multi-Site-CPV-Comparison-Dashboards Tableau based on GTDS-data (Thomas Reischl, Stefan Floercks)\r\n*   GDTS4Future - Multi-Site-CPV-Comparsion Module (Karin Morch (PL GBS), Michaela Koppers (Customer Perspective))\r\n*   Statistical visualisation & usage of Babtec-IPC-data (CPT-Solids, Alexander Kron)\r\n*   Global GDTS-Roll-Out (M.Rommerskirchen)\r\n*   GDTS und GDTS4Future (Andreas Oefner, Caroline Becker)\r\n*   BI-MES Program: data collection and handover to GDTS (K. Trenz)\r\n*   MES PDA\r\n*   SMART (Modeling Platform for more yield) (Alexander Grauland - Bio)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 125,
        "bi_id": "M23",
        "name": "Global supplier qualification oversight",
        "process_step_id": 39,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3\r\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "Low/medium",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Language model als interface (Language model as interface)\r\n*   One global database for reliable identification of Supplier-Qualification-Data: Which raw material/packaging material is qualified for which Drug Product at which site! This will save tremendous time and effort!\r\n*   Daten sind nicht im Trackwise in n\u00f6tiger Qualit\u00e4t vorhanden (Data is not available in Trackwise in the required quality)\r\n*   Maske / Dashboard auf Trackwise setzen um Daten zentral einfach auswerten zu k\u00f6nnen (Place mask/dashboard on Trackwise to easily evaluate data centrally)",
        "further_ideas": "*   Spezialfall von 25 (Special case of 25)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): Value not specified\r\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   --> Quality? (Interface/Relation to Quality)\r\n*   Schnittstelle Quality (Interface Quality)\r\n*   Dependency/Relation to: Global Material Service Center: Global Excel-Liste\r\n*   Dependency/Relation to: GoTrack SQ-Module",
        "contact_persons_text": "*   Head of HP Global Material Service Center: Pia Steigerwald\r\n*   Head of HP Q Systems & Competence Center: Marcel Krepstakis\r\n*   Head of Product Quality Management: Diana Fladerer (Global Product Quality Leads)\r\n*   GMSC Chemie?\r\n*   GMSC Dortmund?\r\n*   Head of Quality Services BioPharma (Biopharma GMSC): Dr. Michael Dieterle oder Thiemo Kohlsdorf\r\n*   Pharma Network Innovation & Harmonisation: Sven Weber\r\n*   GBS: n/a",
        "related_projects_text": "*   Global Material Service Center: Global Excel-Liste Contact: Pia Steigerwald\r\n*   GoTrack SQ-Module",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 126,
        "bi_id": "M07",
        "name": "Real-time release (incl. Batch record review, Batch release)",
        "process_step_id": 25,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2\nBUSINESS PROBLEM SOLVED:\n*   Highly manual effort for collecting, checking all data from excecuted BR, manual sampling & testing in IPC and QC\n*   Prone for error due to incompliance, wrong evaluation, etc.\n*   Accelerating lot release times",
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   Highly manual effort for collecting, checking all data from excecuted BR, manual sampling & testing in IPC and QC\n*   Prone for error due to incompliance, wrong evaluation, etc.\n*   Accelerating lot release times",
        "target_solution_description": "*   Inline & online sensors and measurements instead of sampling and lab analysis\n*   Release of batch by exception --> all electronic batch data is checked automatically, certificates for release are generated, no manual check necessary when all in specification\n*   Automatic cross-check between eBRs, logbooks, deviations, CAPAs, audit trail, etc.\n*   Trending of parameters is checked automatically\n*   For exception - a human is in the loop for decisions",
        "technologies_text": "*   PAT for relevant process steps --> all CPPs und CQAs have to be linked to an equal technology\n*   Centralized system with all relevant information for batch release\n*   MES, LIMS, ERP, Automation middle ware",
        "requirements": "*   Process analytical technologies (inline/online) are available\n*   Systems for data collection and storing are implemented\n*   Defined interfaces between systems\n*   Batch release software that collects all data\n*   Regulatory framework with authorities is in place\n*   Global definition what leads to an exception with risk evaluation\n*   Trust into system and acceptance of employees have to be there\n*   Clear data strategy: what data/information is needed (based on risk assessment and process FMEA)",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (weeks)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Batch release Prozess vereinfachen und automatisieren (eine Plattform) (Simplify and automate batch release process (one platform))\n*   fully batch record review by exeption\n*   global / central SOP for BRR by exception, MBR design, EQ Logbook review, ...\n*   An integrated execution process and system that can capture and track real-time data, facilitate electronic batch record management, and ensure compliance with regulatory requirements\n*   Batch Record Review by Exception\n*   RbE/ BRR enabled by design and common best practice\n*   release by exception\n*   common understanding of Exception priorities\n*   Inline & Online Measurements => Real time for predictiv steering\n*   Utilize intelligent sensors and systems to collect real-time data during the manufacturing process.\n*   Real-time release with relevant process data\n*   Schnittstelle zu Quality (Interface to Quality)\n*   Realtime Release Testing (RTRT)\n*   Alle Daten die zur Chargenfreigabe erforderlich sind \u00fcber ein System automatisch abgreifbar machen Release by Excepition) (Make all data required for batch release automatically accessible via one system (Release by Exception))\n*   Simples Dashboard f\u00fcr die Chargenfreigabe mit allen relevanten Informationen (in one click) (Simple dashboard for batch release with all relevant information (in one click))",
        "further_ideas": "*   Unified standard for batch release bc/ human is not involved as much as before (also listed as Qualitative Benefit in image)\n*   Positive impact on RFT\n*   Comment Corinna Koch: Pharma Sampling for raw materials was partially electronically done with RapID kind of a Laser Technology which helps in checking purity of products etc. Martin Hennig is working on automized COA checks - maybe align with him to save release time at the lab.",
        "effort_quantification": "*   Neutral when MES is existing\n*   High for MES\n*   Time effort and invest is high bc/ implementation is product and process specific with wet lab experiments and further development\n*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": "*   Minor improvements for transfer and launch bc/ batch release times are not limiting factors for transfer (Repeated)\n*   Reduction in routine production with decrease FTE effort\n*   Faster release --> no lab analysis, etc.",
        "dependencies_text": "*   Schnittstelle zu Quality (Interface to Quality - also mentioned in ideation)\n*   Dependency/Relation to: Release by exception (part of MES DTM)\n*   Dependency/Relation to: Process Analytical Technologies and mechanistical modelling for Column performance and yield increase\n*   Dependency/Relation to: Alfred SOL\n*   Dependency/Relation to: BI-MES BRR by Exception\n*   Dependency/Relation to: RTRT\n*   Dependency/Relation to: RapID/Automated COA checks (Martin Hennig)",
        "contact_persons_text": "*   Kontakt Dortmund: Marie Marenberg (Professional Quality IT Projectmanager DTM - Kontakt \u00fcber Markus Kirchner)\n*   Chemie/PEC: Oliver Br\u00fccher\n*   Chemie/Quality: Markus Wheeldon\n*   Joey Studts (IU, PAT/Modelling contact)\n*   Gang Wang (IU, PAT/Modelling contact)\n*   Martin D\u00f6hms (Alfred SOL contact)\n*   GBS: Kerstin Trenz (BI-MES contact)\n*   GBS: Virginia Hau (QM contact)\n*   Andreas Oefner (RTRT contact)\n*   Markus Kirchner (MES DTM contact for Release by exception)\n*   Martin Hennig (Automated COA checks contact)",
        "related_projects_text": "*   Release by exception (part of MES DTM) - Markus Kirchner\n*   Process Analytical Technologies and mechanistical modelling for Column performance and yield increase (Joey Studts, Gang Wang (IU))\n*   Alfred SOL (Martin D\u00f6hms)\n*   BI-MES BRR by Exception (Kerstin Trenz)\n*   RTRT (Andreas Oefner)\n*   Automated COA checks (Martin Hennig)\n*   RapID technology use (related to Corinna Koch comment)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 127,
        "bi_id": "M09",
        "name": "AR assisted process support (e.g. change-over)",
        "process_step_id": 25,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3\nBUSINESS PROBLEM SOLVED:\n*   Efficiency improvements due easier learning for e.g. operator training or mechanic training",
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   Efficiency improvements due easier learning for e.g. operator training or mechanic training",
        "target_solution_description": "*   At anytime the operator or mechanic has AR-supported insight into the equipment-functionality (explosion drawing 3D) and the next process step.\n*   Can be used for: Troubleshooting, Process Guide, Change-Over-Sequence\n*   Min. 2 Subprocesses: - during set-up - production process",
        "technologies_text": "*   AR-devices\n*   Voice Recognition\n*   Pictures",
        "requirements": "*   Library of digital 3D-Models of Equipments (equipment database)\n*   Videos of process steps are available",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "low (days)",
        "reduction_time_launches": "low (weeks)",
        "reduction_costs_supply": "Medium (Reduced human errors)",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   AR assisted, opt. recorded\n*   AR-supported change over support incl. digital checklists\n*   Change over\n*   AR angeleitete Change Over bei komplexen Prozessen (AR-guided changeover for complex processes)\n*   Photo-Anaysis of finalized set-up to identify errors\n*   Visualisierung der Ablaufplanung (was ist fertig, was muss noch gemacht werden in welcher Reihenfolge) (Visualization of the process plan (what is finished, what still needs to be done in which order))\n*   AR support change over in a smart way. Requirement: Lean GxP-conform master data creation\n*   AR f\u00fcr Assisstenz beim Anbau/Umbau/etc. (AR for assistance with assembly/conversion/etc.)",
        "further_ideas": "*   VR-assisted training for change-overs, maintenance and operation of equipment and processes\n*   Reduced training effort. Less time onsite for real-process training in preperation of transfer.\n*   Mitarbeiter mit einbeziehen (Akzeptanz) (Involve employees (acceptance))\n*   Reduced human errors (also noted in supply cost reduction)",
        "effort_quantification": "*   IT licence\n*   Internal Labour efforts\n*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Pilot: 1 year",
        "potential_quantification": "*   Quicker equipment trouble-shootings\n*   Cycle time decrease\n*   Reduced down times",
        "dependencies_text": "*   Dependency/Relation to: Pharma-Pilot AR Change-Over packaging & remote maintenance \"SmartGlasses\" Factory Solids (stopped)\n*   Dependency/Relation to: CoE Mixed Reality",
        "contact_persons_text": "*   GBS: Simon Maus (ME)\n*   Chemie/Produktion: Cord Tomforde/J\u00f6rg Braun\n*   Pharma-Pilot contact: Dr. Karin Winter\n*   CoE Mixed Reality contact: Tobias Rodenfels",
        "related_projects_text": "*   Pharma-Pilot AR Change-Over packaging & remote maintenance \"SmartGlasses\" Factory Solids (stopped), Dr.Karin Winter\n*   CoE Mixed Reality (Tobias Rodenfels)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 128,
        "bi_id": "M11",
        "name": "Automated testing and release of cleaning",
        "process_step_id": 37,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\r\nBUSINESS PROBLEM SOLVED:\r\n*   efficient cleaning process\r\n*   In Bio cleaning process is done automatically with inline testing, monitoring and release. In Pharma this is a manual process (cleaning, sampling, analytics, release in iteration) or we clean with fix volume of water according to SOP independend of volume needed (maybe less)\r\n*   reduce failure in QC",
        "wave": "Waiting list",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "*   efficient cleaning process\r\n*   In Bio cleaning process is done automatically with inline testing, monitoring and release. In Pharma this is a manual process (cleaning, sampling, analytics, release in iteration) or we clean with fix volume of water according to SOP independend of volume needed (maybe less)\r\n*   reduce failure in QC",
        "target_solution_description": "*   Inline measurement and release for cleaning process",
        "technologies_text": "*   sensors\r\n*   MES for implementation into MBR\r\n*   PLS\r\n*   GFE\r\n*   MBR Experts",
        "requirements": "*   Quality to qualify inline testing and release and process validation\r\n*   Testing equipment and algorithm installed",
        "relevants_text": "Bio, Pharma, Chem., Launch, Routine",
        "reduction_time_transfer": "low (days)",
        "reduction_time_launches": "low (weeks)",
        "reduction_costs_supply": "medium/high",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Autom. Testung und Freigabe \u00fcber TOC-Analyse nach Reinigung (Autom. testing and release via TOC analysis after cleaning)\r\n*   Approval Process by exception\r\n*   Enhanced final rinse through online analytics (e.g. UV/VIS/IR such as Roche is doing)\r\n*   Reinung bis TOC passt spart Reinigungsvalidierungsaufwand (Cleaning until TOC fits saves cleaning validation effort)\r\n*   Autonomous Clean/Sterilize-In-Place with Integrated Multi-Sensor Verification",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\r\n*   Invest (Capex): invest in new sensors (~100K per sensor); 50k\u20ac for installation and implementation\r\n*   Implementation time: ~1year incl. leadtime to purchase and implement sensor (maintenance slot)",
        "potential_quantification": "*   reduction of manual QC process by 80-90% due to automated process",
        "dependencies_text": "*   Dependency/Relation to: Online TOC Biberach",
        "contact_persons_text": "*   Chemie/PEC: Thomas Nicola\r\n*   Online TOC Biberach contacts: Antonio Sisto/Markus Kasper\r\n*   GBS: Kerstin Trenz (ME -> dig. Release of cleaning)",
        "related_projects_text": "*   Online TOC Biberach (Antonio Sisto/Markus Kasper)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 129,
        "bi_id": "M15",
        "name": "Company-wide equipment database",
        "process_step_id": 26,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\nBUSINESS PROBLEM SOLVED:\n*   During transfer/launch equipment information from sending site are available and reduce manual effort for exchange/data collection\n*   Check if usable equipment on receiving site is available can be automated --> groundwork for risk assessment during process implementation\n*   Transfer of qualification and validation plans/procedures --> like by like reduces effort\n*   Helps for standardization of equipments (Flottenbildung)",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   During transfer/launch equipment information from sending site are available and reduce manual effort for exchange/data collection\n*   Check if usable equipment on receiving site is available can be automated --> groundwork for risk assessment during process implementation\n*   Transfer of qualification and validation plans/procedures --> like by like reduces effort\n*   Helps for standardization of equipments (Flottenbildung)",
        "target_solution_description": "*   One globally accessible database where all production equipment is entered with performance data\n*   Building of clusters for different types of equipments\n*   Standardized equipments, vendors in parts (where feasable)\n*   Database has link to equipment specific qualification documents e.g. URS, IQ, OQ, PQ",
        "technologies_text": "*   GBS/SAP\n*   DIVAL\n*   COMOS (?)\n*   BIgCAL\n*   Wartungspl\u00e4ne\n*   Geht inhaltlich in Richtung Maintenance (Content goes towards Maintenance)",
        "requirements": "*   Database or tool that links different databases with important info is available\n*   Clear data strategy what equipment performance info is needed\n*   Clear overall qualification guidelines that enable the use of a reduced qualification strategy on existing equipment",
        "relevants_text": "Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Company-wide available equipment overview/list incl. modifications and standards for certain purposes\n*   Standardisierung / Neubeschaffung (Standardization / New Procurement)\n*   --> Site und Factory \u00fcbergreifende Datenbank \u00fcber techn. Equipment und techn. Daten (URS,TS, Lieferant,...) (--> Cross-site and factory database of tech. equipment and tech. data (URS, TS, Supplier,...))\n*   usage of standardized equipments with centrally defined maintenance procedures\n*   Standardisierung von Equipment um Standort\u00fcbergreifenden Einsatz zu sichern. (Standardization of equipment to ensure cross-site deployment.)\n*   Standort\u00fcbergreifende Equipmentliste um Einsatz im Netzwerk zu erm\u00f6glichen (Cross-site equipment list to enable deployment in the network)\n*   standardized Equipment (Hardware / Software)\n*   Harmonisierte Datenbank f\u00fcr Equipments --> Qualifizierungsdaten, etc. dass wenn \u00e4hnliches Equipment angeschafft wird, Arbeit reduziert werden kann (Harmonised database for equipment --> qualification data, etc. so that if similar equipment is purchased, work can be reduced)\n*   Globaler Leistungskatalog f\u00fcr Equipments --> Stammdaten \u00fcber Equipment einsehbar --> Mehr Austausch/Synergien (Global performance catalog for equipment --> master data about equipment visible --> More exchange/synergies)\n*   centralized equipment data base across sites\n*   Globale Produktionsplanung um \u00fcbergreifend Equipment einsetzen zu k\u00f6nnen. (Global production planning to be able to use equipment across sites.)\n*   AI um einfacher an Informationen zu Equipments zu kommen (Equipedia) (AI to get information about equipment more easily (Equipedia))\n*   Beim Eintragen: Vorschlagen von \u00e4hnlichen Equipments (When entering: Suggest similar equipment)\n*   AI macht Vorschl\u00e4ge wenn es z.B. Equipments oder Probleme, oder Best practices in anderen Standorten bereits gibt (AI makes suggestions if, e.g., equipment or problems, or best practices already exist at other locations)",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to: GFE ?\n*   Dependency/Relation to: Equipedia\n*   Dependency/Relation to: DIVAL\n*   Dependency/Relation to: BIgCAL (mentioned in technology)\n*   Dependency/Relation to: COMOS (mentioned in technology)",
        "contact_persons_text": "*   GFE ?\n*   Chemie/Engineering: Matthias Hollinka\n*   Equipedia contact: Oliver Gluth\n*   DIVAL contacts: Yaeli Valdes, Sascha Prigge\n*   GBS: Enric Pallares (PM) (BIgCAL contact from previous UC)",
        "related_projects_text": "*   Equipedia (Oliver Gluth)\n*   DIVAL (Yaeli Valdes, Sascha Prigge)\n*   BIgCAL (Enric Pallares)\n*   COMOS (Contacts from previous UCs: Heiko Reitzer, Paul Messenger GFE)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 130,
        "bi_id": "M16",
        "name": "Assisted deviation and CAPA management",
        "process_step_id": 27,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "high",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   speed up deviation and CAPA management by real-time available data pool\n*   AI agent collects data for deviation management.\n*   seamless traceability of the products (current production: where in which status, complaint/ deviation: when, who, where...)\n*   Creation of summaries\n*   Interviews f\u00fchren (Conduct interviews)\n*   One-pager aus Audits erstellen \u00fcber AI (Create one-pager from audits via AI)",
        "further_ideas": null,
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   \u00c4hlich zu 23, aber unterschiedl. Use Cases. Austausch n\u00f6tig bei Ausarbeitung (Similar to 23, but different Use Cases. Exchange necessary during elaboration)\n*   Schnittstelle zu Quality (Interface to Quality)\n*   Dependency/Relation to: Dataland Self Service\n*   Dependency/Relation to: Quality Workshop\n*   Dependency/Relation to: IDA (BI X)\n*   Dependency/Relation to: Deviation 2.0 in Trackwise\n*   Dependency/Relation to: GBS: Yaeli Valdes (QA/GoTrack)",
        "contact_persons_text": "*   LEAD: Oliver Gluth + Quality Contact (ggf. Susanne Berger)\n*   SOL: Compliance + CPT Ask Shoaib Rana\n*   Andreas Oefner (Dataland Self Service contact)\n*   IT EDP (Dataland Self Service contact)\n*   Susanne Berger (Sen QA Man Discrep&CAPA Mgmt Processes)\n*   Sasha Grauland (Bio Wien)\n*   Chemie/Quality: Markus Wheeldon\n*   Adrian Siwek (Compliance Officer) - Kontakt \u00fcber Markus Kirchner\n*   Alexander Krauland (IDA contact)\n*   Pharma: Compliance-Perspective/CPT Solids ? Ask Joachim Schlosser\n*   Tatjana Popara (Deviation 2.0 contact)\n*   GBS: Yaeli Valdes (QA/GoTrack)",
        "related_projects_text": "*   Dataland Self Service (Andreas Oefner together with IT EDP)\n*   Quality Workshop\n*   IDA (BI X, Alexander Krauland)\n*   Deviation 2.0 in Trackwise (Tatjana Popara)\n*   GBS: Yaeli Valdes (QA/GoTrack)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 131,
        "bi_id": "M19",
        "name": "Automated creation of approval documents",
        "process_step_id": 27,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   AI zur automatischen Erstellung von Dokumenten im Registrierungsprozess (AI for the automatic creation of documents in the registration process)\n*   Autom. Erstellung von Zulassungsdokumenten auf Basis der Entwicklungs-, Produktionsdaten der MBRs, SOPs, etc. (Autom. creation of registration documents based on development, production data from MBRs, SOPs, etc.)",
        "further_ideas": "*   Innovation Idea available? (Oliver Gluth) Comet? Substrate?",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Schnittstelle Quality / RA... (Interface Quality / RA...)\n*   Dependency/Relation to: Implementation of DocuVera CMC Mgmt.",
        "contact_persons_text": "*   GBS: n/a\n*   Chemie/Engineering: Bernhard Pfeuffer\n*   Beatrix Metzner (Head of HP CMC Management Bio); Kontakt: Birgit W\u00e4rner\n*   Global Regulatory Affairs: Head of GL Operations & Digitalisation: Niklas J\u00e4hnich\n*   Oliver Gluth (for Innovation Idea)",
        "related_projects_text": "*   Implementation of DocuVera CMC Mgmt. (Niklas J\u00e4hnich)\n*   Possibly Comet? Substrate? (mentioned in Further Ideas)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 132,
        "bi_id": "M21",
        "name": "Digital onboarding plan",
        "process_step_id": 39,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   digitaler Einarbeitungsplan mit digitalen Unterschriften (digital onboarding plan with digital signatures)\n*   LOS Trainings and SOP assigned based on role, job desctription, real need and when needed\n*   Kein physischer Zettel mehr (No more physical paper)\n*   Flexible Oberfl\u00e4che, in der Coach und FK mit MA den individuellen plan festlegen/ anpassen kann. (\"Teil von Mitarbeiter-Pass\") (Flexible interface where coach and manager can define/adjust the individual plan with the employee. (\"Part of employee passport\"))\n*   Was ist Schulungen wirklich n\u00f6tig und in welcher Reihenfolge? LOS Marathon f\u00fcr neue MA drastisch reduzieren!!! (Which trainings are really necessary and in which order? Drastically reduce the LOS marathon for new employees!!!)",
        "further_ideas": "*   Comment Corinna Koch: Automated Onboarding Plan was also tested via our existing tools - however it wasnt implemented. Check with Anja F\u00e4rber or me.\n*   Evtl. Verkn\u00fcpfung zu BI University? (Viola Meisterling, HR) (Possible link to BI University?)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to BI University?",
        "contact_persons_text": "*   LEAD: Oliver Gluth\n*   Chemie/PEC: Sylvia Engler\n*   GBS: n/a or only for global system onboarding\n*   Anja F\u00e4rber (related to comment)\n*   Corinna Koch (related to comment)\n*   Viola Meisterling (HR, for BI University link)",
        "related_projects_text": "*   Previous test of Automated Onboarding Plan (Check with Anja F\u00e4rber or Corinna Koch)\n*   BI University (Viola Meisterling, HR)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 133,
        "bi_id": "M25",
        "name": "AI supported knowledge management",
        "process_step_id": 39,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "medium (2-3 FTE)",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Knowledgemanagement Tool (google search for SOP; tech. Doc's,...)\n*   Knowledge Management\n*   KI unterst\u00fctztes Q & A Tool f\u00fcr Mitarbeiter aufsetzen damit sie gezielte Fragen zu Ablauf und Besonderheiten gezielt abfragen k\u00f6nnen (Set up AI-supported Q & A tool for employees so they can ask specific questions about processes and specifics)\n*   Education and empowerment to upskill: not everyone has their own computer, therefore sometimes difficult to enable the usage of e.g. BI University. Mostly native speakers lacking English skills.\n*   SOP-Knowledge-Management Graph- Tool f\u00fcr Veeva: Intuitiv zu bedienende Visualisierung der Hierarchie und des inhaltlichen und Zusammenhangs von SOPen und Anlagen. (Level: Operator, Compliance, BL, QA...) (SOP Knowledge Management Graph Tool for Veeva: Intuitively usable visualization of the hierarchy and the content and context of SOPs and facilities. (Level: Operator, Compliance, BL, QA...))\n*   Standardisierung von Trainings, Knowledge Management (Standardization of training, Knowledge Management)\n*   -->Datenbank mit Trainingsunterlagen (z.B. Reinigung, Desinfektion, Umkleideprozedere) (-->Database with training documents (e.g. cleaning, disinfection, changing procedures))\n*   --> Standard Prozess = Grundlage (--> Standard process = basis)\n*   use of genAI that employees can easily find answers to their day to day questions\n*   Digital logbook with lessons from previous changeover\n*   Consider as capability in continuous changeover optimization\n*   AI based training",
        "further_ideas": "*   Maybe Enterprise Knowledge Graph Browser is a suitable application for Veeva-SOP-data hierarchie visualisiation? (ScIX-Project Ulrich Kies already uses EKG-Browser)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   IT O&L Compliance\n*   Dependency/Relation to EKG-Browser\n*   Dependency/Relation to ScIX-Project\n*   Dependency/Relation to iQNow, Chat GPT, Apollo\n*   Dependency/Relation to Frame-by-Frame risk profiling (Innerspace)\n*   Consider as capability in continuous changeover optimization (UC12)",
        "contact_persons_text": "*   IT O&L Compliance (Dept/Group?)\n*   EKG-Browser Contact: Dr. Ulrich Kies\n*   Chemie/PEC: Pascal Naumann\n*   GBS: n/a\n*   Oliver Gluth (iQNow, Chat GPT, Apollo contact)\n*   Nicole K\u00f6hler (Innerspace contact)",
        "related_projects_text": "*   EKG-Browser (Dr. Ulrich Kies)\n*   ScIX-Project (related to EKG Browser, contact Dr. Ulrich Kies)\n*   iQNow, Chat GPT, Apollo (Oliver Gluth)\n*   Frame-by-Frame risk profiling f\u00fcr aseptsiche Prozesse von Fa. Innerspace als Input f\u00fcr MBR, SOPn, Trainings: Nicole K\u00f6hler",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 134,
        "bi_id": "QC13",
        "name": "One LES (Lab Execution System) Guided Workflow",
        "process_step_id": 44,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Description: Implement guided workflows within a unified Lab Execution System (LES) for easy sample testing processes, ensuring user-friendly interfaces and automated data entry.\n*   Key Features: Predefined templates for sample testing. Automated data entry and validation. User-friendly interface for seamless workflow navigation.",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   system based instruction (recipe) and documentation of preparation\n*   harmonized global recipe for AMET (e.g. Lab4U)\n*   One LES (Lab Execution System) Guided Workflow\n*   Digital Workflow for preparation work/equiping automated systems\n*   Guided workflows for sample/reagent preparation\n*   Standardized preparation templates\n*   Guided Workflows (if not fully automated) Display of necessary settings / adjustments ... for staff. Display of \"how to...\" stepby step (Worker assitance)\n*   LES\n*   One cockpit/system connected with all equipment software solutions, guiding through the analysis with online checks.\n*   Description: Implement guided workflows within a unified Lab Execution System (LES) for easy sample testing processes, ensuring user-friendly interfaces and automated data entry. Key Features: Predefined templates for sample testing. Automated data entry and validation. User-friendly interface for seamless workflow navigation.\n*   harmonized methods for lab execution across BUs > system supported detection of deviations\n*   digital guided workflows with review by exception --> Interface from Lab execution system\n*   Separate UX/UI from used Tools and EQs through Architectural Connectivity Layer. Interoperability for used solutions and Standard-Workflowbased-HMI for Operators\n*   User interface supporting different testing methods/software\n*   One harmonized UI for the user.\n*   one UI for end users for test preparation and execution independent from the used system in the background",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium, Hard",
        "potential_quantification": "High",
        "dependencies_text": "n.a.",
        "contact_persons_text": "n.a.",
        "related_projects_text": "*   DigiLab Program ( Jennifer Seefeldt / David Pinto)\n*   AMES (Jennifer Seefeld, Klaudia Knoll , Lab4You/Lab4You Evolution Yvonne Kuehne, Patrick Stetzenbach, Raimund Haug, Klaudia Knoll)\n*   Project: Lab4U Evolution Phase 1 (67333) Background: Lab4U has been successfully transferred and enhanced functionality from MyLab to GBS SAP United Platform and in addition included a stepwise guidance for the analyst through the system. However, additional functionality such as direct equipment connection, certain reports was not implemented yet Objectives:",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 135,
        "bi_id": "M24",
        "name": "AI Workplace assistance",
        "process_step_id": 39,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list\nBUSINESS PROBLEM SOLVED: (empty)",
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Pharma, Chem., Device, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (weeks)",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   Q & A f\u00fcr den Operator zur Ungterst\u00fctzung im Prozess (Q & A for the operator for support in the process)\n*   AI support for fast finding of information, e.g. Vault, technical documentation...\n*   Process CoPilot: An AI agent that understands the process, the MBR, SOPs, and actual process data can provide employees with context-sensitive assistance\n*   KI f\u00fcr Vault Quality (IQ Now?) (AI for Vault Quality (IQ Now?))\n*   availability of learning videos, training materials and SOPs connected with AI chat\n*   AI-supported knowledge database for Incident Management\n*   MyPersonal AI-Knowledge Support: System\u00fcbergreifender AI-Agent, der in SOPen und Knowledge-Dokumenten f\u00fcr mich Informationen recherchiert. (Cross-system AI agent that researches information for me in SOPs and knowledge documents.)\n*   AI Agent, who is able to save time in SOP-reading, by verbally explaining the relevant content in 1.) a summary or 2.) a detailed explanation.",
        "further_ideas": "*   Innovation idea? Oliver Gluth (Equipedia, etc.)",
        "effort_quantification": "*   Operating cost (Opex): Value not specified\n*   Invest (Capex): Value not specified\n*   Implementation time: Value not specified",
        "potential_quantification": null,
        "dependencies_text": "*   Dependency/Relation to IQ Now in Vault Quality\n*   Dependency/Relation to Equipedia (mentioned in Further Ideas)",
        "contact_persons_text": "*   Adrian Siwek (Compliance Officer) - Kontakt \u00fcber Markus Kirchner\n*   Chemie/PEC: Pascal Naumann\n*   GBS: n/a\n*   Oliver Gluth (IQ Now / Innovation Idea contact)",
        "related_projects_text": "*   IQ Now in Vault Quality --> Oliver Gluth\n*   Equipedia (mentioned in Further Ideas, contact Oliver Gluth from UC16)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 136,
        "bi_id": "QC03",
        "name": "Standardized QC Ordering System",
        "process_step_id": 2,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Waiting list",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   high diversity of system, hindering standardization\n*   100% manual process today with lots of effort\n*   if material not available in system it need to be created manually\n*   everything possible will be purchased which leads to higher costs\n*   long material availability, delivery time\n*   minimum stock not defined and traceable\n*   Manual effort to attach CoAs from supplier",
        "target_solution_description": "*   one global sourcing process and system for Lab Material with standard catalogue\n*   inventory management system to track minimum stock level and to trigger automated purchasing in case that minimum stock level is achieved\n*   Automated CoA attachment to purchase (batch, Haltbarkeit, .....)",
        "technologies_text": "*   SAP QM, weBuy, CoA intergration project (xml)\n*   barcode solution to document materials used in the Lab\n*   interface to supplier systems",
        "requirements": "*   consolidate and harmonise material already in use\n*   global standard SOP to support it\n*   site optimum versus Boehringer optimum?",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Implement a governance and a standardized approach for ordering reagens/material for the laboratories. Share information on supplier status or better - only reagens/material from valid supplier can be ordered.\n*   Description: Implement a standardized system for ordering and managing quality control materials and supplies.\n*   Key Features: Centralized ordering platform for QC materials, Automated inventory tracking and replenishment, Integration with quality management systems, Real-time order status updates and notifications\n*   Harmonized ordering process via a central system/hub/team\n*   better pricing power, to be evaluated\n*   reduce complexity in recipes in lab4you\n*   same for all sites, this reduces complexity and transfer effort",
        "further_ideas": "n.a.",
        "effort_quantification": "Easy; Implementation costs to design and implement solution on a global level; Operating cost (Opex): Invest (Capex): Implementation time: 6-12 month",
        "potential_quantification": "Medium",
        "dependencies_text": "supplier offer information on their material, would be great to integrate this information; Lab4you; IT, GBS, Source2pay; country specific/Tax topics??",
        "contact_persons_text": "n.a.",
        "related_projects_text": "*   digital vendor CoA transfer initiative already planned in Quality roadmap (Sandra Diebel, Virginia Hau)\n*   lab4you (Patrick Stetzenbach, Yvonne K\u00fchne, Virginia Hau)\n*   DigiLab program ( Jennifer Seefeldt, David Pinto )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 137,
        "bi_id": "QC01",
        "name": "Integrated Lab Planning & Scheduling and Management System",
        "process_step_id": 2,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   No forecast available at quality unit level\n*   no transparency\n*   no scheduling tool for daily work\n*   manual planning steps, meetings, high effort for replanning on case of events",
        "target_solution_description": "*   capacity planning in team/expert level\n*   connect to shift planning and production planning\n*   stability testing planning\n*   planning of equipment and their status\n*   Description: Develop a unified system for comprehensive lab scheduling, predictive adjustments, priority-based task allocation, and equipment utilization tracking.\n*   Key Features: Centralized scheduling dashboard, Predictive scheduling and adjustments, Priority-based task allocation, Equipment utilization tracking, Integration with other departments, Real-time notifications",
        "technologies_text": "*   OR Soft\n*   MWB\n*   SAP/QM (LIMS data)\n*   successfactor\n*   OR Soft lab planning\n*   shift planning/Personaleinsatzplanung)\n*   interfaces / seamless integration between the systems",
        "requirements": "*   harmonized SCM /operations planning\n*   working time per inspection and throughput times for testing",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "Low (up to 0,5 FTE per lab for planning)",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   AI- enabled scheduling and capacity planning for QC (e.g. Binocs - bluecrux)\n*   analyze (AI based) use of equipment to predict bottlenecks\n*   Automated Scheduling: AI Algorithms: Use of AI to optimize scheduling based on resource availability, priority tasks, and deadlines. Conflict Resolution: Automated detection and resolution of scheduling conflicts.\n*   AI supported planning: Planning and adjustments need to be automatically transferred into the respective planning tools\n*   Software for Planning with data about throughput times for staff, equipment and consumables offering a interface to production planning. It should also reflect unplanned unavailabilities.\n*   Integrated and connected planning tools allow long term planning of lab resources and timely adjustments if needed\n*   Personell & equipment utilization forecast and planning tool per lab, department, site to reduce costs\n*   online QC planning + scheduling based on production plan, incoming goods, stabilities, inspection plans, equipment activities, training + available resources in labs supported by AI with a easy to use frontend including a retrospective evaluation of plan vs. reality\n*   Drag-and-Drop Functionality: Easy scheduling with drag-and-drop features for tasks and resources.\n*   Standardistation of Activities and recources for mudular planning. e.g. \"Density-Check - 20mins\", \"Documentation Density Check - 5mins\"\n*   Feedback loops: The lab resources need also to be displayed for release planning to ensure reliable timelines\n*   Database with all needed resouces (FTE, chemicals, equipment etc.) for flexible planning in the laboratory area including unexpected influences for short term planning\n*   Real-Time Data Integration: Live Updates: Integration with lab equipment and inventory systems to provide real-time data on resource availability and usage. Analytics: Tools for analyzing data trends and making informed decisions.\n*   Lab resource database: For precise planning the Lab resources need to be available for the planning tools on a high detailed level\n*   a retrospective evaluation of plan vs. reality\n*   Display of alternative scenarios, e.g. if EQ is ooo during workflow, if it can be done on several EQs\n*   User-Friendly Interface: Dashboard: A central dashboard displaying key metrics, schedules, and alerts. Drag-and-Drop Functionality: Easy scheduling with drag-and-drop features for tasks and resources.\n*   1) Lab Planning & Scheduling process harmonization, identifying requirements, needs, contributing factors and data flows.\n*   production plan connected and used as basis for planning of needed equipment\n*   global tool for production planning to support a global tool for QC planning & scheduling\n*   Assign multiple user to the same task\n*   Day to day planning: The current tasks need to be clearly visible to the lab personell\n*   Planning tool should contain all labs\n*   Availability Check e.g. STATUS in use, in maintenance, in cleaning ... e.g. Material material available, enough available, Reorder ..\n*   Interface between production planning and QC planning tool\n*   optimization of capacity for method (e.g. AI based)\n*   efficient resource planning for transfer\n*   resources utilization optimized\n*   better transparency for annual discussion\n*   less errors due to reprioritization\n*   Qualitative Benefits: employee satisfaction as we avoid rescheduling (stress), less human failures, better planning quality, less reschedules",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): Invest (Capex): Implementation time: 1-2 years for template (depending on mindset + change impact)",
        "potential_quantification": "Medium; up to 0,5 FTE per lab for planning",
        "dependencies_text": "licence costs; IT, GBS",
        "contact_persons_text": "*   Sonja Br\u00fcnen\n*   Xavier Rivera Martinez\n*   Julia Tolle\n*   Chris Strati",
        "related_projects_text": "*   evaluation of user requirements lab planning/scheduling (Julia Tolle)\n*   shift planning (Klaus Peter Krause)\n*   SCPE/MWB for BIO (Jonas Ritzer)\n*   GBS united Germany migration of CSI solution (Virgina Hau, Kitty Kientzler)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 138,
        "bi_id": "QC09",
        "name": "Automated Sample Tracking",
        "process_step_id": 21,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Waiting list",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Description: Develop an automated system for tracking samples using e.g. RFID to enhance efficiency and accuracy.\n*   Key Features: tagging of samples, Real-time tracking and location updates, Integration with lab and inventory systems, Alerts for sample movement and status changes",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": null,
        "ideation_notes": "*   Solution could be camera / barcode / ...\n*   Automated Sample Tracking\n*   Guided workflow will ensure proper sample condition and prevent further steps to be processed\n*   Description: Develop an automated system for tracking samples using e.g. RFID to enhance efficiency and accuracy. Key Features: tagging of samples, Real-time tracking and location updates, Integration with lab and inventory systems, Alerts for sample movement and status changes\n*   traceability throughout the entire lifecycle of the sample\n*   digital localization of samples in fridges, including overview on disposable samples (e.g. via simple check-in app or fully automated)\n*   Sample Data only needs to be reviewed if anything out of the ordinary happens\n*   Automated sample tracking based on e.g. RFID tags while beeing transported.\n*   automated sample tracking with RFID or other suitable technologies\n*   Sample memory\n*   Labeling of samples guaranteeing track (and trace)\n*   Samples are atomatically tracked and warnings are triggered if handled/stored incorrectly\n*   alarm when conditions or limits are violated.",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "n.a.",
        "contact_persons_text": "*   Business / Process needs: Tobias Wenner, Niko Manderscheid\n*   C. Dechow",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 139,
        "bi_id": "QC12",
        "name": "Production-Lab Interface Integration",
        "process_step_id": 21,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": null,
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   different UI's for several softwares\n*   high training effort for softwares\n*   system breaks\n*   reduction of licence costs\n*   IPC result transfer from SAP/QM to MES\n*   important foundation for digital initiatives in the labs",
        "target_solution_description": "*   integration SAP/QM in MES systems",
        "technologies_text": null,
        "requirements": "*   system access to software of suppliers",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   Production monitoring in regards \"Live-Tracking\" of a Batch (Status of Samples) for e.g. trending (Live-influence on Batch). --> Manufacturing\n*   Asset Administration Shell\n*   different UI's for several softwares\n*   high training effort for softwares\n*   system breaks\n*   reduction of licence costs\n*   IPC result transfer from SAP/QM to MES\n*   important foundation for digital initiatives in the labs\n*   Interface between production and Lab software e.g. for documentation of sampling\n*   Sample data are fed back to manufacturing systems\n*   integration SAP/QM in MES systems\n*   system access to software of suppliers\n*   sampling/labelling in production for operators in MES, but data is transferred to LIMS\n*   Description: Develop a seamless interface between production and lab software to automate the process of sending samples for analysis.\n*   Key Features: Standardized protocol for interfacing with Laboratory Information Management Systems (LIMS), Automated sample transfer from production to lab, Real-time data synchronization between production and lab systems, Error detection and correction mechanisms",
        "further_ideas": "enabler for most of the automation use cases in Quality and unified user interface for employees",
        "effort_quantification": "Medium",
        "potential_quantification": "High",
        "dependencies_text": "see use case 11",
        "contact_persons_text": "see use case 11",
        "related_projects_text": "DigiLab program -> DigiEngine-> IT Architercture Stream ( Jennifer Seefeldt, David Pinto )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 140,
        "bi_id": "QC14",
        "name": "Robotic Sample Preparation and Testing Execution",
        "process_step_id": 44,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 1",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": "*   High manual effort\n*   Accuracy depending on human factor\n*   lab buildings are out of life..",
        "target_solution_description": "*   Should be conctet into the AMET layer\n*   Roboter for sample preparation and inspection execution\n*   Visual Inspection",
        "technologies_text": "*   PoC robotics for sample preparation (\"chemspeed\") https://www.chemspeed.com/workflow/sample-preparation/\n*   Lab Robot/Cobot https://www.laborpraxis.vogel.de/roboter-mausern-sich-zu-wertvollen-laborhelfern-a-66d19cf335a5a2974783cd2cf582fb87/",
        "requirements": "*   we need a labaroty design for the future as a target\n*   limited space in current lab buildings to be considered\n*   Robotic Hardware: Advanced robotic systems capable of precise sample handling.\n*   Automation Software: Software to control robotic systems and automate testing processes.\n*   Laboratory Management System Integration: Ensure compatibility with existing laboratory management systems.\n*   Precision Instruments: High-accuracy instruments for testing execution.",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Description: Automate sample preparation and testing execution using robotics and advanced automation technologies.\n*   Key Features: Robotic systems for sample handling and preparation. Automated testing execution with precision instruments. Integration with laboratory management systems for seamless operation.\n*   Robotic Sample Preparation and Testing Execution\n*   High manual effort\n*   Accuracy depending on human factor\n*   lab buildings are out of life..\n*   Modular (repository) based robotics solution for sample preparation for analysts (drag and drop)\n*   Workflows based on automated transkript of Testing specifications are used to control robotics\n*   Automated preparation of stock solutions by robotics\n*   automation for sample preparation e.g. robotics\n*   Should be conctet into the AMET layer\n*   Roboter for sample preparation and inspection execution\n*   Robotic Systems: Implement robotic systems to automate sample and Test preparation, reducing human error and increasing efficiency.\n*   automated test execution where beneficial\n*   Activity feedback to planning / scheduling (ready, in progress, done...)\n*   Visual Inspection\n*   we need a labaroty design for the future as a target\n*   automated preparation of e.g. solvents and mobile phases\n*   Automated Pipetting: Use automated pipetting systems to ensure precise and consistent sample volumes.\n*   Lab Robot/Cobot https://www.laborpraxis.vogel.de/roboter-mausern-sich-zu-wertvollen-laborhelfern-a-66d19cf335a5a2974783cd2cf582fb87/\n*   Robotic Systems: Implement robotic systems to automate sample and Test preparation, reducing human error and increasing efficiency.\n*   PoC robotics for sample preparation (\"chemspeed\") https://www.chemspeed.com/workflow/sample-preparation/\n*   limited space in current lab buildings to be considered\n*   Robotic Hardware: Advanced robotic systems capable of precise sample handling.\n*   Automation Software: Software to control robotic systems and automate testing processes.\n*   Laboratory Management System Integration: Ensure compatibility with existing laboratory management systems.\n*   Precision Instruments: High-accuracy instruments for testing execution.\n*   help to reduce lab headcount to prepare for deografical change\n*   potential to save millions\u20ac with insourcing of expensive external QC\n*   competitive with external labs\n*   less human error\n*   24/7 inspection possible",
        "further_ideas": "Logos and links for Chemspeed and LaborPraxis (see Technologies)",
        "effort_quantification": "Medium; Operating cost (Opex): Invest (Capex): Implementation time: 12-18month",
        "potential_quantification": "High; help to reduce lab headcount to prepare for deografical change; potential to save millions\u20ac with insourcing of expensive external QC; competitive with external labs; less human error; 24/7 inspection possible",
        "dependencies_text": "IT/GBS; Robots",
        "contact_persons_text": "*   Patrick Stetzenbach (they evaluated Roboter solution)\n*   Carsten Haecker (CSI)\n*   Lab4you Team (Raimund Haug)\n*   Antje Schmelzer (CoE Robotics)\n*   Oliver Gluth (Visual Inspection)",
        "related_projects_text": "*   Project: Lab4U Evolution Phase 1 (67333) Background: Lab4U has been successfully transferred and enhanced functionality from MyLab to GBS SAP United Platform and in addition included a stepwise guidance for the analyst through the system. However, additional functionality such as direct equipment connection, certain reports was not implemented yet Objectives:",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 141,
        "bi_id": "QC05",
        "name": "Automated Specification Transfer Solution",
        "process_step_id": 43,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "*   GSPECS very complicated and not user friendly (high effort)\n*   word is more simple compared to GSPECS\n*   no automated recipe generation and inspection instruction\n*   user do not see benefit of GSPECS\n*   no standardization today\n*   each site is creating their own pr\u00fcfvorschrift,......",
        "target_solution_description": "*   autoring should be very simple (easy text editor, not like a development language)\n*   'Baukastensystem' for easy creation\n*   automated generation of inspections plans\n*   Description: Implement an automated system for transferring specifications seamlessly to subsequent systems, ensuring consistency and saving time.\n*   Key Features: Automated data transfer workflows, Real-time synchronization between systems, Error detection and correction mechanisms, Customizable transfer rules and triggers, Audit trails and logging for compliance",
        "technologies_text": "*   to be evaluated\n*   interfaces to LIMS and Lab4You",
        "requirements": "*   the specification need to start with IU Dev in the same system to accelerate launch",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Automated Specification Transfer Solution\n*   GSPECS very complicated and not user friendly (high effort)\n*   word is more simple compared to GSPECS\n*   no automated recipe generation and inspection instruction\n*   Changes are automatically transferred into the respective systems and change controls / compliance checks are initiated\n*   Connecting Specification management with other systems (e.g. Lims, LES)\n*   Inspection plans can be created automatically from the testing specifications\n*   Description: Implement an automated system for transferring specifications seamlessly to subsequent systems, ensuring consistency and saving time. Key Features: Automated data transfer workflows, Real-time synchronization between systems, Error detection and correction mechanisms, Customizable transfer rules and triggers, Audit trails and logging for compliance\n*   Global System for managing specifications as (one source of truth) that is interfaced with RIMS system, Change control system and LIMS/AMET systems, to trigger subsequent automated specs updates and analysis workflows updates.\n*   user do not see benefit of GSPECS\n*   no standardization today\n*   each site is creating their own pr\u00fcfvorschrift,......\n*   DigiLab Stream ( Jennifer Seefeldt, Thomas Hrebicek )\n*   autoring should be very simple (easy text editor, not like a development language)\n*   'Baukastensystem' for easy creation\n*   automated generation of inspections plans\n*   automated creation of inspection plans based on TS/AP\n*   automated creation of sampling plans based on specifications\n*   automated creation of workflows for robotics\n*   the specification need to start with IU Dev in the same system to accelerate launch\n*   automated creation of workflows for lab execution systems\n*   Connection to needed EQ / Systems already in Metadata, to atutomate other usecases\n*   Establish governance (perhaps also technical) to ensure that the global master data can only be changed by authorized persons. --> Direct digital solution to ensure that, for example, workflows in the LES can also be adapted when process changes are made in the master.\n*   easier transfer due to standardization\n*   FTE reduction needed to create manual specs, inspection plan, workflows, etc. (~45 in Ingelheim, ~30 in Biberach)",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; potential high effort to develop what we need; Operating cost (Opex): Invest (Capex): Implementation time: ~2years",
        "potential_quantification": "High; FTE reduction needed to create manual specs, inspection plan, workflows, etc. (~45 in Ingelheim, ~30 in Biberach)",
        "dependencies_text": "IT/GBS; Lab4U; potentially licenses for new software",
        "contact_persons_text": "*   Y. K\u00fchne / P. Stetzenbach\n*   GBS Virginia Hau\n*   Raimund Haug IT\n*   Tobias Elsenheimer\n*   Philipp Hattemer, Julia Ilgen",
        "related_projects_text": "*   DigiLab program -> DigiEngine-> Process Harmonization Stream ( Jennifer Seefeldt, Thomas Hrebicek )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 62,
        "bi_id": "SCM10",
        "name": "Tactical & Strategic Planning of critical excipients and materials",
        "process_step_id": 35,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting list",
        "effort_level": "Low",
        "status": "medium",
        "business_problem_solved": "Utilize SC planning results on lower BoM levels for e.g. raw material demand forecast; supplier negotiations etc. (all planning horizons). No manual creation of tactial and strategic procurement plans.",
        "target_solution_description": "System created foreccast/procurement plan for all starting material. Automated update of procuremtn s plany across all time horizons incl. alerts in case of potential bottlenecks.",
        "technologies_text": "SAP.",
        "requirements": "Harmonized data modelSKU concept /uniqued identifier.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "Low",
        "reduction_time_launches": "Low",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Utilize SC planning results on lower BoM levels for e.g. raw material demand forecast; supplier negotiations etc. (all planning horizons).",
        "further_ideas": null,
        "effort_quantification": "Project cost: Mdium/High effort for first time implementatzio incl. Data Cleansing (GEt right and stay right). Run costs (p.a.): improves OPEX due to reduction of manual work. Time for implementation: 2-3 years.",
        "potential_quantification": null,
        "dependencies_text": "data model. GBS United (EGMG/SCPE). Tacatical Supply Planning / COPE.",
        "contact_persons_text": "Langlouis,Dr.,Gabriele.",
        "related_projects_text": "-",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:02:52.985034+00:00"
      },
      {
        "id": 142,
        "bi_id": "QC08",
        "name": "AI-Driven Analytical Procedure Development",
        "process_step_id": 43,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Wave 3",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "Standardized SOPs from DEV to GMP ready for direct implementation into System",
        "technologies_text": "Possible with standardized template and possible not AI needed",
        "requirements": "Better Integration of IU into operations processes (handover)",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "Low",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   AI-Driven Analytical Procedure Development\n*   Authoring Tool with an easy to use front end (similar to a \"simple\" text editor) but offering a data structur in the backend empowering automated \"transkription\" into other software solutions (e.g. testing plans in LIMS, Workflows in LES)\n*   Prerequisite: design of analytical procedures to support automation activities (e.g. robotics)\n*   AI supported creation of analytical procedures\n*   Standardized SOPs from DEV to GMP ready for direct implementation into System\n*   Standardization by offering building block based authoring software\n*   Interface to IU --> Co-creation?!\n*   Better Integration of IU into operations processes (handover)\n*   Possible with standardized template and possible not AI needed\n*   \"Pr\u00fcfplan\" / Sample Plan",
        "further_ideas": "n.a.",
        "effort_quantification": "Easy, Medium",
        "potential_quantification": "rather Low",
        "dependencies_text": "n.a.",
        "contact_persons_text": "*   Caroline Becker, Andreas Oefner\n*   Ulrich Weber",
        "related_projects_text": "*   DigiLab program -> DigiEngine-> Process Harmonization Stream ( Jennifer Seefeldt, Thomas Hrebicek )",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 143,
        "bi_id": "QC19",
        "name": "Connected Systems Integration",
        "process_step_id": 44,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": null,
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "No data connection, no data transfer,",
        "target_solution_description": "*   Description: Integrate sample testing processes with ERP and procurement systems for seamless data flow and coordination.\n*   Key Features: ERP system integration for real-time data synchronization. Interface with procurement systems for resource management. Unified data management across connected systems.\n*   All systems are connected / interfaced as needed.",
        "technologies_text": "see use case 10",
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "Medium (weeks)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Connected Systems Integration\n*   No data connection, no data transfer,\n*   all layers are connected ERP/LIMS/AMET/VSIMS/Software/Equipment\n*   No manual data transfer / get rid of system interfaces\n*   seamless E2E integration (vertical) to ensure data integrity and reduce effort\n*   Description: Integrate sample testing processes with ERP and procurement systems for seamless data flow and coordination. Key Features: ERP system integration for real-time data synchronization. Interface with procurement systems for resource management. Unified data management across connected systems.\n*   All systems are connected / interfaced as needed.\n*   Interface to pre/subsequent systems",
        "further_ideas": "see use case 10 (Pink sticker)",
        "effort_quantification": "Hard",
        "potential_quantification": "High",
        "dependencies_text": "n.a.",
        "contact_persons_text": "n.a.",
        "related_projects_text": "*   DigiLab program -> DigiEngine-> IT Architercture Stream ( Jennifer Seefeldt, David Pinto )\n*   Project: Lab4U Evolution Phase 1 (67333) Background: Lab4U has been successfully transferred and enhanced functionality from MyLab to GBS SAP United Platform and in addition included a stepwise guidance for the analyst through the system. However, additional functionality such as direct equipment connection, certain reports was not implemented yet Objectives:",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 144,
        "bi_id": "QC21",
        "name": "Automated QC Release",
        "process_step_id": 23,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   many manual checks creating a high effort\n*   very difficult to check all data in all systems\n*   risk for human error\n*   plausi check high effort and complexity",
        "target_solution_description": "*   batch release cockpit withh interfaces to all source systems (e.g. BIChrome, ...)\n*   SAP QM automated usage decision",
        "technologies_text": "*   Lab4You, Batch Release Cockpit\n*   interface to all source systems\n*   QUDA",
        "requirements": "*   check and challenge regulatory requirements",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days) (n.a. indicated on slider)",
        "reduction_time_launches": "Low (days) (n.a. indicated on slider)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Automated QC Release\n*   many manual checks creating a high effort\n*   very difficult to check all data in all systems\n*   risk for human error\n*   plausi check high effort and complexity\n*   One Button Batch Release\n*   Batch release cockpit. Traffic light for QC release if all deviations are closed, all results are there and OK, ...\n*   Automated check the plausibility of analytical results and correct status of all tests and raw data (Double Check performed/done)\n*   batch release cockpit withh interfaces to all source systems (e.g. BIChrome, ...)\n*   SAP QM automated usage decision\n*   Description: Implement an automated system for QC release, focusing on dashboards, checks, and one-button batch release.\n*   Key Features: Real-time QC dashboards for status. Automated checks and validations. One-button release functionality.\n*   Harmonized CoA and automated creation\n*   check and challenge regulatory requirements\n*   Qualitative Benefits: less human failures\n*   up to 1FTE per release department depending on complexity",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium; Operating cost (Opex): Invest (Capex): Implementation time: 1-2 years",
        "potential_quantification": "High; up to 1FTE per release department depending on complexity",
        "dependencies_text": "IT/GBS; GBS United project and Batch Release Cockpit; QUDA; digilab",
        "contact_persons_text": "*   Lab4You Team\n*   Klaudius Dragon\n*   Sascha Prigge",
        "related_projects_text": "DigiLab Program (LabConnect)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 145,
        "bi_id": "QC23",
        "name": "Guided workflow for review and release",
        "process_step_id": 23,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 1",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "if review by exception is in not needed",
        "technologies_text": null,
        "requirements": "*   Standardized Procurement Process: Establish a uniform process for purchasing equipment globally.\n*   Integration with ERP Systems: Seamless integration with existing Ent (Enterprise systems).",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Guided workflow for review and release\n*   guided workflow for review\n*   Digitalize the paper checklist\n*   Description: Implement automated workflows for QC review and release, guiding personnel through the process.\n*   Key Features: Step-by-step QC review workflows. Automated task assignments and tracking. Integration with QC management systems. Automated compliance checks for GxP data. Real-time review notifications. Integration with current compliance management systems.\n*   guided workflow for release\n*   if review by exception is in not needed\n*   Standardized Procurement Process: Establish a uniform process for purchasing equipment globally.\n*   Integration with ERP Systems: Seamless integration with existing Ent (Enterprise systems)\n*   Not required if review by exception is in place",
        "further_ideas": "Idea",
        "effort_quantification": "Medium",
        "potential_quantification": "High",
        "dependencies_text": "Not required if review by exception is in place",
        "contact_persons_text": "Lab4U Team",
        "related_projects_text": "DigiLab Program ( Jennifer Seefeldt / David Pinto) - AMES: Claudia Knoll -Lab4U: Yvonne Keune, Patrick Stetzenbach)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 146,
        "bi_id": "QC26",
        "name": "Automated trending and evaluation of non-analytical data",
        "process_step_id": 45,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 2",
        "wave": "Waiting list",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": "*   Description: Automated identification and assessment of patterns/trends.\n*   Key Features: One trending for all quality events using all available data",
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "High (month)",
        "reduction_time_launches": "High (month)",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "*   Automated trending and evaluation of non-analytical data\n*   Automated \"trending/evaluation\" of available lab data by AI and timely notification if patterns arise\n*   Using data (e.g. discrepancies, equ. availability) to automatical assess Products (SCRA), Suppliers (Purchasing Assessments, Supplier Assessment, RQA) etc\n*   Description: Automated identification and assessment of patterns/trends. Key Features: One trending for all quality events using all available data\n*   Automated identification AND assessment of patterns/trends inkl report generation for quality events. Use only one trending for all quality events",
        "further_ideas": "n.a.",
        "effort_quantification": "Medium",
        "potential_quantification": "Medium",
        "dependencies_text": "Linked to \"predictive analytics\" / or combined with",
        "contact_persons_text": "Carolin Becker, Andreas Oefner",
        "related_projects_text": "n.a.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 147,
        "bi_id": "QC28",
        "name": "Global Equipment Purchasing Standards",
        "process_step_id": 24,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Wave: Wave 3",
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "*   Currently, there is no strong central governance on equipment purchase by the sites, and is it following the global standard catalogue or not\n*   This can lead to lost/mis-allocated Capex investments, as the purchased equipment won't fit to the overall and long term systems architecture",
        "target_solution_description": "Global System to govern standard Lab equipment catalogue, assets tracking, purchase, replacement and associated Capex planning.",
        "technologies_text": "Process/system control points to ensure that before authorizing purchase, it is checked against standard equipment catalogue/database",
        "requirements": "*   Standardized Procurement Process: Establish a uniform process for purchasing equipment globally.\n*   Supplier Evaluation and Selection: Implement criteria for evaluating and selecting suppliers to ensure quality and reliability.\n*   Cost Management: Optimize costs through bulk purchasing and negotiated contracts.\n*   Compliance and Risk Management: Ensure all purchases comply with regulatory standards and manage associated risks.\n*   Integration with ERP Systems: Seamless integration with existing Ent (Enterprise systems)",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine, AI",
        "reduction_time_transfer": "Medium (weeks)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Description: Establish global standards for lab equipment cataloging, requests, purchases, transfers, maintenance, and Capex planning.\n*   Key Features: Standardized equipment catalog. Global request and purchase system. Equipment transfer and maintenance protocols. Integrated Capex planning.\n*   Standardized equipment\n*   Global Equipment Purchasing Standards\n*   Global System to govern standard Lab equipment catalogue, assets tracking, purchase, replacement and associated Capex planning.\n*   Currently, there is no strong central governance on equipment purchase by the sites, and is it following the global standard catalogue or not\n*   This can lead to lost/mis-allocated Capex investments, as the purchased equipment won't fit to the overall and long term systems architecture\n*   Strong focus on standardized equipment across all sites\n*   Process/system control points to ensure that before authorizing purchase, it is checked against standard equipment catalogue/database",
        "further_ideas": "Idea",
        "effort_quantification": "Easy",
        "potential_quantification": "High",
        "dependencies_text": "IU need to be involved",
        "contact_persons_text": "n.a.",
        "related_projects_text": "*   Equ Std. Christine Mladek\n*   DigiEngine: Equipment Standardization\n*   DigiLab Program -> DigiEngine-> Equipment Standardization Stream ( Jennifer Seefeldt / Heike Gottschalg)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 77,
        "bi_id": "QA01",
        "name": "Automated SOP creation, update and translation workflow",
        "process_step_id": 17,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   Verification of SOPs aderance to template and Good Writing Practice needs to be done manually\n*   SOP creation does often not reflect good writing styles to improve understanding\n*   Translations are not availble on a click - high manual effort\n*   Information to feed the VQD platform with the right metadata requires manual interaction with different function (doc unit)",
        "target_solution_description": "*   AI to write documents based on provided content following Good Writing Practice and the recent doc template.\n*   Adapting existing documents into new templates automatically\n*   AI ensures that the provided content presented is easy to understand for the target audience\n*   Embedded translation feature including formatting capabilities within the e-DMS\n*   Automated request from the e-DMS to ensure that the provided data are directly transferred into e-DMS metadata",
        "technologies_text": "*   AI connectivity to e-DMS (VQD)\n*   Closed AI to be used\n*   e-DMS connectivites towards BI AI solution (iQ Now)",
        "requirements": "*   Co-operation with e-DMS provider (Veeva)\n*   Flexibility to connect Boehringer solutions",
        "relevants_text": "Bio, Chem., Device, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Simplify SOP Creation and workflow\n*   The process requires manual start (RMS panel), followed by manual filling of forms to start the editing workflow. The content must be manually copied & pasted into the new template before starting the real work of editing. Comments added in the review process cannot be displayed in the editable version. a copy must be downloaded.\n*   Implement an automated SOP management system that uses AI to streamline the creation, updating, and approval of SOPs. This system can include templates, version control, and automated notifications for updates. Additionally, introduce a collaborative SOP review platform that allows real-time commenting and editing, making the review process more efficient and less painful.\n*   Use AI to help creating SOP, create a prompt asking questions and helping to create first drafts at least\n*   AI supported writing of GPDocs based on Good Worting Practice.\n*   integrate translation modules into document management system\n*   no formatting effort",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): \u20ac200k - \u20ac500k; Invest (Capex): <\u20ac500k; Implementation time: 1-3 years",
        "potential_quantification": "High; Demands that VQD provides AI translations in VQD were discussed. Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   GMSO for Documentatiuon Mgt: Andr\u00e9 de Freitas\n*   DMSO HP documentation mgt",
        "related_projects_text": "*   Engage AI initiatives ongoing to use AI for SOP content writing and comparison\n*   Demands that VQD provides AI translations in VQD were discussed.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:48:55.107267+00:00"
      },
      {
        "id": 78,
        "bi_id": "QA02",
        "name": "AI-supported, need driven information provision",
        "process_step_id": 17,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "*   Document and content retrieval is too cumbersome\n*   Search for Documents and content not intuitive",
        "target_solution_description": "*   Easy AI prompting using LLM to find the right document and/or content\n*   AI tool provides a summary linked to your prompt with content and source information, as applicable",
        "technologies_text": "*   AI connectivity to e-DMS (VQD)\n*   Closed AI to be used\n*   e-DMS connectivites towards BI AI solution (iQ Now)",
        "requirements": "*   LLM solution to work accross languages.",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   AI supported need driven provision of Information out VQD.\n*   AI supported need driven provision of Information out VQD.\n*   I want to know at the current moment, what the right SOP is and where to find the information I need\n*   We will reduce effort for searching of relevant information, because information required for the work execution are provided based on the need of the employees",
        "further_ideas": "n/a",
        "effort_quantification": "Easy; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   GMSO for Documentatiuon Mgt: Andr\u00e9 de Freitas\n*   DMSO for Documentatiuon HP",
        "related_projects_text": "*   Engage AI initiatives ongoing to use AI for SOP content writing and comparison\n*   Demands that VQD provides AI translations in VQD were discussed.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:49:00.524040+00:00"
      },
      {
        "id": 89,
        "bi_id": "QA05",
        "name": "Role-based learning",
        "process_step_id": 17,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   differentiate between must know and nice to know, allow for reports of each bucket, provide relevant SOP's per case\n*   Guided Workflow at workstation with knowldge, pictures, SOP extracts etc.\n*   Implement an integrated learning management system that automatically grants access based on learning achievements. This system can include interactive and multimedia-based learning modules that focus on \"how-to-learn\" rather than just \"what-to-learn,\" enhancing the overall learning experience.\n*   Roll-out of role-based learning approach down to local level to ensure targeted training & qualitication based on needs\n*   implement \"for information\" training in LOS (knowlegde of BI process is needed for job but procedure does not need to be followed personnally)\n*   Automized role-based learning generation through AI (based on SOPs)\n*   Automated upload of LOS Trainings in VQD\n*   LOS recordings time consuming\n*   combination of access rights and learning content --> automated assignment possible\n*   role-based learnings: Support development, maintenance, translation of learnings and knowledge check\n*   Medical Device / CP product knowhow (summary) is easily accessible",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:49:35.041129+00:00"
      },
      {
        "id": 12,
        "bi_id": "QA10",
        "name": "Automated internal APQR generation",
        "process_step_id": 31,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   translation of data for APQR generation\n*   APQR 'readiness' supported with automated data collection\n*   Tool to assisst creation of APQR at least semi automated (by given product & timeframe)\n*   Automated APQR (use case already running), including trend analysis and identification of potential for continuous improvement",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:51:46.682239+00:00"
      },
      {
        "id": 34,
        "bi_id": "QA11",
        "name": "Proactive and automated risk management tool",
        "process_step_id": 31,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Extend use of Quality Risk Management to make information accessible\n*   IT Tool for RiskMgt Life Cycle Mgt of Medical Devices (Polarion)\n*   AI supported Risk Communication out of various source systems providing recommendations for its risk control\n*   AI generated automated Risk Register out of variouss source system to enure Risk Oversight",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:51:51.406859+00:00"
      },
      {
        "id": 36,
        "bi_id": "QA09",
        "name": "Harmonized user-friendly change control system",
        "process_step_id": 31,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   Simplify processing of Change Controls supported with AI e.g. to identify recurrent events to compare impact assessments\n*   simplification of Change Control execution\n*   CC process / module adaption (streamlined, focusing on the minimum requirements, fields to be entered are self-explanatory)\n*   optimization of change system to be more ... visual, perhaps by integrating diagramms, dependencies etc\n*   One Change Control system at BI\n*   assisstance tool for creation of changes (guided by questions and proposed by AI)\n*   evaluating risk automatically during change process (e.g. change in master data, report available where these data are used)\n*   one Change Control system for technical & pharmaceutical changes in OPS and IU with a streamlined process\n*   AI support for writing Change Control records highlighting potential risks and make proposal for its control",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:51:44.467735+00:00"
      },
      {
        "id": 49,
        "bi_id": "QA13",
        "name": "AI-supported RIN & PIN processes",
        "process_step_id": 19,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Low/Medium",
        "status": null,
        "business_problem_solved": "*   The main problem to be solved is the inefficiency and risk of non-compliance due to manual processes. By integrating AI, the system can automatically check and update requirements, suggest amendments, and initiate change requests, ensuring compliance and efficiency.\n*   Furthermore, in some cases BI is contractually obligated to support CMOs with regulatory intelligence. Currently this is executed in a time-consuming and risk-prone manual process...",
        "target_solution_description": "*   The goal is to create an AI-supported system that automates regular checks, updates, and amendments to ensure compliance with external requirements and internal standards....\n*   resulting change controls are automatically generated for implementation tracking to ensure regulatory compliance as license to operate.\n*   The output is available in a format which can be easily shared with CMOs to whom such contractual obligations exist....",
        "technologies_text": "*   AI Algorithms: For automated checks, updates, and suggestions....\n*   Unified IT Tool: Integration of a unified RIN IT tool for Boehringer Ingelheim.\n*   Data Integration: Seamless integration of external requirements and internal standards.",
        "requirements": "*   Automated Regular Check: AI performs regular checks of external requirements and compares them to internal standards (e.g., SOP)...\n*   Pharmacopoeia Assignment: AI performs the assignment process to divisions and sites (PIN).\n*   Automated Update Provision: If external requirements (RIN/PIN) change, AI provides automated proposals on how internal guidelines need to be adapted.\n*   Change Request Initiation: Automated initiation of change requests in case of changes to external guidelines.\n*   Impact Assessment: AI supports impact assessment for PIN and RIN.\n*   Provision to CMOs: Easy provision of RIN/PIN to Contract Manufacturing Organizations (CMOs) to support expectations and contractual requirements.\n*   Change Proposals: AI-supported change proposals based on new text/monographs and available BI processes.\n*   Screening of Pharmacopoeia: AI screens Pharmacopoeia/RA monographs and entering into the PIN/RIN system.",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Low",
        "ideation_notes": "*   automated regular check of external requirements and comparison to internal standards (e.g. SOP)\n*   Integrate AI to suggest necessary process amendments improving compliance due to updated regulations.\n*   AI tperformed Pharmacooeia assignment process to Divisions and sites (PIN)\n*   if external requirements (RIN / PIN) are changed automated update provision of a proposal how internal guidelines need to be adpated\n*   automated initiation of change request in case of change of external guidelines\n*   AI supported impact assessment for PIN and RIN\n*   ONE RIN IT Tool for Boehring incl AH!\n*   easy provision of RI / PI to CMOs to support such expectations / contractual requirements\n*   AI supported change proposals based on new Text / Monograph and available BI processes\n*   AI screening of Pharmacopoeia / RA monographs and entering into PIN / RIN system",
        "further_ideas": "n/a",
        "effort_quantification": "hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   Karin Cudris (GMSO PIN)\n*   Anke Timm (external interface 3PQM)\n*   Petra Regenhardt (GMSO RIN)\n*   Thomas Waizenegger / Ingo Ehleben (CMC)",
        "related_projects_text": "*   P360 67694?",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:52:32.840500+00:00"
      },
      {
        "id": 50,
        "bi_id": "QA14",
        "name": "Leveraged learnings form audit & inspection observations",
        "process_step_id": 19,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Auditor observation reporting: increase transparency about observation background ==> cite regulations or internal processes which the auditee deviates from\n*   easy retrieval of audit results (e.g. in form of short summaries)\n*   regulatory requirement basis for observations directly included in finding statement\n*   Good practice: FDA\n*   Extenral inposections summary generation by AI\n*   AI to support creating Audit Summary\n*   information of audit report in a digestiable and better format (instead of report, ABCD charter or whatever)\n*   Obervation based alerts\n*   Audit and Inspection results communication",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:52:34.664631+00:00"
      },
      {
        "id": 55,
        "bi_id": "QA19",
        "name": "Full integration of ERP and eQMS [Enabler]",
        "process_step_id": 18,
        "priority": 3,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "*   full integration of ERP and deviation system (e.g. automated batch blocking, automated PCID retrieval) currently manual data transfer to ERP\n*   Integrated connected Event and issue workflows linked to consistent Risk managment",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High/Medium; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:54:04.248795+00:00"
      },
      {
        "id": 56,
        "bi_id": "QA20",
        "name": "Simplify the investigation of Discrepancies",
        "process_step_id": 18,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": "*   The main problem to be solved is increasing speed, efficiency and quality of investigations resulting in easy to capture chain of thought and logical writing style.",
        "target_solution_description": "*   The goal is to create a system that simplifies the investigation of discrepancies by providing clear feedback, AI-supported documentation, and easy access to workflow details.\n*   The AI will support the investigation in conducting the methodological approach.\n*   AI-supported formulation etc. support to make complex issues easily understandable for subsequent readers",
        "technologies_text": "*   AI Algorithms: For providing feedback and supporting documentation....\n*   Data Integration: Seamless integration of workflow details and records.",
        "requirements": "*   AI-supported Documentation: AI should support the documentation of investigation processes, including the creation of Executive Summaries.",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   clear and understandable feedback from system why something is not possible and what the solution can be.\n*   AI supporting the documentation of investigation processes e.g. creation of Executive Summary\n*   overview of workflow details directly near the record",
        "further_ideas": "n/a",
        "effort_quantification": "Medium/Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): \u20ac500k - \u20ac1mio; Implementation time: 1-3 years",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   Tatjana Popara (GMSO and network)\n*   Christina Faul (DMSO TPC)\n*   Sascha Klein (GMSO and network)",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:54:06.646908+00:00"
      },
      {
        "id": 57,
        "bi_id": "QA21",
        "name": "Integrated quality management system foundation [Enabler]",
        "process_step_id": 18,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Interconnected modules. (Currently: records are processed in silos, not interconnected)\n*   new eQMS to increase process connectivity\n*   Ensure traceability between standalone modules and CAPAs\n*   Track and trace records\n*   enable sites to track actions easily--> CAPA is not an action tracker\n*   Old naming: \"New eQMS\"",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:54:14.791798+00:00"
      },
      {
        "id": 46,
        "bi_id": "QA30",
        "name": "AI-supported anti-counter fighting investigation & mgmt.",
        "process_step_id": 22,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "*   Screening and management of anti counterfeiting measures is fully manual\n*   caused by individual experiences manual screening can be biased\n*   The main problem to be solved is the inefficiency and complexity of detecting and managing counterfeit activities. By integrating AI, the system can automatically detect counterfeit activities, gather intelligence, manage cases, and ensure transparency, thereby improving supply chain integrity",
        "target_solution_description": "*   supported case management\n*   database to capture information and maintain oversight\n*   assissted by AI anti counter feiting measures can be bundled and more focussed based on risks\n*   based on screening results effects of anti counter feeting measures can be assessed automatically\n*   The goal is to create an AI-supported system that enhances the detection, investigation, and management of counterfeit activities, ensuring transparency and improving supply chain integrity.",
        "technologies_text": "*   one platform (or if not one, interfaces between more platforms) to cover all activities around anti counter feiting",
        "requirements": "*   AI for On/Offline Counterfeit Detection: The system should include AI capabilities for detecting counterfeit activities both online and offline....\n*   Intelligence and Case Management: AI should support intelligence gathering and case management, interfacing with GoTrack (Q) and Legal/SCM systems....\n*   Intelligence and Case Management: AI should support intelligence gathering and case management, interfacing with GoTrack (Q) and Legal/SCM systems.",
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "*   Supply Chain Integrity- ACF: System incl. AI for on/off-line CF detection, Intelligence and Case Management - interfacing to GoTrack (Q) and Legal/SCM Systems\n*   transparency: check public electronic sources\n*   SCI: complete transparency in one system on global Pharma crime related to all Boehringer Ingelheim products & brands",
        "further_ideas": "n/a",
        "effort_quantification": "Medium; Operating cost (Opex): <\u20ac200k; Invest (Capex): \u20ac500k - \u20ac1mio; Implementation time: 1-3 years",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": "*   Andrea Desel (GMSO Anti Counterfeiting)",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:57:30.794195+00:00"
      },
      {
        "id": 100,
        "bi_id": "SCM05",
        "name": "Product LCManagement & Simulation over all Products & LC Stages",
        "process_step_id": 38,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": "high",
        "business_problem_solved": "Transparency on portfolio lifecycle status. RoI as guiding principle enabled. Delayed decision making. Better resource allocation.",
        "target_solution_description": "Enable scenario planning should improve business decision making (economic, environmental, ...). Product review digitally enabled (no/limited manual data collection required for PMR / RR / Brand assessments). Proactive product optimization planning. Predictive Analytics.",
        "technologies_text": "Digital Twin for Simulation and decison support. Data Analytics Tool / Simulation Software. AI supported PLM GPT.",
        "requirements": "Stringent product documentation & Product planning. Clear accountability for data / information provision. Ability to track and visualize all product inflection points.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Platform to accelerate brand assesments and decisions on withdrawl/divestiture-portfolio cleanup. Simulation/Scenario Planning. - Market Dynamics Simulation: Use advanced simulation tools to model different market scenarios and plan strategic options. (not part of PACE/COPE Replacement). Predictive Analytics: Implement predictive analytics to forecast trends and make data-driven decisions. (not part of PACE/COPE Replacement). digital twin for E2E supply chain (until BOPU WH). simulate network wrt flow of volume, cost, CO2, batches. Enables optimal SC design decision based on facts. Rapid Product Launches. -Scenario Planning: Use simulation capabilities to predict market dynamics and optimize product launch and change strategies. (not part of PACE/COPE Replacement). Product LCM platform to 1. provide transparency on all product inflection points (from RoFD to withdrawal / divest), investments, returns, network occupation, ... 2. enable scenario & simulation of product portfolio based on internal and external parameter changes. --> Allows for better, faster and early decision making on product portfolio investments. Capability available to simulate - (i.e. launch 2nd wave countries based on parameters/readiness). Development of decision tree as foundation for simulation and scenario planning. Product Lifecycle Board: Provides oversight of where we stand with our inline/pipeline portfolio from early stage (IU) to eoE (BU). Ingests data from various functions and systems for information and joint collaboration purposes. Systems in scope could be target PLM solution, OMP, Marketing Information... Parameters. Sales; Invests ... create decision making engine (scenario preparation, prediction, prescription, decision making) based on unified data. E2E Integration - Integrated Processes: Connect all stages of the product lifecycle, from RoFD to commercialization, for faster decision-making. (partially part of PACE/COPE Replacement). build system capability for segmentation of products (eg via attributes for archetypes).",
        "further_ideas": null,
        "effort_quantification": "Project cost: ~0,5 mio\u20ac for digital twin foundation. built of interfaces from source systems . ingestion of data from source systems. Run costs (p.a.): transfer of data from existing systems in LLM. Time for implementation: 1 year learning timeline including training. availability of training data sets.",
        "potential_quantification": null,
        "dependencies_text": "Network planning. Spice decision. Strategic S&OP.",
        "contact_persons_text": "Neves,Filipe Oliveira. Dr. Ries,Britta. Dr.Kache,Florian.",
        "related_projects_text": "Spice: Jiong Qu, Konstantin Fooss. Cope.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:01:05.438480+00:00"
      },
      {
        "id": 4,
        "bi_id": "SCM07",
        "name": "STML Cockpit",
        "process_step_id": 38,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "# GBS IT Budget Process 2026 - Project Fact Sheet Value Proposition_STML_Cockpit_MARTIN.pptx",
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": "-",
        "requirements": "-",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "...",
        "further_ideas": null,
        "effort_quantification": "Project cost: -. Run costs (p.a.): -. Time for implementation: -.",
        "potential_quantification": null,
        "dependencies_text": "-",
        "contact_persons_text": "Thomas Lersch.",
        "related_projects_text": "-",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:01:09.628438+00:00"
      },
      {
        "id": 43,
        "bi_id": "QA28",
        "name": "Digital batch release hub",
        "process_step_id": 22,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": "Bio, Pharma, Chem., Device, Launch, Routine",
        "reduction_time_transfer": "Low (days)",
        "reduction_time_launches": "Low (days)",
        "reduction_costs_supply": "Low ( )",
        "quality_improvement_quant": "High",
        "ideation_notes": "*   Batch Release in one system\n*   Automated labeling compliance checks to prevent Market Actions\n*   Automated batch release (support) inlc dossier compliance check via RIM/CPD3 - Batch Release Hub\n*   flexible / adaptable system support for creation of certificates (CoA / CoC)\n*   automated comparison of packaging order to country requirements (Dacor, SLCI)\n*   Simplified Batch Record Review System Develop a system to consolidate requirements from different sources (e.g., HU, CSS, Transferplan, Validationplan, etc.) into a single, unified batch record review process. Implement automated workflows and data integration to streamline the review process, reducing complexity and manual work\n*   automated provision of submission status (GMD modules, change approvals, labelling) against which batch needs to be released, especially with focus on outsourced manufacturing incl. batch release\n*   automated document management around batch release (certificates)\n*   all information relevant for release at one glance\n*   centralized batch release hub to capture information centrally and allow for batch traceability",
        "further_ideas": "n/a",
        "effort_quantification": "Hard; Operating cost (Opex): <\u20ac200k; Invest (Capex): <\u20ac500k; Implementation time: <1 year",
        "potential_quantification": "High; Only fill in affected cost bucket",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T11:57:22.987161+00:00"
      },
      {
        "id": 88,
        "bi_id": "SCM01",
        "name": "SKU creation & management",
        "process_step_id": 38,
        "priority": 1,
        "raw_content": null,
        "summary": null,
        "inspiration": "Interactive dashboards. Workflow Visualization (Assessment and Approval Process). Automated Reports.",
        "wave": "Wave 1",
        "effort_level": "High",
        "status": "medium",
        "business_problem_solved": "Inefficient SKU Creation and Approval: Streamlining the process will reduce delays and improve time-to-market for new products. Manual Workload: Automating repetitive tasks will free up resources for more strategic activities. currently many system breaches and therefore manual effort along lifecycle, data quality issues. End of lifecycle of current systems. no KPIs & clear responsible for master data quality.",
        "target_solution_description": "Develop a concept of Data Content Ownership that changes throughout the lifecycle. Define which attributes have to be captured how early in the process, based on attribute utilisation. Increase speed for SKU creation and change -> faster time to market. integration of registration data (OMP). handling of new technologies enabled (e.g. digital products). Efficient art work process enabled. Integrated Workflow system: Integrated platform that manages the entire SKU lifecycle (creation and changes). Proactive Portfolio Management process should be integrated as automated process incl. AI generated preliminary results.",
        "technologies_text": "PLM System - Make or Buy (Dassault / Siemens). PLM-Tool as data integration hub. A central repository that consolidates material data from various sources (MDG, OMP, BIPRISMA, etc.) with real time updates and consistency. MDG-Sytem (Masterdata Governance). OMP. BIPRISMA.",
        "requirements": "Version handling decided which option will be in use at Boehringer Ingelheim. Develop a concept of Data Content Ownership that changes throughout the lifecycle. Define which attributes have to be captured how early in the process, based on attribute utilisation. Real time data integration from multiple sources. Scalibility to handle increasing data of multiple businesses (HP, BIO, AH). User friendly interface: An intuitive interface that allows users to easily navigate and manage SKUs with dashboards for tracking progress. PLM System decision - Make or Buy (Dassault / Siemens). Masterdata concept allowing for flexibility where needed jointly global and local.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Automated Validation: Automatically validate product data to ensure compliance and readiness for market release. (part of PACE/COPE Replacement). SKU Creation and Management. Streamlined SKU Creation and Change: Accelerate the creation and change approval of new/existing SKUs through integrated workflows. (part of PACE/COPE Replacement). Data Integration: Seamlessly integrate material data from various sources to maintain consistency and accuracy, e.g Automated Regulatory/Compliance checks with RIM system, (part of PACE/COPE Replacement). Instand creation of material via easy process and UI - Data is automaticailly validated using smart systems - one source of truth. Develop a concept of Data Content Ownership that changes throughout the lifecycle. Define which attributes have to be captured how early in the process, based on attribute utilisation. PLM: As for the business case we have set up a meeting in Cope. Goal is to measure and increase the speed. Setup of joint global+local Master data concept to ensure consistent stringent and high-quality data sets in all sites. Increase knowledge how to change or eliminate errors.",
        "further_ideas": null,
        "effort_quantification": "Project cost: FTE and Time to work on such a project clear R&R. Run costs (p.a.): According to COPE program - PLM System: run cost (~ 2 mio \u20ac p.a. for license, hosting). Time for implementation: According to COPE replacement Go Live 2030.",
        "potential_quantification": "data Integrity increased. ease of reporting and reliability of data enableing proactive lifecycle management.",
        "dependencies_text": "Version handling. STML integration. Artwork Management. IU. Strategic / tactical planning processes (felxible SKU management to allow integrated planning, no \"stand-alone\" solution for long-term planning.",
        "contact_persons_text": "Neves,Filipe Oliveira. Business: Lyse Wotschke, Britta Lifka. GBS MDM (Martin Treder).",
        "related_projects_text": "COPE replacement - PACE Workstream. COPE - Rene Kluiber ext. Version Stream. Bernhard Poll. Britta Lifka. Martin Treder MDM. BIPRISMA Replacement. MDG: Sabine Germeyer / Boris Klockow.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:00:51.898093+00:00"
      },
      {
        "id": 102,
        "bi_id": "SCM12",
        "name": "Transparent display of all demand plans (ARC, ....)",
        "process_step_id": 35,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": "one consistent plan for operations including possibility for reconcillations and comparison with LTF/ARC. system supported solution to comparee e.g last approved plan from HPSC and asset team including impact for oparations.",
        "target_solution_description": "one plan /repository with all available demand plans for better decison making. state oft the art perfomance and accuracy manamgement for better decision making (e.g Forecast Accuracy).",
        "technologies_text": "SAP for Demand.",
        "requirements": "one platform and data structure to support all plans. cross-functional alignement between TA, Fiance and Operations. platform available for all function (e.g XTA, IU, etc.).",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Strategic demand review with central forecast repository bringing LTF, ARC, Asset Team, HPSC, Sales Forecasting views together to create final consensus as one agreed plan. Easily identiy deviations and where there is need to react. Data integration: Create a centralized platform that consolidates data from various sources, ensureing consistency and accuracy across the supply chain. single source of truth for strategic, tactical and op forecast and underlying assumptions incl. Scenarios enables better decision making and stops blaming culture.",
        "further_ideas": null,
        "effort_quantification": "Project cost: Enable simpliefied demand planning setup in SAP IBP (only data structures and simple data maintenance) and comparison > Low Medium effort. Run costs (p.a.): Once implemented massive reduction of Excel file handling overcompensating potentially needed governance. Time for implementation: 1-2 years.",
        "potential_quantification": "Most recent planning assumptionstran sparentto all involved functions.Improved data quality.",
        "dependencies_text": "Provides best demand input to scenario planning.",
        "contact_persons_text": "Laufersweiler,Joern. Gardt,Thomas.",
        "related_projects_text": "-",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:03:00.177575+00:00"
      },
      {
        "id": 7,
        "bi_id": "SCM09",
        "name": "System support for product review",
        "process_step_id": 35,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": "Scenario planning, simulation and optimization of global int/ext capacities including financial integration.",
        "target_solution_description": "Capacity vizualization of internal and extenal production sites for FG to starting materials based on harmonized data model allowing aggregation and dis-aggregation covering time horizon 0-10y for all product lifecycle stages. system support for product review. integration of demand scenarios. all decisions are driven by fiancial impact assessement.",
        "technologies_text": "-",
        "requirements": "-",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "Medium",
        "reduction_time_launches": "Medium",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "Strategic product review with unified data model linking to cross functional availble databased (enrich, etc.), bring expert knowledge structured into systems.",
        "further_ideas": null,
        "effort_quantification": "Project cost: -. Run costs (p.a.): -. Time for implementation: -.",
        "potential_quantification": "Integrated planning across all functions. Collaboration across the company.",
        "dependencies_text": "-",
        "contact_persons_text": "Langlouis,Dr.,Gabriele. Dr.Ries,Britta. Lersch,Thomas.",
        "related_projects_text": "-",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:02:51.321025+00:00"
      },
      {
        "id": 14,
        "bi_id": "SCM16",
        "name": "Scenario Planning on Demand Level",
        "process_step_id": 28,
        "priority": 4,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting List",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "Create possibility to create forecast/ demand plan on likelyhood of success (i.e. tender business = 60% SR for 50k PU).",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": "Integrated planning across all functions. Collaboration across the company.",
        "dependencies_text": "...",
        "contact_persons_text": "Kache,Dr.,Florian. Sarah.",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:03:49.078686+00:00"
      },
      {
        "id": 82,
        "bi_id": "SCM28",
        "name": "Product traceability to avoid counterfeiting",
        "process_step_id": 32,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "Dangerous Goods.pptx",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": "low",
        "business_problem_solved": "System supported completion checks and monitoring. Currently no E2E visibility for Boehringer products in place.",
        "target_solution_description": "ww traceability of BI products (eg via Serialization) until patient level.",
        "technologies_text": "coding technology in place. cloud solution for storage of codes in place. customer read out tbd (simliar to scanning @ pharmacy, app on mobile).",
        "requirements": "...",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "Boehringer coding strategy implemented to avoid counterfeits and ensure compliance and traceability of products E2E until patient level (eg single unit coding, S&A, SSCC as required, GTIN, ePIL). TAPA oriented one security standards for WHs & routes. Align with QA.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ~ 3 years for ww.",
        "potential_quantification": "use beyond ACF topcis (T&T). avoid counterfeits, reputational issues. be proactive instead of reactive. avoid destruction cost.",
        "dependencies_text": "automation of EU alerts. Customer Feedback and touch points. Coding strategy, eg SUC.",
        "contact_persons_text": "Jyrki Syv\u00e4ri. GMSO Andrea Desel.",
        "related_projects_text": "automation of EU alerts.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:09:22.766147+00:00"
      },
      {
        "id": 104,
        "bi_id": "SCM15",
        "name": "Exception based planning",
        "process_step_id": 28,
        "priority": 2,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting List",
        "effort_level": "Medium",
        "status": "low",
        "business_problem_solved": "Exception based planning is one part of integrated demand planning process, similar like segmentation it helpsthe demand planners to focue on the most value adding activities with the aim to provide best possible demand plan.",
        "target_solution_description": "Implement exception-based planning supported by reports, dashboards, and log functionality guiding the planner\u2019s focus and effort, therefore, increasing planning efficiency and effectiveness. Build common dashboards along the integrated demand planning process. Implement exception-based planning and reporting (e.g. driven by KPI deviationslike BIAS, FA or actual sales peaks). Enable logging of sales forecast and assumption history.",
        "technologies_text": "Demand planning solution. Reporting tools.",
        "requirements": "Information feed into S&OP and back to demand planning should include timeseries, alert- and exception-based reports on deviations as well as information on risks, opportunities, assumptions,and constraints.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Exception-based planning supported by reports, dashboards, and log functionality guiding the planner\u2019s focus.",
        "further_ideas": null,
        "effort_quantification": "Project cost: ... Run costs (p.a.): ... Time for implementation: ...",
        "potential_quantification": null,
        "dependencies_text": "-",
        "contact_persons_text": "Kache,Dr.,Florian. Sarah.",
        "related_projects_text": "...",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:03:47.475829+00:00"
      },
      {
        "id": 109,
        "bi_id": "SCM23",
        "name": "Integrated Incident Mgmt.",
        "process_step_id": 32,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": "medium",
        "business_problem_solved": "Today two non-integrated systems Go Track & BIX. Double Work in 2 systems.",
        "target_solution_description": "integrated incident management across systems (BIX & GoTrack successors) for financial and Quality issues. wave 2: local systems & communication with 3PL. LIM process supported by system (batch status, affected volume, value, issue, root cause, mitigation, Q decision, destruction, trending, batch oversight).",
        "technologies_text": "Add use case requirements for GoTrack Successor Solution. interface BIX successor to GoTrack Successor is a Must Have. One LIM Reporting / trending tool connecting infos from both systems.",
        "requirements": "Interface between Incident Tool and ERP for Financial Reconceliation. Interface between Incident Tool and ERP for triggering material movements into blocked stock.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "Medium",
        "reduction_time_launches": "Medium",
        "reduction_costs_supply": "Medium",
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Integrated Logistics Incident Management Solution (Quality/Usage decision AND commercial).",
        "further_ideas": "FURTHER INPUT / IDES: wave 2: interface deviation system to local systems supporting local LIM & communication with 3PL / CMO.",
        "effort_quantification": "Project cost: n/a (only Reporting and Interfaces). Run costs (p.a.): Reporting and Cost of interfaces tbd. Time for implementation: Incident management should be covered by GoTrack Successor. Follow-up actions like stock movements or credit note issue to BOPU in ERP system should be triggered via interfaces. Trending capabilities should be covered via reporting solutions.",
        "potential_quantification": "compliance, oversight.",
        "dependencies_text": "-",
        "contact_persons_text": "Henrike Munderloh. GMSO LIM Robert M\u00fcller. Deviation Mgmt Tatjana Popara. GBS Hendrik Lindmeyer.",
        "related_projects_text": "Gotrack successor. LIM process project (LIM 2.0).",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:08:56.865365+00:00"
      },
      {
        "id": 61,
        "bi_id": "SCM27",
        "name": "End 2 End Labeling",
        "process_step_id": 32,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 1",
        "effort_level": "Medium/High",
        "status": "high",
        "business_problem_solved": "Multiple different labels in global use. Manual efforts in warehouse processes (e.g. relabeling).",
        "target_solution_description": "Global standardized labels (incl. SSCC). One BI scanable pallet and case label (starting at external supplier level) & suitable for information exchange with external (CMO, 3PL, supplier). Future vision: could be fully digital (eg RFID tag). use GS 1 standard. part 1: inbound from supplier/CMO. part 2: outbound to POPU/ BOPU / CMO.",
        "technologies_text": "EWM. S/4 Hana. use SLCI process also for case/pallet.",
        "requirements": "GS1 Standard. SSCC Code Globally.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "Seamless end-to-end labeling using barcodes and RFID tags \u2014 from supplier to customer. Same case and pallet label for BI network. Label Harmonization. Label Harmonizaton. Cross site utilization of Handling Unit Label from source site. Increase digitalization in GBS ILOL processes: Paperless reduce and challenge checklists. One BI scanable pallet and case label (starting at external supplier level) & suitable for information exchange with external (CMO, 3PL, supplier). Avoid mix ups, ensure T&T, reduce TPT. Future vision: could be fully digital (eg RFID tag). Harmonized shipping and shipping carton labels across all sites and cmos. Digital label. Implement digital label to avoid manual label changes.",
        "further_ideas": null,
        "effort_quantification": "Project cost: none. Run costs (p.a.): ... Time for implementation: > 1y, higher complexity for integration at supplier/CMOs. Start with scoping workshop.",
        "potential_quantification": "Compliance: Avoid mix ups. Oversight & efficiency: ensure T&T, reduce TPT.",
        "dependencies_text": "Global SKU needs to be implemented that will be used for labeling. Master Data Definition / Ownership / Quality. harmonized label from supplier only if supplier / Q consent. Supplier and Customer needs to confirm BI Req. for labeling.",
        "contact_persons_text": "GMSO/ process: Ute Ostermann. GBS: Daniel Hildebrand, Kerstin Trenz. Content: Robert M\u00fcller. for CMOs: Uli Kies.",
        "related_projects_text": "Implementation of pool batch in EWM.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:09:17.617505+00:00"
      },
      {
        "id": 75,
        "bi_id": "PM-UC-10",
        "name": "Target Achievement Cockpit for Goal Monitoring",
        "process_step_id": 40,
        "priority": null,
        "raw_content": null,
        "summary": "Target Achievement Cockpit for Goal Monitoring. Automated daily/monthly/annual target achievement cockpit. Connected to action tracker (19) + good system to translate goals to targets and future oriented KPIs (1)",
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Lack of automated target achievement tracking. Manual monitoring of goal achievement across different time periods. Disconnected monitoring systems without integration to action tracking",
        "target_solution_description": "Target Achievement Cockpit for Goal Monitoring. Automated daily/monthly/annual target achievement cockpit. Connected to action tracker (19) + good system to translate goals to targets and future oriented KPIs (1)",
        "technologies_text": "Automated cockpit system. Integration with action tracking systems. KPI translation and monitoring tools",
        "requirements": "Integration with existing KPI systems. Connection to action tracker systems. Automated reporting capabilities",
        "relevants_text": "All areas requiring performance monitoring",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Target Achievement Cockpit for Goal Monitoring. Connected to action tracker (19) + good system to translate goals to targets and future oriented KPIs (1). Automated daily/monthly/annual target achievement cockpit. Also connected to 2",
        "further_ideas": null,
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null. Initial evaluation: Medium",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: null",
        "dependencies_text": "Connected to action tracker (19). Good system to translate goals to targets and future oriented KPIs (1). Also connected to 2. Partners, suppliers, stakeholders involvement mentioned",
        "contact_persons_text": "Marinie? (tentative contact mentioned)",
        "related_projects_text": "Action tracker (19). KPI translation system (1). Connection to use case 2",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:25:31.314842+00:00"
      },
      {
        "id": 116,
        "bi_id": "SCM36",
        "name": "SC Analytics & Reporting",
        "process_step_id": 14,
        "priority": null,
        "raw_content": null,
        "summary": null,
        "inspiration": "-",
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": "high",
        "business_problem_solved": "Clear transparency on available SC reports and analytics capabilities to increase process execution performance. Transparency: Clear reference data systems (one source of truth). MDG/FRED/etc. Eliminating reporting / data silos by creating ... Data needed to create insights are spread across various systems. Time to create information needed for decisions is very long and delays decision taking. (Before the product start it took up to 1 week to compile data for global inventory level). Many insights requested must be created manually or can not created manually. KPIs are not standardized and well defined with regards to formula and data to be used.",
        "target_solution_description": "Supply chain analytics involves using data analysis methodologies and tools to improve the effectiveness and efficiency of supply chain management. We help the organization make sense of large amounts of data generated, uncovering patterns, and generating insights to enhance material availability, logistics, inventory performance, customer experience, and profitability. We provide visibility and a single source of truth across the supply chain. offer solutions to optimize business value and collaboration. With the Digital Supply Chain Twin we use AI to answer complex questions and improve decision-making.",
        "technologies_text": "SAP Analytics Cloud. DataLand.",
        "requirements": "Life Cycle: The product uses data from core IT-Systems (e.g. transactional ERPs, COPE-Systems) but do not run them. However, we are impacted by LCM of SAP regarding BW and SAC platforms.",
        "relevants_text": "Bio, Pharma, Chemicals, Device, Launch, Routine",
        "reduction_time_transfer": "High",
        "reduction_time_launches": "High",
        "reduction_costs_supply": "High",
        "quality_improvement_quant": "High",
        "ideation_notes": "no E2E transparency on data. SC E2E Roadmap for Reporting. Extracting reports is cumbersome. Build SC Reporting & Analytics Community. One common concept forSC Reporting & Analytics. One data set used for SCM (and other fuctions such as Finance) - so we speak the same data language.",
        "further_ideas": null,
        "effort_quantification": "Project cost: Continuous invest in external support (PICON). Run costs (p.a.): SC Reporting & Analytics Community in Operations. Internal resources in SCA (current: 2FTE). Time for implementation: Product roll out and enhanacements ongoing.",
        "potential_quantification": "Increased data integrity, accuracy.",
        "dependencies_text": "...",
        "contact_persons_text": "SCA Christian P.",
        "related_projects_text": "SC Digital Twin, Christian Petri.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:11:41.675506+00:00"
      },
      {
        "id": 18,
        "bi_id": "PM-UC-01",
        "name": "One holistic performance management approach",
        "process_step_id": 46,
        "priority": null,
        "raw_content": null,
        "summary": "One holistic performance management approach with one source-of-truth cascading Our Priorities to team or individual targets and setting clear goals; visibility of upper targets. Harmonized & standardized methodology to break down strategic goals. Transparency on how each KPI contributes to each target and goal/ strategic objective on the next upper level. One Performance Monitoring Tool / Dashboard across BI",
        "inspiration": null,
        "wave": null,
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Use of multiple tools for performance management, leading to inefficiencies and lack of integration. Parallel breakdown of strategic targets resulting in more than one set of priorities within the organisation. Misalignment between individual and organizational goals",
        "target_solution_description": "One holistic performance management approach with one source-of-truth cascading Our Priorities to team or individual targets and setting clear goals; visibility of upper targets. Harmonized & standardized methodology to break down strategic goals. Transparency on how each KPI contributes to each target and goal/ strategic objective on the next upper level. One Performance Monitoring Tool / Dashboard across BI",
        "technologies_text": "ONE system for goals / targets and KPIs -> connection between KPIs and goals they contribute to. One electronic template in all organisation units to breakdown targets and setting goals",
        "requirements": "Breaking down goals and setting targets. Standardized breakdown methodology",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Connect long-term orientation and agile response capability (strategy - key results - KPI (measure&analyze). Smart and consistent target cascading. One holistic performance management approach with one source-of-truth cascading Our Priorities to team or individual targets and setting clear guardrails. Standardized breakdown: Use one electronic template in all organisation units to breakdown targets and setting goals. Common understanding of the dimensions",
        "further_ideas": null,
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null. Initial evaluation: Medium",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: High",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:19:48.612447+00:00"
      },
      {
        "id": 155,
        "bi_id": "PM-UC-31",
        "name": "MAG target achievement cockpit",
        "process_step_id": 42,
        "priority": 4,
        "raw_content": null,
        "summary": "This use case focuses on creating a Monthly-Updated Group (MAG) target achievement cockpit. This digital cockpit provides a clear and frequently updated overview of progress against defined targets.",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Low",
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:02:57.125684+00:00"
      },
      {
        "id": 22,
        "bi_id": "PM-UC-02",
        "name": "Break-down tool for strategic goals (transparent goal tree)",
        "process_step_id": 46,
        "priority": null,
        "raw_content": null,
        "summary": "IT Tool supporting standardized breakdown: One holistic performance management approach with one source-of-truth cascading Our Priorities to team or individual targets and setting clear goals; visibility of upper targets. Standardised approach to define and measure roadmaps for strategy implementation. Hoshin Kanri methodology in a standard software solution which incl. Savings tracker. Transparency on how each KPI contributes to each target and goal/ strategic objective on the next upper level",
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Each function develops different roadmaps not comparable or measurable. No aggregated roadmap towards our 2035 goal. Not all initiatives / actions are cascaded through the relevant teams precisely. Parallel breakdown of strategic targets resulting in more than one set of priorities within the organisation. Misalignment between individual and organizational goals",
        "target_solution_description": "IT Tool supporting standardized breakdown: One holistic performance management approach with one source-of-truth cascading Our Priorities to team or individual targets and setting clear goals; visibility of upper targets. Standardised approach to define and measure roadmaps for strategy implementation. Hoshin Kanri methodology in a standard software solution which incl. Savings tracker. Transparency on how each KPI contributes to each target and goal/ strategic objective on the next upper level",
        "technologies_text": "System supported standardized approach for breaking down strategic objectives to targets per department. Smart and connected goal cascading",
        "requirements": "Breaking down goals and setting targets. Business Case Tracker (e.g. expected savings of Project A x EUR in y sites --> track if these targets have been reached). Communication tool",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Visibility of targets of higher levels. Possibility to drill up/down between different levels of goals / targets. Each goal or target must be aligned and connected to the corresponding higher-level objective. System supported standardized approach for breaking down strategic objectives to targets per department. Smart and connected goal cascading",
        "further_ideas": "Business Case Tracker (e.g. expected savings of Project A x EUR in y sites --> track if these targets have been reached). Communication tool",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null. Initial evaluation: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:19:17.606896+00:00"
      },
      {
        "id": 25,
        "bi_id": "PM-UC-08",
        "name": "KPI Definition & Cascading",
        "process_step_id": 13,
        "priority": null,
        "raw_content": null,
        "summary": "Tool for KPI overview, calculation and connecting (incl. KPI Handbook). Smart and connected KPI tree pool. Standardized KPI framework for individual areas/functions. Systems for calculating KPIs ensuring consistent calculation and enabling easy drill down and aggregation. KPI Database: find KPIs, their definition and similar KPIs with KPI Playbook/Definition always linked with the specific dashboard",
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "Same KPI is calculated and/or interpreted in various ways in different areas. KPI dependencies are not clear or visualized. No structured overview of performance relevant KPIs across BI. No legacy system available for KPI management",
        "target_solution_description": "Tool for KPI overview, calculation and connecting (incl. KPI Handbook). Smart and connected KPI tree pool. Standardized KPI framework for individual areas/functions. Systems for calculating KPIs ensuring consistent calculation and enabling easy drill down and aggregation. KPI Database: find KPIs, their definition and similar KPIs with KPI Playbook/Definition always linked with the specific dashboard",
        "technologies_text": "Knowledge graph which shows the dependencies of the KPIs. Connected KPI-Tree Database. Digital and automated format for KPI logic and interaction. Drag and drop systematic from a KPI lake",
        "requirements": "Common understanding, cross functional exchange, employee acceptance via reduced efforts and clarity. Top down commitment by upper mgmt (no exceptions). Accept to develop from green field a new \"system\" (solution) - disruptive, ignore legacy approach. Connection to KPI lake (and dashboard) required. End-to-end transparency",
        "relevants_text": "All areas/functions across the organization",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "KPI Database: find KPIs, their definition and similar KPIs. KPI Playbook/Definition always linked with the specific dashboard. Kind of Knowledge graph which shows the dependencies of the KPIs. Tool for KPI overview, calculation and connecting (incl. KPI Handbook). Make KPIs compatible to benchmarks BI is participating (e.g. POBOS). Use established templates (SCOR-Model from APICS). Possibility to drill up/down between different levels of KPIs. Establish clear rules and standards for defining KPIs. Connected KPI-Tree Database easy accessible. KPI definitions and correlation to level above. Where does the key figure contribute to the effect of higher-level reporting? A specific KPI is clearly defined (calculation formula) including upper/lower limits for the entire organization. KPI logic and their interaction is available in a digital and automated format. Drag and drop systematic from a KPI lake. KPIs can be aggregated to higher-level KPIs or vice versa. KPIs are clearly linked in both direction (KPI hierarchy and horizontal). KPI calculation reflects area specific value stream. End user has simple system access and a user friendly application experience (way of working). \"House of Performance\" reflects and connects Strategy via Goals/Targets to KPIs across all levels. Each area is using a KPI portfolio which was selected/guided by the KPI handbook and by that it is ensure that comparable areas apply the same KPIs. Leading and execution by example (all leader levels). Top down commitment by upper mgmt (no exceptions). Accept to develop from green field a new \"system\" (solution) [disruptive, ignore legacy approach]. Connection to KPI lake (and dashboard) required. No legacy system available. Common understanding, cross functional exchange, employee acceptance via reduced efforts and clarity. End-to-end transparency",
        "further_ideas": null,
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null. Initial evaluation: Easy",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: High",
        "dependencies_text": "Breaking down silos/barriers and increase transparency (mentioned in related area)",
        "contact_persons_text": "Christina Frossert. Birgit W\u00e4rner. OneOps Ex. Exc. & Standard.",
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:21:44.004537+00:00"
      },
      {
        "id": 1,
        "bi_id": "PM-UC-03",
        "name": "AI supported knowledge graph tool for identifying dependant or conflicting targets and goals",
        "process_step_id": 46,
        "priority": null,
        "raw_content": null,
        "summary": "AI supported consolidation of individual targets and gap assessment vs. strategic goals. AI supported automatic translation of strategic goals into targets for individual areas (from top level to shop level). Overview over goals/targets of different departments with important interfaces is available with connection to own goals. System warns if goals/targets are contradictive. System shows dependences of goals in order to derive mutual measures to reach goals",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "Goals and targets of other departments are not communicated and not transparent. Connection between goals/targets are not visible and cannot be set into relation to each other and not to goals from above. No visualization of targets is available",
        "target_solution_description": "AI supported consolidation of individual targets and gap assessment vs. strategic goals. AI supported automatic translation of strategic goals into targets for individual areas (from top level to shop level). Overview over goals/targets of different departments with important interfaces is available with connection to own goals. System warns if goals/targets are contradictive. System shows dependences of goals in order to derive mutual measures to reach goals",
        "technologies_text": "Kind of Knowledge graph which show the dependencies of the Goals. Electronic tool for breakdown links to OneOps strategic targets to make focus and interdependencies transparent. AI supported knowledge graph tool",
        "requirements": "Breaking down goals and setting targets. Target breakdown tool with goal overview must be available (use case 02)",
        "relevants_text": null,
        "reduction_time_transfer": "n/a",
        "reduction_time_launches": "n/a",
        "reduction_costs_supply": "Impact if contradicting goals exist",
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "Kind of Knowledge graph which show the dependencies of the Goals. Electronic tool for breakdown links to OneOps strategic targets to make focus and interdependencies transparent. Co-dependencies of goals: Make goals for every employee transparent to enable more effective collaboration on goals or highlight conflicting goals. AI supported consolidation of individual targets and gap assessment vs. strategic goals",
        "further_ideas": "Target breakdown tool with goal overview must be available (use case 02)",
        "effort_quantification": "Operating cost (Opex): Software as a service. Invest (Capex): Cost for IT implementation. Implementation time: null. Initial evaluation: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: n/a. REDUCTION OF TIME FOR PRODUCT LAUNCH: n/a. REDUCTION OF TOTAL COSTS OF SUPPLY: Impact if contradicting goals exist. QUALITY (RFT): This helps to understand if goals are connected to reduce contradicting measures. Initial evaluation: null",
        "dependencies_text": "Target breakdown tool with goal overview must be available (use case 02)",
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:20:07.931449+00:00"
      },
      {
        "id": 150,
        "bi_id": "PM-UC-07",
        "name": "AI supported mapping for connecting KPIs to targets",
        "process_step_id": 13,
        "priority": 1,
        "raw_content": null,
        "summary": "This use case aims to provide AI system support to identify the most relevant KPIs for specific targets, acting as an automated guide for connecting KPIs to strategic goals. It makes focus areas and potential conflicts transparent by linking KPIs to relevant strategic targets, ensuring consistent cascading across aggregation levels.",
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:20.606258+00:00"
      },
      {
        "id": 28,
        "bi_id": "PM-UC-14",
        "name": "KPI-Lake with raw data access",
        "process_step_id": 40,
        "priority": null,
        "raw_content": null,
        "summary": "KPI-Lake with raw data access. enabler for Monitoring & Performance Dialogues",
        "inspiration": null,
        "wave": null,
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Access to raw/basis data in data lake for detailed analysis and improvement projects. KPI-Lake: Easy way to add KPI to individual monitoring use cases. All data in one place",
        "target_solution_description": "KPI-Lake with raw data access. enabler for Monitoring & Performance Dialogues",
        "technologies_text": "Connected to use case 8",
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Access to raw / basis data in data lake for detailed analysis and improvement projects. KPI-Lake: Easy way to add KPI to individual monitoring use cases. All data in one place",
        "further_ideas": "Info: KPI lake see #8. Info: Data lake see #20",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "Initial evaluation: High. REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": "Connected to use case 8. Related to KPI lake (see #8). Related to Data lake (see #20)",
        "contact_persons_text": null,
        "related_projects_text": "Connected to use case 8. KPI lake project (#8). Data lake project (#20)",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:25:44.980603+00:00"
      },
      {
        "id": 8,
        "bi_id": "PM-UC-18",
        "name": "Performance Optimization Recommender/Benchmark",
        "process_step_id": 41,
        "priority": null,
        "raw_content": null,
        "summary": "Tool to plan scenarios through including financial impact for decision making. Scenario planning and impact assessment (automatic). Predictive Performance Management. Interface to manufacturing. Performance pattern analysis to identify performance drivers. We are identifying the drivers in performance by analyzing the underlying data",
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "We are lacking full understanding of high performance. Trial-and-error approach. No way to find the optimal configuration in a production setting",
        "target_solution_description": "Tool to plan scenarios through including financial impact for decision making. Scenario planning and impact assessment (automatic). Predictive Performance Management. Interface to manufacturing. Performance pattern analysis to identify performance drivers. We are identifying the drivers in performance by analyzing the underlying data",
        "technologies_text": "ServiceNow could be a technology. ALFRED (automated machine learning use case). Data/ KPI Lake connection. Process and machine Data",
        "requirements": "Good data foundation. Especially data resolution. More unique data -> Higher chance to find drivers. Definition of high performance (e.g. maximizing Output vs. quality). Impact evaluation on production planning (e.g. connect to MWB). Flexible parameter ranges to optimize potential machine learning use case",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Tool to plan scenarios through including financial impact for decision making. Scenario planning and impact assessment (automatic). Performance pattern analysis to identify performance drivers. Impact evaluation on production planning (e.g. connect to MWB). We are lacking full understanding of high performance. Trial-and-error approach. No way to find the optimal configuration in a production setting",
        "further_ideas": "Good data foundation. Especially data resolution. More unique data -> Higher chance to find drivers. Definition of high performance (e.g. maximizing Output vs. quality). Impact evaluation on production planning (e.g. connect to MWB). Flexible parameter ranges to optimize potential machine learning use case. Data/ KPI Lake connection. Process and machine Data. ALFRED (automated machine learning use case). Increased effectiveness of corrective actions, reduction of Human Error Rate, reduction of recurrence rate",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "Initial evaluation: High. REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": "Victor Emenike L&I (ALFRED automated machine learning use case). Michael Fischer (MDM). Data Ownership Topic",
        "related_projects_text": "ALFRED (automated machine learning use case) - Victor Emenike L&I. MDM - Michael Fischer. Data Ownership Topic",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:28:03.533043+00:00"
      },
      {
        "id": 149,
        "bi_id": "PM-UC-05",
        "name": "Scenario simulation tool for target changes",
        "process_step_id": 46,
        "priority": 1,
        "raw_content": null,
        "summary": "This use case involves a tool designed for simulating the interdependencies and influences on Key Performance Indicators (KPIs) when targets are changed. It allows for advanced scenario planning to understand the potential impact of target adjustments before implementation.",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Medium/High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:23.920042+00:00"
      },
      {
        "id": 153,
        "bi_id": "PM-UC-25",
        "name": "Integrated Data Sharing Portal with internals & externals",
        "process_step_id": 30,
        "priority": 2,
        "raw_content": null,
        "summary": "This use case focuses on building an integrated data sharing portal to enable seamless data exchange both internally within the organization and with external partners (e.g., suppliers, CMOs, customers). It aims to process data effectively to facilitate this sharing.",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": null,
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:08.704811+00:00"
      },
      {
        "id": 151,
        "bi_id": "PM-UC-09",
        "name": "Data driven KPI creator and simulator for difficult targets",
        "process_step_id": 13,
        "priority": 2,
        "raw_content": null,
        "summary": "This use case proposes an AI tool that suggests new KPIs based on data connections and relationships, particularly for challenging targets. It also includes scenario planning capabilities for KPIs, reflecting cause-and-effect opportunities and utilizing established KPI-Trees (e.g., ROI-Tree).",
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Low",
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:16.312264+00:00"
      },
      {
        "id": 152,
        "bi_id": "PM-UC-21",
        "name": "Data Quality & Standardization",
        "process_step_id": 30,
        "priority": 1,
        "raw_content": null,
        "summary": "This use case addresses the critical need for improving data quality and standardization. It focuses on establishing a formal data governance framework, using IT tools and AI/ML algorithms for continuous monitoring of data quality, and defining clear policies and procedures for data management across the organization.",
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": null,
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:12.660288+00:00"
      },
      {
        "id": 154,
        "bi_id": "PM-UC-30",
        "name": "Performance Companion",
        "process_step_id": 42,
        "priority": 3,
        "raw_content": null,
        "summary": "This use case envisions a 'Performance Companion' system designed to propose existing standards and tools for improving performance mindset and orientation. It includes features for AI-supported employee development planning, AI-powered coaching, and a more employee-driven learning system to enhance individual and role-based performance.",
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:02.378236+00:00"
      },
      {
        "id": 30,
        "bi_id": "PM-UC-15",
        "name": "PurposeFit Dashboards",
        "process_step_id": 40,
        "priority": null,
        "raw_content": null,
        "summary": "Automatically updated KPI Dashboard with possibility to switch between level - management views vs. detail views. Flexible Dashboards with multiple views. Standardized Template-Dashboards that allow adaptation for specific cases. One dashboard solution for similar functions (instead of reinventing the wheel again and again) e.g., QC PD. Audience and purpose specific visualization & read out (interconnected)",
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "No unified system for dashboarding. Dashboards are not standardized, everybody develops their own solutions. Updates of dashboards are often done manually before meetings, not automatically populated with data. Dashboards are often too generic, can't be adjusted based on audience or issue at hand. High Recurrency Rate of Defects, Deviations, ... because the drivers of performance are not fully understood/root-causes not known",
        "target_solution_description": "Automatically updated KPI Dashboard with possibility to switch between level - management views vs. detail views. Flexible Dashboards with multiple views. Standardized Template-Dashboards that allow adaptation for specific cases. One dashboard solution for similar functions (instead of reinventing the wheel again and again) e.g., QC PD. Audience and purpose specific visualization & read out (interconnected)",
        "technologies_text": "PowerBI, Tableau, etc. Service Now. Global solution",
        "requirements": "Templates need to be discussed and created. KPI-Standards and KPI tree. Easy connection to underlying data to get fast insights into the foundational data. Data and KPI-Lake",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium/High",
        "ideation_notes": "Audience and purpose specific visualization & read out (interconnected). One dashboard solution for similar functions (instead of reinventing the wheel again and again) e.g., QC PD. Automatically updated KPI Dashboard with possibility to switch between level - management views vs. detail views. No unified system for dashboarding. Dashboards are not standardized, everybody develops their own solutions. Updates of dashboards are often done manually before meetings, not automatically populated with data. Dashboards are often too generic, can't be adjusted based on audience or issue at hand",
        "further_ideas": "Templates need to be discussed and created. KPI-Standards and KPI tree. Easy connection to underlying data to get fast insights into the foundational data. Data and KPI-Lake. PowerBI, Tableau, etc. Service Now. Global solution. No need of sites to invest in all dashboard creation. Standard dashboard no own development",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "See KPI deviations faster. REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": "High Recurrency Rate of Defects, Deviations, ... because the drivers of performance are not fully understood/root-causes not known. See KPI deviations faster",
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:25:49.637010+00:00"
      },
      {
        "id": 2,
        "bi_id": "PM-UC-16",
        "name": "Root Cause Analysis & Recommender System",
        "process_step_id": 41,
        "priority": null,
        "raw_content": null,
        "summary": "System supported analysis of main drivers for deviations. Tool to perform root cause analysis in case of deviations. Agentic resolution of deviations from KPI targets (or even before it deviates). Historical Knowledge Database: Find possible root-causes in historical data for KPI's. Define improvement activities from digital applications. Actions and their status are tracked and linked to related KPI / goal. Preventive action proposal tool with early-warning mechanism before gaps arise. SME/Expert community pool to drive standardized actions across units. Tool to propose options to close gap to target (based on historical data)",
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "No system to automatically support high quality root cause analysis. Knowledge about possible problem resolution is fragmented across people and systems -> not accessible. Real root cause for performance issue not identified. Tool to early identify risks and opportunities",
        "target_solution_description": "System supported analysis of main drivers for deviations. Tool to perform root cause analysis in case of deviations. Agentic resolution of deviations from KPI targets (or even before it deviates). Historical Knowledge Database: Find possible root-causes in historical data for KPI's. Define improvement activities from digital applications. Actions and their status are tracked and linked to related KPI / goal. Preventive action proposal tool with early-warning mechanism before gaps arise. SME/Expert community pool to drive standardized actions across units. Tool to propose options to close gap to target (based on historical data)",
        "technologies_text": "ServiceNow could be a technology",
        "requirements": "If KPI data including limits are available, accessible then digital notification (only this part) has a low implementation effort of one to two weeks, may be a quick win",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Digital notifications via smart devices and real-time countermeasures recommendations. Red KPI automatically show root-cause and proposed measures. AI-based proposals for solving similar known problems. Tool to early identify risks and opportunities. No system to automatically support high quality root cause analysis. Knowledge about possible problem resolution is fragmented across people and systems -> not accessible. Real root cause for performance issue not identified. Linked to action / mitigation tracker (owner, due date, commitment). Preventive action proposal tool with early-warning mechanism before gaps arise. SME/Expert community pool to drive standardized actions across units. Tool to propose options to close gap to target (based on historical data). Real-time countermeasures recommendations. Automated digital notifications via smart devices incl. escalation cascading. References to existing CAPAs addressing the same root cause",
        "further_ideas": "ServiceNow could be a technology. See #17. This is the base needed to be able to do #17",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: If KPI data including limits are available, accessible then digital notification (only this part) has a low implementation effort of one to two weeks, may be a quick win",
        "potential_quantification": "Initial evaluation: High. REDUCTION OF TIME FOR PRODUCT TRANSFER: See #17. REDUCTION OF TIME FOR PRODUCT LAUNCH: See #17. REDUCTION OF TOTAL COSTS OF SUPPLY: See #17. QUALITY (RFT): High",
        "dependencies_text": "See #17. This is the base needed to be able to do #17",
        "contact_persons_text": null,
        "related_projects_text": "See #17",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:27:59.981791+00:00"
      },
      {
        "id": 16,
        "bi_id": "PM-UC-23",
        "name": "Easy implementation of basic & advanced Analytical Tools",
        "process_step_id": 30,
        "priority": null,
        "raw_content": null,
        "summary": "Basic and advanced analytics tools to effectively analyze performance data. Simple, transparent and effective tracking of mitigation actions across functions with clear responsibilities to close gaps to target. Data analysis tool",
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Data analytic quality depends on personal experience and skills. Analysis is very time consuming. Complex models used for most issues while simple tools could provide equal insights / solutions",
        "target_solution_description": "Basic and advanced analytics tools to effectively analyze performance data. Simple, transparent and effective tracking of mitigation actions across functions with clear responsibilities to close gaps to target. Data analysis tool",
        "technologies_text": "Data lake. IQ solution",
        "requirements": "Access to data engineers. Data analytics as a service (e.g., Service Hub)",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Basic and advanced analytics tools to effectively analyze performance data. Simple, transparent and effective tracking of mitigation actions across functions with clear responsibilities to close gaps to target. Data analytic quality depends on personal experience and skills. Analysis is very time consuming. Complex models used for most issues while simple tools could provide equal insights / solutions",
        "further_ideas": "Data analysis tool. Access to data engineers. Data analytics as a service (e.g., Service Hub). Data lake. IQ solution",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:29:26.796393+00:00"
      },
      {
        "id": 27,
        "bi_id": "PM-UC-13",
        "name": "What-Now-Analyzer of KPIs",
        "process_step_id": 40,
        "priority": null,
        "raw_content": null,
        "summary": "Conclusion and action focused dashboards ('so what' instead of a collection of KPIs and graphs only) - supported by AI. What-Now-Analyzer of KPIs. Executive summary pre-drafted. Helps in faster decision-making, more efficient meetings and eventually faster problem fixing",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "Dashboards show graphs and numbers but lack conclusion \"the so-what message\". Collection of KPIs and graphs without clear action orientation. Inefficient decision-making and meetings due to lack of conclusive insights. Slower problem fixing due to missing actionable insights",
        "target_solution_description": "Conclusion and action focused dashboards ('so what' instead of a collection of KPIs and graphs only) - supported by AI. What-Now-Analyzer of KPIs. Executive summary pre-drafted. Helps in faster decision-making, more efficient meetings and eventually faster problem fixing",
        "technologies_text": "AI-supported analysis and conclusion generation. Large language models. Interlinked systems integration (e.g. CPV trending, other governance meetings)",
        "requirements": "Integration with existing KPI systems. AI/ML capabilities for analysis and conclusion generation. Connection to various governance systems. Comments interlinked to other systems e.g. CPV trending, other governance meetings",
        "relevants_text": "All areas using KPI dashboards and performance monitoring. Management and decision-making levels",
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Conclusion and action focused dashboards ('so what' instead of a collection of KPIs and graphs only) - supported by AI. Comments interlinked to other systems e.g. CPV trending, other governance meetings. Dashboards show graphs and numbers but lack conclusion \"the so-what message\". It helps in faster decision-making, more efficient meetings and eventually faster problem fixing. Executive summary pre-drafted. Conclusion and action focused dashboards ('so what' instead of a collection of KPIs and graphs only) - supported by AI. Executive summary pre-drafted",
        "further_ideas": "Interlinked systems e.g. CPV trending, other governance meetings. Large language models",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null. Initial evaluation: null",
        "dependencies_text": "Interlinked systems e.g. CPV trending, other governance meetings. Dependency on AI/ML infrastructure and capabilities",
        "contact_persons_text": null,
        "related_projects_text": "CPV trending systems. Other governance meetings systems",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:25:39.852567+00:00"
      },
      {
        "id": 31,
        "bi_id": "PM-UC-20",
        "name": "One Single Source of Truth (Data lake)",
        "process_step_id": 30,
        "priority": null,
        "raw_content": null,
        "summary": "Data Lake KPI Lake. Central data integration platform as single point of truth. Standardized systems. All Data are available in a data lake to be ordered. One data lake versus interconnection of various lakes. Single Source of truth. Connect all relevant data to one data foundation. Ad hoc data availability via a data lake instead of having to create new interfaces for each new report/dashboard. One pool allowing access to all relevant data. Systemic integration/interlinkage of data source to performance management tool. Central data platform as one source of truth. One central data lake as single source of truth containing data from all relevant systems. Clear definition of data source for each individual KPI",
        "inspiration": null,
        "wave": "Wave 1",
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "Performance relevant data are stored in various / multiple systems with limited access and interfaces. Difficulty in accessing required data due to its fragmentation across multiple systems. Data cannot be linked effectively due to a lack of standardization and harmonization. Need to create new interfaces for each new report/dashboard. Lack of a Centralized Data Inventory",
        "target_solution_description": "Data Lake KPI Lake. Central data integration platform as single point of truth. Standardized systems. All Data are available in a data lake to be ordered. One data lake versus interconnection of various lakes. Single Source of truth. Connect all relevant data to one data foundation. Ad hoc data availability via a data lake instead of having to create new interfaces for each new report/dashboard. One pool allowing access to all relevant data. Systemic integration/interlinkage of data source to performance management tool. Central data platform as one source of truth. One central data lake as single source of truth containing data from all relevant systems. Clear definition of data source for each individual KPI",
        "technologies_text": "Technology used in Program Dataland/ Business Warehouse",
        "requirements": "One harmonized approach in OneOps. Ensuring the accuracy, completeness, and consistency of the data. Easy accessibility of all data for users with business need, disregarding ownership",
        "relevants_text": null,
        "reduction_time_transfer": "Early identification of upcoming problem help to take countermeasures at an early point of time",
        "reduction_time_launches": "Alignment of targets and issue solving will support all target achievements, i.e. ensures faster transfers, launches & seamless supply",
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "Data Lake KPI Lake. Central data integration platform as single point of truth. Standardized systems. All Data are available in a data lake to be ordered. One data lake versus interconnection of various lakes. Single Source of truth. Performance relevant data are stored in various / multiple systems with limited access and interfaces. Difficulty in accessing required data due to its fragmentation across multiple systems. Data cannot be linked effectively due to a lack of standardization and harmonization. Need to create new interfaces for each new report/dashboard. Lack of a Centralized Data Inventory",
        "further_ideas": "Connect all relevant data to one data foundation. Ad hoc data availability via a data lake instead of having to create new interfaces for each new report/dashboard. Possibility to create dashboards in a reasonable time. One pool allowing access to all relevant data. Systemic integration/interlinkage of data source to performance management tool. Central data platform as one source of truth. One central data lake as single source of truth containing data from all relevant systems. Clear definition of data source for each individual KPI. One harmonized approach in OneOps. Ensuring the accuracy, completeness, and consistency of the data. Easy accessibility of all data for users with business need, disregarding ownership. Technology used in Program Dataland/ Business Warehouse",
        "effort_quantification": "Operating cost (Opex): Project cost to establish interfaces for data lake. Invest (Capex): n.a.. Implementation time: Medium (1 year?)",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: Early identification of upcoming problem help to take countermeasures at an early point of time. REDUCTION OF TIME FOR PRODUCT LAUNCH: Alignment of targets and issue solving will support all target achievements, i.e. ensures faster transfers, launches & seamless supply. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": "Enabler / pre-requisite for effective KPI performance management dashboard",
        "contact_persons_text": null,
        "related_projects_text": "L&I Data Hub",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:29:06.472547+00:00"
      },
      {
        "id": 15,
        "bi_id": "PM-UC-22",
        "name": "Information Model (Description of content and relevance of data)",
        "process_step_id": 30,
        "priority": null,
        "raw_content": null,
        "summary": "Central (SME) hub to overlook & define performance mgmt. relevant data. Canonical Data Model to connect data from various systems in place and used. Tool which shows existing KPIs and the connect between KPIs. Leverage the harmonized information model to develop KPIs. Landscape of KPIs, KPI tree",
        "inspiration": null,
        "wave": "Wave 2",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Difficult to benchmark between sites. KPIs not harmonized (harmonization does not mean that KPIs need to be the same on all levels, but an improvement on shopfloor level should also reflect on site and network level). Different definition of KPIs. Interdependencies between KPIs not fully understood",
        "target_solution_description": "Central (SME) hub to overlook & define performance mgmt. relevant data. Canonical Data Model to connect data from various systems in place and used. Tool which shows existing KPIs and the connect between KPIs. Leverage the harmonized information model to develop KPIs. Landscape of KPIs, KPI tree",
        "technologies_text": "There is no fancy technology involved here. AI to analyse correlations between KPIs and ideally also cause and effect connections",
        "requirements": "Understanding what action or objective you measure with the KPI",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Central (SME) hub to overlook & define performance mgmt. relevant data. Canonical Data Model to connect data from various systems in place and used. Tool which shows existing KPIs and the connect between KPIs. Difficult to benchmark between sites. KPIs not harmonized (harmonization does not mean that KPIs need to be the same on all levels, but an improvement on shopfloor level should also reflect on site and network level). Different definition of KPIs. Interdependencies between KPIs not fully understood",
        "further_ideas": "Leverage the harmonized information model to develop KPIs. Tool which shows existing KPIs and the connect between KPIs. Canonical Data Model to connect data from various systems in place and used. Central (SME) hub to overlook & define performance mgmt. relevant data. Landscape of KPIs, KPI tree. There is no fancy technology involved here. Understanding what action or objective you measure with the KPI. AI to analyse correlations between KPIs and ideally also cause and effect connections",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:29:17.130736+00:00"
      },
      {
        "id": 32,
        "bi_id": "PM-UC-26",
        "name": "Data mindset & according Governance",
        "process_step_id": 16,
        "priority": null,
        "raw_content": null,
        "summary": "Ensure culture that sees data as value and everyone contributes to generating the data that arise in real time and with good quality in the system where manually necessary. Data is seen as asset and its availability as a strategic target / asset. We fix / bring data to systems instead of creating facts / alternative data outside the systems. Important for the success of the complete SEOS project. Purpose driven",
        "inspiration": null,
        "wave": null,
        "effort_level": "High",
        "status": null,
        "business_problem_solved": "We fix / bring data to systems instead of creating facts / alternative data outside the systems. Data is not seen as asset and its availability as a strategic target / asset",
        "target_solution_description": "Ensure culture that sees data as value and everyone contributes to generating the data that arise in real time and with good quality in the system where manually necessary. Data is seen as asset and its availability as a strategic target / asset. We fix / bring data to systems instead of creating facts / alternative data outside the systems. Important for the success of the complete SEOS project. Purpose driven",
        "technologies_text": "Primarily no digital solution but mindset change",
        "requirements": "Buy-in upper management for change & transformation. Management and communication",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "High",
        "ideation_notes": "We fix / bring data to systems instead of creating facts / alternative data outside the systems. Data is seen as asset and its availability as a strategic target / asset. Ensure culture that sees data as value and everyone contributes to generating the data that arise in real time and with good quality in the system where manually necessary",
        "further_ideas": "Wirkung entfaltet sich mit positiver Erfahrung (Impact unfolds with positive experience). We fix / bring data to systems instead of creating facts / alternative data outside the systems. Data is seen as asset and its availability as a strategic target / asset. Important for the success of the complete SEOS project. Purpose driven. Buy-in upper management for change & transformation. Management and communication. Primarily no digital solution but mindset change",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:30:19.601900+00:00"
      },
      {
        "id": 33,
        "bi_id": "PM-UC-33",
        "name": "Automated data & information lessons learned database",
        "process_step_id": 42,
        "priority": null,
        "raw_content": null,
        "summary": "Automated data & information lessons learned database. Training pool is constructed that helps others to better decide, learn, not do the same errors. Instead of finding, potential solutions are suggested. Common technical language (Translating). While opening a defects there is a suggestion how to fix it based on historic data",
        "inspiration": null,
        "wave": "Waiting list",
        "effort_level": "Low",
        "status": null,
        "business_problem_solved": "Knowledge transfer currently very manual, contained in small teams. Many people do the same in different departments and they cannot learn from each other. Knowledge transfer is dependent on persons and it's trapped in different systems without the possibility to be connected",
        "target_solution_description": "Automated data & information lessons learned database. Training pool is constructed that helps others to better decide, learn, not do the same errors. Instead of finding, potential solutions are suggested. Common technical language (Translating). While opening a defects there is a suggestion how to fix it based on historic data",
        "technologies_text": "DocuBot. Service Now and OPEX prime. IQNow. Sharepoint",
        "requirements": "Connected system, data collected (not only words, but also machine and process data). Connection OPEX prime offers a solution (not yet fully developed)",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Medium",
        "ideation_notes": "Automated data & information lessons learned database. Knowledge transfer currently very manual, contained in small teams. Many people do the same in different departments and they cannot learn from each other. Knowledge transfer is dependent on persons and it's trapped in different systems without the possibility to be connected",
        "further_ideas": "Training pool is constructed that helps others to better decide, learn, not do the same errors. Instead of finding, potential solutions are suggested. Common technical language (Translating). While opening a defects there is a suggestion how to fix it based on historic data. Connected system, data collected (not only words, but also machine and process data). DocuBot. Service Now and OPEX prime. IQNow. Sharepoint. Connection OPEX prime offers a solution (not yet fully developed)",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "Initial evaluation: Medium. REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:31:35.948237+00:00"
      },
      {
        "id": 10,
        "bi_id": "PM-UC-27",
        "name": "Health check for performance mindset/behaviour",
        "process_step_id": 16,
        "priority": null,
        "raw_content": null,
        "summary": "(Health-checks) AI tool to support checking the maturity level regarding performance mindset of an organisation. Tool to measure engagement (number of participants in performance dialogue, number of Gemba walks, number of actions taken.....). Personal level: support to make individual behaviour transparent and show aggregated trends. Visualized Leading by example: Behavioral KPIs for leaders => adherence to company values in decision-making. Role Modeling tracker",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": "Lack of ambitious Performance mindset. No consequent management health-check",
        "target_solution_description": "(Health-checks) AI tool to support checking the maturity level regarding performance mindset of an organisation. Tool to measure engagement (number of participants in performance dialogue, number of Gemba walks, number of actions taken.....). Personal level: support to make individual behaviour transparent and show aggregated trends. Visualized Leading by example: Behavioral KPIs for leaders => adherence to company values in decision-making. Role Modeling tracker",
        "technologies_text": "Virtual campus, BI University. Performance Maturity Dashboard",
        "requirements": "Approval/alignment by workcouncil depending on what is measured",
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": "(Health-checks) AI tool to support checking the maturity level regarding performance mindset of an organisation. Tool to measure engagement (number of participants in performance dialogue, number of Gemba walks, number of actions taken.....). Personal level: support to make individual behaviour transparent and show aggregated trends. Lack of ambitious Performance mindset. No consequent management health-check",
        "further_ideas": "Tool to support checking the maturity level regarding performance mindset of an organisation. Visualized Leading by example: Behavioral KPIs for leaders => adherence to company values in decision-making. Role Modeling tracker. (Health-checks) AI tool to support checking the maturity level regarding performance mindset of an organisation. Tool to measure engagement (number of participants in performance dialogue, number of Gemba walks, number of actions taken.....). Role Modeling tracker. Approval/alignment by workcouncil depending on what is measured. Virtual campus, BI University. Performance Maturity Dashboard",
        "effort_quantification": "Operating cost (Opex): null. Invest (Capex): null. Implementation time: null",
        "potential_quantification": "REDUCTION OF TIME FOR PRODUCT TRANSFER: null. REDUCTION OF TIME FOR PRODUCT LAUNCH: null. REDUCTION OF TOTAL COSTS OF SUPPLY: null. QUALITY (RFT): null",
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-07T12:30:31.205774+00:00"
      },
      {
        "id": 148,
        "bi_id": "PM-UC-04",
        "name": "Smart tool for collaborative target setting methodology",
        "process_step_id": 46,
        "priority": 2,
        "raw_content": null,
        "summary": "This use case focuses on a smart tool to facilitate collaborative target setting. It enables a dialogue-based process for defining targets across hierarchical levels and provides easier feedback on unrealistic targets. This digital support aims to streamline and improve the effectiveness of goal definition.",
        "inspiration": null,
        "wave": "Wave 3",
        "effort_level": "Medium",
        "status": null,
        "business_problem_solved": null,
        "target_solution_description": null,
        "technologies_text": null,
        "requirements": null,
        "relevants_text": null,
        "reduction_time_transfer": null,
        "reduction_time_launches": null,
        "reduction_costs_supply": null,
        "quality_improvement_quant": "Low/Medium",
        "ideation_notes": null,
        "further_ideas": null,
        "effort_quantification": null,
        "potential_quantification": null,
        "dependencies_text": null,
        "contact_persons_text": null,
        "related_projects_text": null,
        "created_at": "2025-06-07T12:57:07.188532+00:00",
        "updated_at": "2025-06-07T13:03:28.780469+00:00"
      }
    ],
    "usecase_area_relevance": [],
    "usecase_step_relevance": [
      {
        "id": 1,
        "source_usecase_id": 88,
        "target_process_step_id": 3,
        "relevance_score": 90,
        "relevance_content": "**Type:** Strategic Guidance & Lifecycle Management, Data Exchange & Information Provision\n**Description:** The decision to outsource specific products (SKUs) is central to SPM01. Efficient SKU creation and management, including robust master data and lifecycle handling, is essential for SPM to strategically define and manage the product portfolio for external manufacturing.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 2,
        "source_usecase_id": 97,
        "target_process_step_id": 3,
        "relevance_score": 95,
        "relevance_content": "**Type:** System/Platform Integration, Data Exchange & Information Provision\n**Description:** A harmonized SKU data model provides the foundational framework for classifying and tracking products, enabling SPM01 to make informed decisions about which products are suitable for outsourcing and how they fit into the overall external manufacturing strategy.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 3,
        "source_usecase_id": 84,
        "target_process_step_id": 3,
        "relevance_score": 95,
        "relevance_content": "**Type:** Planning & Resource Coordination, Data Exchange & Information Provision\n**Description:** SPM01 relies on a comprehensive understanding of global internal and external (CMO) capacities to make strategic make-vs-buy decisions and to optimize the entire external manufacturing network. This data model is critical for long-term strategic planning.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 4,
        "source_usecase_id": 100,
        "target_process_step_id": 3,
        "relevance_score": 95,
        "relevance_content": "**Type:** Strategic Guidance & Lifecycle Management, Planning & Resource Coordination\n**Description:** This use case enables scenario planning and simulation across the entire product lifecycle. SPM01 needs these capabilities to evaluate the impact of outsourcing decisions on product profitability, market entry, and resource allocation at a strategic level.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 5,
        "source_usecase_id": 111,
        "target_process_step_id": 3,
        "relevance_score": 90,
        "relevance_content": "**Type:** Strategic Guidance & Lifecycle Management, Data Exchange & Information Provision\n**Description:** SPM01 must continuously assess external factors, including new regulations, to inform its outsourcing strategy. This use case provides the intelligence needed to proactively adapt the external network to ensure compliance and avoid disruptions.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 6,
        "source_usecase_id": 125,
        "target_process_step_id": 4,
        "relevance_score": 95,
        "relevance_content": "**Type:** Compliance & Quality Oversight, Strategic Guidance & Lifecycle Management\n**Description:** SPM02 initiates the formal qualification of potential CMOs. This use case ensures that a standardized process and data are in place for assessing and overseeing whether new partners meet global qualification standards, a mandatory prerequisite for contracting.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 7,
        "source_usecase_id": 115,
        "target_process_step_id": 4,
        "relevance_score": 100,
        "relevance_content": "**Type:** System/Platform Integration, Data Exchange & Information Provision\n**Description:** Accurate and high-quality master data (especially for suppliers/CMOs) is fundamental for SPM02. It ensures that all contractual details and partner information are consistently and reliably managed from the very beginning of the relationship.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 8,
        "source_usecase_id": 80,
        "target_process_step_id": 4,
        "relevance_score": 100,
        "relevance_content": "**Type:** External Partnership Management, System/Platform Integration\n**Description:** As SPM02 establishes new partner relationships, the ability to set up seamless and secure data interfaces for ongoing collaboration (e.g., sharing due diligence documents, initial quality data) is critical for efficient contracting.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 9,
        "source_usecase_id": 79,
        "target_process_step_id": 5,
        "relevance_score": 95,
        "relevance_content": "**Type:** Compliance & Quality Oversight, Data Exchange & Information Provision\n**Description:** The transfer of analytical methods and product specifications to a CMO is a core task of SPM04. A centralized system ensures that CMOs receive the correct, harmonized, and up-to-date specifications, critical for compliant manufacturing and testing.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 10,
        "source_usecase_id": 68,
        "target_process_step_id": 5,
        "relevance_score": 95,
        "relevance_content": "**Type:** Sequential Process Dependency, Data Exchange & Information Provision\n**Description:** SPM04 is responsible for transferring comprehensive product and process knowledge to CMOs. This use case ensures that this knowledge is readily available in a unified format, accelerating the transfer process and enabling \"right first time\" production at the partner site.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 11,
        "source_usecase_id": 67,
        "target_process_step_id": 5,
        "relevance_score": 90,
        "relevance_content": "**Type:** Sequential Process Dependency, Competency & Operational Support Provision\n**Description:** Effective technology transfer to CMOs (managed by SPM04) necessitates the provision of clear, standardized, and digitally supported Master Batch Records and recipes, enabling the CMO to implement manufacturing processes correctly.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 12,
        "source_usecase_id": 70,
        "target_process_step_id": 5,
        "relevance_score": 80,
        "relevance_content": "**Type:** Sequential Process Dependency, System/Platform Integration\n**Description:** When a CMO receives a transferred manufacturing process, the ability to automatically load recipes and equipment settings based on the transferred technology reduces manual errors and accelerates implementation, directly supporting SPM04.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 13,
        "source_usecase_id": 58,
        "target_process_step_id": 5,
        "relevance_score": 90,
        "relevance_content": "**Type:** Compliance & Quality Oversight, Data Exchange & Information Provision\n**Description:** During technology transfer (SPM04), the Contamination Control Strategy (CCS) and Control Strategy (CSS) for the product and process must be clearly communicated and implemented at the CMO. A digital tool streamlines this critical quality transfer.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 14,
        "source_usecase_id": 73,
        "target_process_step_id": 5,
        "relevance_score": 85,
        "relevance_content": "**Type:** Competency & Operational Support Provision, Compliance & Quality Oversight\n**Description:** SPM04 manages the validation and qualification activities at CMOs post-transfer. Automated generation of related documentation (e.g., validation protocols, reports) significantly streamlines this process, ensuring compliance and efficiency.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 15,
        "source_usecase_id": 122,
        "target_process_step_id": 6,
        "relevance_score": 90,
        "relevance_content": "**Type:** Data Exchange & Information Provision, Feedback Loop for Improvement & Adaption\n**Description:** SPM05 requires real-time insight into CMO manufacturing processes to proactively identify and respond to quality deviations or performance issues, ensuring continuous compliance.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 16,
        "source_usecase_id": 126,
        "target_process_step_id": 6,
        "relevance_score": 92,
        "relevance_content": "**Type:** Data Exchange & Information Provision, Compliance & Quality Oversight\n**Description:** SPM05 is responsible for the quality release of batches manufactured by CMOs. Real-time batch data and efficient review mechanisms enable quicker and more compliant release decisions for outsourced products.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 17,
        "source_usecase_id": 69,
        "target_process_step_id": 6,
        "relevance_score": 88,
        "relevance_content": "**Type:** Data Exchange & Information Provision, System/Platform Integration\n**Description:** To effectively oversee quality at CMOs, SPM05 needs assurance that production and in-process control data are accurately and reliably collected and transferred from CMO equipment, ideally in real-time for compliance monitoring.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 18,
        "source_usecase_id": 24,
        "target_process_step_id": 6,
        "relevance_score": 85,
        "relevance_content": "**Type:** Feedback Loop for Improvement & Adaption, Data Exchange & Information Provision\n**Description:** SPM05 manages deviations and CAPAs originating from CMOs. This use case is critical for evaluating the long-term effectiveness of these corrective actions, ensuring sustained quality improvement at partner sites.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 19,
        "source_usecase_id": 17,
        "target_process_step_id": 6,
        "relevance_score": 90,
        "relevance_content": "**Type:** System/Platform Integration, Data Exchange & Information Provision\n**Description:** Advanced AI capabilities, enabled by this interface, can support SPM05 in predictive quality monitoring (e.g., identifying potential quality excursions at CMOs based on trending data) and more efficient root cause analysis of quality issues.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 20,
        "source_usecase_id": 34,
        "target_process_step_id": 6,
        "relevance_score": 90,
        "relevance_content": "**Type:** Compliance & Quality Oversight, Feedback Loop for Improvement & Adaption\n**Description:** SPM05 actively manages quality risks associated with external partners. A proactive risk management tool allows for early identification and mitigation of potential quality issues at CMOs, enhancing overall product safety and compliance.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 21,
        "source_usecase_id": 52,
        "target_process_step_id": 6,
        "relevance_score": 85,
        "relevance_content": "**Type:** Data Exchange & Information Provision, Compliance & Quality Oversight\n**Description:** SPM05 is heavily involved in documenting quality events (deviations, complaints, CAPAs) from CMO operations. This use case streamlines the creation of these records in the eQMS, improving efficiency and data quality for partner-related quality incidents.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 22,
        "source_usecase_id": 55,
        "target_process_step_id": 6,
        "relevance_score": 95,
        "relevance_content": "**Type:** System/Platform Integration, Compliance & Quality Oversight\n**Description:** SPM05 oversees quality-related actions such as batch blocking/unblocking for CMO-produced goods. Full integration between ERP and eQMS is critical for automated and compliant execution of these actions, providing SPM05 with real-time control over outsourced products.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 23,
        "source_usecase_id": 43,
        "target_process_step_id": 6,
        "relevance_score": 90,
        "relevance_content": "**Type:** Sequential Process Dependency, Compliance & Quality Oversight\n**Description:** SPM05 provides the final quality approval for batches manufactured by CMOs. A digital batch release hub consolidates all necessary documentation and data, enabling SPM05 to make efficient and compliant release decisions for outsourced products.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 24,
        "source_usecase_id": 29,
        "target_process_step_id": 6,
        "relevance_score": 90,
        "relevance_content": "**Type:** Compliance & Quality Oversight, Data Exchange & Information Provision\n**Description:** SPM05 monitors the QC processes and results from CMOs. Implementing \"review by exception\" for QC data from external partners allows SPM05 to focus its oversight on critical deviations, streamlining the quality control process for outsourced products.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 25,
        "source_usecase_id": 144,
        "target_process_step_id": 6,
        "relevance_score": 92,
        "relevance_content": "**Type:** Compliance & Quality Oversight, Sequential Process Dependency\n**Description:** SPM05 relies on accurate and timely QC release data from CMOs. Automated QC release processes (including automated CoA generation) at CMOs provide SPM05 with rapid verification of product quality for batch disposition.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 26,
        "source_usecase_id": 38,
        "target_process_step_id": 6,
        "relevance_score": 90,
        "relevance_content": "**Type:** Data Exchange & Information Provision, Feedback Loop for Improvement & Adaption\n**Description:** SPM05 benefits from predictive analytics for quality trending of CMO data. This allows for proactive identification of potential quality issues with external partners before they escalate, enhancing preventive quality oversight.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 27,
        "source_usecase_id": 109,
        "target_process_step_id": 6,
        "relevance_score": 95,
        "relevance_content": "**Type:** Event-Driven Trigger / Anomaly Response, Data Exchange & Information Provision\n**Description:** SPM05 manages quality incidents (e.g., deviations, complaints) with external partners. An integrated incident management system provides comprehensive visibility and streamlined resolution of quality-related issues involving CMOs.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 28,
        "source_usecase_id": 18,
        "target_process_step_id": 7,
        "relevance_score": 80,
        "relevance_content": "**Type:** Strategic Guidance & Lifecycle Management, Planning & Resource Coordination\n**Description:** SPM06 manages the day-to-day performance of CMOs. A holistic performance management approach ensures that CMO performance is measured, reviewed, and improved in alignment with the broader company's performance goals and KPIs.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 29,
        "source_usecase_id": 27,
        "target_process_step_id": 7,
        "relevance_score": 85,
        "relevance_content": "**Type:** Data Exchange & Information Provision, Feedback Loop for Improvement & Adaption\n**Description:** SPM06 conducts performance reviews with CMOs. A KPI \"What-Now-Analyzer\" provides actionable insights from CMO performance data, enabling faster and more effective decision-making during routine performance dialogues.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 30,
        "source_usecase_id": 28,
        "target_process_step_id": 7,
        "relevance_score": 90,
        "relevance_content": "**Type:** Data Exchange & Information Provision, System/Platform Integration\n**Description:** SPM06 requires detailed performance data from CMOs for routine monitoring and deep-dive analysis. A KPI-Lake provides centralized access to raw data, enabling comprehensive assessment of partner performance.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 31,
        "source_usecase_id": 31,
        "target_process_step_id": 7,
        "relevance_score": 100,
        "relevance_content": "**Type:** System/Platform Integration, Data Exchange & Information Provision\n**Description:** This foundational use case ensures that all data relevant for SPM06's routine performance management (e.g., delivery, cost, production data from CMOs) is accurate and consistent, enabling reliable performance evaluation.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 32,
        "source_usecase_id": 32,
        "target_process_step_id": 7,
        "relevance_score": 80,
        "relevance_content": "**Type:** Competency & Operational Support Provision, Strategic Guidance & Lifecycle Management\n**Description:** A data-driven mindset and strong data governance ensure that performance data from CMOs is consistently reliable and valued, which is crucial for SPM06 to effectively monitor and manage partner performance.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 33,
        "source_usecase_id": 93,
        "target_process_step_id": 7,
        "relevance_score": 90,
        "relevance_content": "**Type:** Planning & Resource Coordination, Event-Driven Trigger / Anomaly Response\n**Description:** SPM06 needs to respond to operational deviations and exceptions that occur with CMOs within the broader supply chain. E2E orchestration provides the necessary visibility and coordination mechanisms.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 34,
        "source_usecase_id": 44,
        "target_process_step_id": 8,
        "relevance_score": 90,
        "relevance_content": "**Type:** External Partnership Management, Data Exchange & Information Provision\n**Description:** SPM08 coordinates with Contract Laboratory Organizations (CLOs). Automated integration of data, such as Certificates of Analysis (CoAs) from CLOs, is critical for efficient oversight of testing services and compliance.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      }
    ],
    "usecase_usecase_relevance": [],
    "process_step_process_step_relevance": [
      {
        "id": 1,
        "source_process_step_id": 3,
        "target_process_step_id": 17,
        "relevance_score": 85,
        "relevance_content": "Type: Strategic Guidance & Lifecycle Management. Description: The strategic decision to outsource products or processes, made by SPM01, directly creates the imperative for Quality Assurance to establish, adapt, and manage its foundational processes (e.g., external partner integration, documentation, quality systems) to ensure compliance and quality oversight for these new external manufacturing relationships.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 2,
        "source_process_step_id": 4,
        "target_process_step_id": 19,
        "relevance_score": 98,
        "relevance_content": "Type: Compliance & Quality Oversight. Description: SPM02's activities, such as initial CMO qualification, due diligence assessments covering GxP standards, and the establishment of Quality Agreements, are mandatory prerequisites that require direct input, execution, and approval from Quality Assurance. QA ensures that new partners meet all necessary regulatory and internal quality standards before contracting.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 3,
        "source_process_step_id": 5,
        "target_process_step_id": 20,
        "relevance_score": 95,
        "relevance_content": "Type: Compliance & Quality Oversight. Description: SPM04 executes technology transfer activities that are subject to rigorous validation and qualification requirements. Quality Assurance defines these requirements and provides oversight, ensuring that the transfer and subsequent implementation of processes at CMOs are compliant with GxP and internal standards.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 4,
        "source_process_step_id": 6,
        "target_process_step_id": 19,
        "relevance_score": 100,
        "relevance_content": "Type: Compliance & Quality Oversight. Description: SPM05 continuously monitors the manufacturing quality of external partners, managing deviations, coordinating CAPA processes, and overseeing quality agreements. These activities are integral to Quality Assurance's ongoing audit and intelligence functions, providing critical data for compliance assessments and continuous improvement.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 5,
        "source_process_step_id": 6,
        "target_process_step_id": 23,
        "relevance_score": 85,
        "relevance_content": "Type: Planning & Resource Coordination. Description: As part of its holistic quality oversight for external partners, SPM05 actively coordinates with internal or contract laboratories (e.g., via SPM08) to ensure that product testing is performed, and results are generated, evaluated, and released accurately and in a timely manner. This coordination is crucial for the efficient flow of quality data.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 6,
        "source_process_step_id": 7,
        "target_process_step_id": 13,
        "relevance_score": 85,
        "relevance_content": "Type: Data Exchange & Information Provision. Description: SPM06 is actively involved in tracking Key Performance Indicators (KPIs) and conducting performance review meetings for CMOs. The data and performance insights gathered directly contribute to and align with the organization's broader Performance Management framework, influencing KPI definitions and informing structured performance dialogues across the company.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 7,
        "source_process_step_id": 7,
        "target_process_step_id": 19,
        "relevance_score": 80,
        "relevance_content": "Type: Compliance & Quality Oversight. Description: SPM06 is responsible for the ongoing maintenance of CMO qualifications and supplier development programs. These continuous activities are subject to regular audits and surveillance by Quality Assurance, ensuring sustained compliance with GxP and established quality standards throughout the partner relationship.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 8,
        "source_process_step_id": 8,
        "target_process_step_id": 44,
        "relevance_score": 100,
        "relevance_content": "Type: External Partnership Management. Description: SPM08 directly manages the relationship and operational coordination with Contract Laboratory Organizations (CLOs). This involves overseeing the execution of testing services and ensuring their alignment with internal Quality Control standards for test preparation, execution, and data integrity.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 9,
        "source_process_step_id": 8,
        "target_process_step_id": 19,
        "relevance_score": 95,
        "relevance_content": "Type: Compliance & Quality Oversight. Description: SPM08 provides dedicated quality oversight and ensures compliance for Contract Laboratory Organizations. This directly links to Quality Assurance's responsibilities for auditing, managing quality agreements, and handling any non-conformances arising from external lab activities, ensuring adherence to GxP standards.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 10,
        "source_process_step_id": 8,
        "target_process_step_id": 6,
        "relevance_score": 80,
        "relevance_content": "Type: Strategic Guidance & Lifecycle Management. Description: SPM08 operates as a specialized and integral part of SPM05's broader mandate for holistic quality oversight of external partners. While SPM05 defines the overall quality strategy for CMOs, SPM08 focuses specifically on the unique requirements and coordination of contract laboratory services within that framework.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 11,
        "source_process_step_id": 3,
        "target_process_step_id": 25,
        "relevance_score": 10,
        "relevance_content": "Type: Strategic Guidance & Lifecycle Management. Description: SPM01 performs strategic make-vs-buy analyses and develops the overall CMO (Contract Manufacturing Organization) strategy. These high-level decisions directly determine whether specific products or processes are manufactured internally or externally, thereby setting the fundamental scope and operational context for the Manufacturing area regarding these outsourced activities.\r\n\r\nOliver: this is rather a task of SCM",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 12,
        "source_process_step_id": 5,
        "target_process_step_id": 43,
        "relevance_score": 90,
        "relevance_content": "Type: Sequential Process Dependency. Description: SPM04's transfer of analytical methods is a direct input for Quality Control. QC relies on these transferred methods to establish and update product specifications, ensuring that the necessary analytical procedures are in place for testing products from CMOs.\r\n\r\nAgain the other way round",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 13,
        "source_process_step_id": 25,
        "target_process_step_id": 5,
        "relevance_score": 98,
        "relevance_content": "Type: Sequential Process Dependency. Description: SPM04 is responsible for the systematic coordination and execution of technology transfer, encompassing manufacturing processes, analytical methods, and critical product knowledge, to qualified CMOs. This successful transfer is a direct and indispensable prerequisite for the external partner to initiate and effectively execute manufacturing operations.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      },
      {
        "id": 14,
        "source_process_step_id": 6,
        "target_process_step_id": 8,
        "relevance_score": 90,
        "relevance_content": "**Type**: Planning & Resource Coordination. \n\n**Description**: SPM05 holds the overarching responsibility for quality oversight of all external partners, including the testing conducted by contract laboratories. This general mandate is specifically executed and detailed by SPM08, which manages the direct coordination and performance of these contract labs, demonstrating a clear internal delegation of function within SPM.",
        "created_at": "2025-06-06T14:05:40.147324+00:00",
        "updated_at": "2025-06-06T14:05:40.147324+00:00"
      }
    ]
  }
}